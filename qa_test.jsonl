{"type": "matched_pair", "qa_id": "0be54f59-7cc4-5c78-be67-22245566eca3", "question": {"id": null, "qa_id": "0be54f59-7cc4-5c78-be67-22245566eca3", "book_id": "47bbcc23-9276-5662-9e40-96e8a4841ec7", "section_labels": ["practice", "solutions"], "section_titles": ["Exercise Solutions", "Practice Exercises"], "pdf_page": 1050, "problem_key": "4", "question_number": 4, "question_text": "Given ğ‘›line segments and a disk (represented as a center point and a radius) in an ğ‘¥ğ‘¦-plane, you want to determine whether any two line\nsegments intersect inside of the disk. What is the worst-case time complexity of solving this problem, if you use the most efficient algorithm?\nA) Î˜(log(ğ‘›))\nB) Î˜(\nâˆš\nğ‘›)\nC) Î˜(ğ‘›)\nD) Î˜(ğ‘›log(ğ‘›))\nÎ˜(ğ‘›2)E)", "question_embedding": null, "page_ids": ["1a3da172-d383-5da8-b297-3fd5ea9024dc", "2afd0c50-ab9c-5b1e-acab-c7e93b22bf80", "5b3eb61a-78ca-5ab0-a3f1-002ac1c1cff4", "6275fd1a-cffc-5d55-9e15-840a57b06dcd", "7b25559a-771c-5789-849e-761231306ccf", "7b7d9dc6-5cd7-52df-b66e-d4548821bf99", "862d47c5-75db-5446-8ee5-19e543dc5181", "8c8f8242-6e2b-563a-af29-ebd95912031a", "942883f1-20a5-56b3-a5e0-a9ffafda687c", "9801d2c0-b83e-52f9-b703-56eeba030479", "9b0d4dd4-86c3-518e-a300-140b5431246b", "a33ee040-cb9d-5bce-8fe4-7a2149f54fc9", "a732e97e-0ac4-53d2-b683-2ca489c035d6", "a8bd50a1-a8c7-5431-824f-b2983d36f1ed", "e07bc6fe-0bb9-5892-9565-a839b6bcff01", "eeb12615-da5e-5489-a593-75fa07932e2c", "f0f93193-dc46-5ba5-9f4d-77717945d193", "f5d6b0c4-2db1-5173-8428-b1cf083e7cc4", "f6099dd1-8ca5-5a05-8f00-ca473fc97adc"]}, "answers": [{"id": null, "qa_id": "0be54f59-7cc4-5c78-be67-22245566eca3", "book_id": "47bbcc23-9276-5662-9e40-96e8a4841ec7", "section_labels": ["practice", "solutions"], "section_titles": ["Exercise Solutions", "Practice Exercises"], "pdf_page": 126, "problem_key": "4", "answer_number": 4, "answer_choice": "C", "answer_text": "Lower order terms can be ignored in big-O, and the term with the highest order is 79ğ‘›. Coefficients can be\nignored as well, so the complexity of can be simplified to Î˜(ğ‘›).foo\nÎ˜(ğ‘›3 Î˜(ğ‘›3)5. The correct answer is (D). A algorithm grows faster than a algorithm due to the presence of an additional termlog(ğ‘›)) log(ğ‘›)\nÎ˜(2ğ‘›) Î˜(ğ‘›ğ‘›) Î˜(2ğ‘›)ğ‘›3.that is multiplied with A algorithm grows faster than a algorithm, and a algorithm grows faster than both aÎ˜(ğ‘›!)\nand a algorithm. You can also see this by testing a few values of ğ‘›, as shown below:Î˜(ğ‘›!)\nn\n2\n4\n8\n2ğ‘›\n4\n16\n256\nğ‘›!\n2\n24\n40,320\nğ‘›ğ‘›\n4\n256\n16,777,216", "answer_embedding": null, "answer_confidence": null, "page_ids": ["8c8f8242-6e2b-563a-af29-ebd95912031a", "f6099dd1-8ca5-5a05-8f00-ca473fc97adc"]}, {"id": null, "qa_id": "0be54f59-7cc4-5c78-be67-22245566eca3", "book_id": "47bbcc23-9276-5662-9e40-96e8a4841ec7", "section_labels": ["practice", "solutions"], "section_titles": ["Exercise Solutions", "Practice Exercises"], "pdf_page": 211, "problem_key": "4", "answer_number": 4, "answer_choice": "E", "answer_text": "When initializing a vector using a fill constructor, the first argument is the intended size of the vector, and the\nsecond argument is the value you want initialized for each of the elements in the vector. Only choice (E) works here: you are initializing a\nvector of size 5 (first argument) where each element is initialized to a vector of integers (second argument). This inner vector is given a size\nof 3 (first argument), where each element is initialized to 4 (second argument).", "answer_embedding": null, "answer_confidence": null, "page_ids": ["8c8f8242-6e2b-563a-af29-ebd95912031a", "eeb12615-da5e-5489-a593-75fa07932e2c", "f6099dd1-8ca5-5a05-8f00-ca473fc97adc"]}, {"id": null, "qa_id": "0be54f59-7cc4-5c78-be67-22245566eca3", "book_id": "47bbcc23-9276-5662-9e40-96e8a4841ec7", "section_labels": ["practice", "solutions"], "section_titles": ["Exercise Solutions", "Practice Exercises"], "pdf_page": 281, "problem_key": "4", "answer_number": 4, "answer_choice": "D", "answer_text": "The situation described in answer choice (D) is most similar to how a queue works, since those who are in line\nfirst are seated first.\nstd::queue<>,5. The correct answer is (C). To access the most recently added element in a you must remove the elements that areğ‘›âˆ’1\nbefore it, which takes time.Î˜(ğ‘›)", "answer_embedding": null, "answer_confidence": null, "page_ids": ["8c8f8242-6e2b-563a-af29-ebd95912031a", "9b0d4dd4-86c3-518e-a300-140b5431246b", "eeb12615-da5e-5489-a593-75fa07932e2c", "f6099dd1-8ca5-5a05-8f00-ca473fc97adc"]}, {"id": null, "qa_id": "0be54f59-7cc4-5c78-be67-22245566eca3", "book_id": "47bbcc23-9276-5662-9e40-96e8a4841ec7", "section_labels": ["practice", "solutions"], "section_titles": ["Exercise Solutions", "Practice Exercises"], "pdf_page": 328, "problem_key": "4", "answer_number": 4, "answer_choice": "B", "answer_text": "Option (A) is false because unsorted sequence containers provide insertion and removal. Option (C)Î˜(ğ‘›)Î˜(1)\nis false because sorted sequence containers provide removal. Option (D) is false because an array of linked lists is only viable forÎ˜(1)\npriorities of small integers and may involve other inefficiencies (such as memory overhead). Only option (B) is true: if you use a binary\nheap to implement a priority queue, then the time complexities of insertion and removal are both Î˜(log(ğ‘›)).", "answer_embedding": null, "answer_confidence": null, "page_ids": ["8c8f8242-6e2b-563a-af29-ebd95912031a", "9b0d4dd4-86c3-518e-a300-140b5431246b", "a732e97e-0ac4-53d2-b683-2ca489c035d6", "eeb12615-da5e-5489-a593-75fa07932e2c", "f6099dd1-8ca5-5a05-8f00-ca473fc97adc"]}, {"id": null, "qa_id": "0be54f59-7cc4-5c78-be67-22245566eca3", "book_id": "47bbcc23-9276-5662-9e40-96e8a4841ec7", "section_labels": ["practice", "solutions"], "section_titles": ["Exercise Solutions", "Practice Exercises"], "pdf_page": 420, "problem_key": "4", "answer_number": 4, "answer_choice": "A", "answer_text": "Only statement I is required for the STLâ€™s set algorithms, as they rely on the assumption that the provided values\nare in sorted order. Statement II is false since these methods take in input iterators, and statement III is false because the two provided\niterator ranges can be of different sizes (what happens to any extra values in the larger iterator range depends on the method called).", "answer_embedding": null, "answer_confidence": null, "page_ids": ["7b7d9dc6-5cd7-52df-b66e-d4548821bf99", "8c8f8242-6e2b-563a-af29-ebd95912031a", "9b0d4dd4-86c3-518e-a300-140b5431246b", "a732e97e-0ac4-53d2-b683-2ca489c035d6", "eeb12615-da5e-5489-a593-75fa07932e2c", "f6099dd1-8ca5-5a05-8f00-ca473fc97adc"]}, {"id": null, "qa_id": "0be54f59-7cc4-5c78-be67-22245566eca3", "book_id": "47bbcc23-9276-5662-9e40-96e8a4841ec7", "section_labels": ["practice", "solutions"], "section_titles": ["Exercise Solutions", "Practice Exercises"], "pdf_page": 453, "problem_key": "4", "answer_number": 4, "answer_choice": "D", "answer_text": "Option A is false because bubble sort can be implemented to be both adaptive and stable (see section 14.2 for\nthis exact implementation). Option B is false because insertion sort can be done in-place without any additional auxiliary space. Option C\nÎ˜(ğ‘›2)is false because selection will still need to perform comparisons, regardless of what the input is (for this reason, option D is true,\nsince these comparisons represent a majority of the work done while running a selection sort).", "answer_embedding": null, "answer_confidence": null, "page_ids": ["5b3eb61a-78ca-5ab0-a3f1-002ac1c1cff4", "7b7d9dc6-5cd7-52df-b66e-d4548821bf99", "8c8f8242-6e2b-563a-af29-ebd95912031a", "9b0d4dd4-86c3-518e-a300-140b5431246b", "a732e97e-0ac4-53d2-b683-2ca489c035d6", "eeb12615-da5e-5489-a593-75fa07932e2c", "f6099dd1-8ca5-5a05-8f00-ca473fc97adc"]}, {"id": null, "qa_id": "0be54f59-7cc4-5c78-be67-22245566eca3", "book_id": "47bbcc23-9276-5662-9e40-96e8a4841ec7", "section_labels": ["practice", "solutions"], "section_titles": ["Exercise Solutions", "Practice Exercises"], "pdf_page": 491, "problem_key": "4", "answer_number": 4, "answer_choice": "C", "answer_text": "Finding a given value in a sorted array takes time due to binary search, but removing any elementÎ˜(log(ğ‘›))\nmay take up to in an array (since elements may need to be shifted after the removal point). The cost of removal is dominant, so theÎ˜(ğ‘›)\noverall time complexity of finding and removing any element ends up being Î˜(ğ‘›).", "answer_embedding": null, "answer_confidence": null, "page_ids": ["5b3eb61a-78ca-5ab0-a3f1-002ac1c1cff4", "7b7d9dc6-5cd7-52df-b66e-d4548821bf99", "8c8f8242-6e2b-563a-af29-ebd95912031a", "9b0d4dd4-86c3-518e-a300-140b5431246b", "a732e97e-0ac4-53d2-b683-2ca489c035d6", "eeb12615-da5e-5489-a593-75fa07932e2c", "f0f93193-dc46-5ba5-9f4d-77717945d193", "f6099dd1-8ca5-5a05-8f00-ca473fc97adc"]}, {"id": null, "qa_id": "0be54f59-7cc4-5c78-be67-22245566eca3", "book_id": "47bbcc23-9276-5662-9e40-96e8a4841ec7", "section_labels": ["practice", "solutions"], "section_titles": ["Exercise Solutions", "Practice Exercises"], "pdf_page": 530, "problem_key": "4", "answer_number": 4, "answer_choice": "A", "answer_text": "If you want to find an input range ğ´within another sequence ğµ, then you would never be able to find ğ´\nstd::equal()in ğµif the length of ğµis smaller than ğ´. Thus, is guaranteed to return false if the input range you are searching for\n[first1, last1) first2).is larger than the container you are searching in (represented by\nstd::unique()5. The correct answer is (C). The function eliminates all but the first element from every consecutive group of equivalent\npizza really[first, last). str \"This iselements in the provided range Thus, the following five letters of are removed:\ngood!!!\".\na1 a2.6. The correct answer is (D). The loop on line 4 reverses the contents of and inserts them into Therefore, when the loop completes its\na2 {'1', '2', 'F', '\\0', '7', '3', 'S', 'C', 'E', 'E'}. a2last iteration, the contents of are Printing would read\n'\\0', \"12F\".every character up to the first sentinel character so the output would be", "answer_embedding": null, "answer_confidence": null, "page_ids": ["5b3eb61a-78ca-5ab0-a3f1-002ac1c1cff4", "7b7d9dc6-5cd7-52df-b66e-d4548821bf99", "862d47c5-75db-5446-8ee5-19e543dc5181", "8c8f8242-6e2b-563a-af29-ebd95912031a", "9b0d4dd4-86c3-518e-a300-140b5431246b", "a732e97e-0ac4-53d2-b683-2ca489c035d6", "eeb12615-da5e-5489-a593-75fa07932e2c", "f0f93193-dc46-5ba5-9f4d-77717945d193", "f6099dd1-8ca5-5a05-8f00-ca473fc97adc"]}, {"id": null, "qa_id": "0be54f59-7cc4-5c78-be67-22245566eca3", "book_id": "47bbcc23-9276-5662-9e40-96e8a4841ec7", "section_labels": ["practice", "solutions"], "section_titles": ["Exercise Solutions", "Practice Exercises"], "pdf_page": 587, "problem_key": "4", "answer_number": 4, "answer_choice": "C", "answer_text": "Using 17, 99, 83, and 41, we get the following:ğ‘¡= ğ‘˜ğ‘’ğ‘¦= ğ‘€==\nâŒŠ83âˆ’17â„(ğ‘˜ğ‘’ğ‘¦)=\nâŒŠ66Ã—41âŒ‹=99âˆ’17\n41Ã—41âŒ‹=âŒŠ66Ã—82\n182âŒ‹=âŒŠ66Ã—\n2âŒ‹=33", "answer_embedding": null, "answer_confidence": null, "page_ids": ["1a3da172-d383-5da8-b297-3fd5ea9024dc", "5b3eb61a-78ca-5ab0-a3f1-002ac1c1cff4", "7b7d9dc6-5cd7-52df-b66e-d4548821bf99", "862d47c5-75db-5446-8ee5-19e543dc5181", "8c8f8242-6e2b-563a-af29-ebd95912031a", "9b0d4dd4-86c3-518e-a300-140b5431246b", "a732e97e-0ac4-53d2-b683-2ca489c035d6", "eeb12615-da5e-5489-a593-75fa07932e2c", "f0f93193-dc46-5ba5-9f4d-77717945d193", "f6099dd1-8ca5-5a05-8f00-ca473fc97adc"]}, {"id": null, "qa_id": "0be54f59-7cc4-5c78-be67-22245566eca3", "book_id": "47bbcc23-9276-5662-9e40-96e8a4841ec7", "section_labels": ["practice", "solutions"], "section_titles": ["Exercise Solutions", "Practice Exercises"], "pdf_page": 689, "problem_key": "4", "answer_number": 4, "answer_choice": "E", "answer_text": "The worst-case of insert is for both cases. For an array-based tree, we could have to traverse the entireÎ˜(ğ‘›)\narray before we find an open position to insert the new element (and if the array was completely full, we would also need to reallocate). The\nsame applies for a pointer based tree; regardless of what algorithm you use to insert a new node into the tree, you could end up visiting\nnodes if you get unlucky and never find an open spot.Î˜(ğ‘›)\n2ğ‘›nodes,5. The correct answer is (C). The right child of the root is located at index 3. Since each additional row of the binary tree adds we\nwould keep on adding powers of two until we get an answer choice, which happens to be 31. In addition, the rightmost node of any row has\n2ğ‘›âˆ’1,an index of the form which can also be used to get 31.\n19.3 Depth-First Search\n707\nAll of vertex ğ´â€™s neighbors have now been visited. Since ğ´was the source node, the recursive depth-first search starting at vertex ğ´is\nnow complete, and we have successfully processed all vertices in the graph that are reachable from vertex ğ´. The order of branches we\nexplored during the recursive search was different from the branches we explored during the iterative search: we first explored the branch\nğ´â†’ğµâ†’ğ¶â†’ğ·, then we backtracked to vertex ğ¶and explored the branch ğ´â†’ğµâ†’ğ¶â†’ğ¸, then we backtracked to vertex ğ´and explored\nthe branch ğ´â†’ğ¹â†’ğºâ†’ğ»â†’ğ½â†’ğ¾â†’ğ¿, then we backtracked to vertex G and explored the branch ğ´â†’ğ¹â†’ğºâ†’ğ¼. This is because a\nrecursive call on a node automatically sets it as our current vertex.\nÂ¸ 19.3.3\nDepth-First Search Time Complexity\nWhat is the time complexity of a depth-first search? This depends on whether the underlying graph is represented as an adjacency list or an\nadjacency matrix. In an adjacency list, each vertex is only visited once, and we only have to traverse the neighbors of each vertex whendirect\nwe iterate through its vertex list. As a result, each edge in an adjacency list is visited at most once in a directed graph, and at most twice in an\nundirected graph (an undirected edge connecting two vertices ğ´and ğµis checked twice during the depth-first search: once when checking the\nneighbors of ğ´, and once when checking the neighbors of ğµ). Because each vertex and each edge is visited a constant number of times during a\nÎ˜(|ğ‘‰|+|ğ¸|).depth-first search, the overall time complexity of performing DFS on an adjacency list is worst-case On the other hand, traversing\n|ğ‘‰| Î˜(|ğ‘‰|)through the edges of a vertex in an adjacency requires us to iterate through vertices in its row. Since this process is donematrix all\nÎ˜(|ğ‘‰|2).|ğ‘‰| times, once for each vertex, the overall time complexity of performing DFS on an adjacency matrix is worst-case\nIn summary, depth-first searches provide a method for traversing over all of the vertices in a graph reachable from a given source vertex. If\nyou recall from the previous chapter, trees themselves are a special type of graph. Thus, the preorder, inorder, and postorder traversals are\nactually variants of a depth-first search on a tree, since they rely on a recursive stack to explore the nodes of a tree. The idea of depth-first\nsearch actually appears in many different types of problems, and it will show up again in the future when we discuss algorithm families such as\nbacktracking and branch and bound.\nGraph Representation\nAdjacency List\nAdjacency Matrix\nDFS Time Complexity\nÎ˜(|ğ‘‰|+|ğ¸|)\nÎ˜(|ğ‘‰|2)\nÂ¸ 19.3.4\nSolving Problems Using Depth-First Search\nExample 19.12 You are given an unweighted, undirected graph in the form of an adjacency list (where ğ‘›vertices are labeled from 0 to\nğ‘›âˆ’1) and two vertices: a source and a destination. Write a function that returns all possible paths from the source vertex to the destination\nthat visits a vertex at most once (i.e., no cycles), in any order. The function header is shown below:\nstd::vector<std::vector<int32_t>> find_all_paths(const std::vector<std::vector<int32_t>>& graph,\nint32_t int32_tsource, dest);\nExample: Given the following graph:\n0\n1\n2\n3\n4\n0\n1\n2\n3\n4\n1\n2\n3\n0\n4\n0\n3\n4\n0\n2\n4\n1\n2\n3\nyou should return the following paths, in any order:\n[[0, 1, 4, 2, 3], [0, 1, 4, 3], [0, 2, 3], [0, 2, 4, 3], [0, 3]]\nThis is a graph search problem, so we can solve it by performing a depth-first search. We will start with the source node and begin our search,\nkeeping track of our current path in a vector. If the destination is ever reached, we push the contents of this path into our solution vector. Since\nthe graph is undirected and we want to avoid cycles, we must mark vertices in our current path as so that we do not end up in a cycle. Anvisited\nillustration of this process is shown below. We start at vertex 0, our source vertex, and make a recursive call on each of its adjacent vertices (1, 2,\nand 3). We will start by recursing on vertex 1, which pushes it into the call stack. We then mark vertex 1 as visited and add it to our path.\n0\n1\n2\n3\n4\n1\nStack\n0\n1\nPath\nSolutions:\n708\nChapter 19. Graphs and Elementary Graph Algorithms\nWe then make a recursive call on each of 1â€™s unvisited adjacent vertices. In this case, the only unvisited neighbor is 4, so we make a recursive\ncall on 4, which pushes it into the call stack. We then mark vertex 4 as visited and add it to our path.\n0\n1\n2\n3\n4\n1\n4\nStack\n0\n1\n4\nPath\nSolutions:\nWe then make a recursive call on each of 4â€™s unvisited vertices. In this case, the unvisited neighbors are 2 and 3. We will first make a recursive\ncall on 2, which pushes it into the call stack. We then mark vertex 2 as visited and add it to our path.\n0\n1\n2\n3\n4\n1\n4\n2\nStack\n0\n1\n4\n2\nPath\nSolutions:\nWe then make a recursive call on each of 2â€™s unvisited vertices. In this case, the only unvisited neighbor is 3, which is our destination vertex. As\na result, we can add 3 to our path and append it to our list of solutions.\n0\n1\n2\n3\n4\n1\n4\n2\n3\nStack\n0\n1\n4\n2\n3\nPath\nSolutions:\n[0, 1, 4, 2, 3]\nWe have finished processing all of 2â€™s unvisited neighbors, so the recursion unrolls back to vertex 4. We then consider 4â€™s other unvisited\nneighbor, which happens to be 3, our destination vertex. As a result, we can also this path to our list of solutions.\n0\n1\n2\n3\n4\n1\n4\n3\nStack\n0\n1\n4\n3\nPath\nSolutions:\n[0, 1, 4, 2, 3]\n[0, 1, 4, 3]\nWe have finished processing all of 4â€™s unvisited neighbors, so the recursion unrolls back to vertex 1. Additionally, since 4 was 1â€™s only unvisited\nneighbor, the recursion unrolls back to vertex 0. We now make a recursive call on 0â€™s next unvisited neighbor of 2, which pushes it into the call\nstack. We then mark vertex 2 as visited and add it to our path.\n0\n1\n2\n3\n4\n2\nStack\n0\n2\nPath\nSolutions:\n[0, 1, 4, 2, 3]\n[0, 1, 4, 3]\nWe then make a recursive call on each of 2â€™s unvisited vertices, which are 3 and 4. Since 3 is our destination, we can add this path to our solution.\n0\n1\n2\n3\n4\n2\n3\nStack\n0\n2\n3\nPath\nSolutions:\n[0, 1, 4, 2, 3]\n[0, 1, 4, 3]\n[0, 2, 3]\nWe then process 2â€™s unvisited vertex of 4. Recursing into vertex 4 gives us the following path, which we add to our solution (note that we also\nrecurse into vertex 1 after recursing into vertex 4, but that search does not lead to our destination vertex, so nothing gets added to the solution\nalong that search path).\n0\n1\n2\n3\n4\n2\n4\n3\nStack\n0\n2\n4\n3\nPath\nSolutions:\n[0, 1, 4, 2, 3]\n[0, 1, 4, 3]\n[0, 2, 3]\n[0, 2, 4, 3]\n19.3 Depth-First Search\n709\nThe recursion then unrolls back to vertex 0. The last neighbor of 0 we have yet to consider is vertex 3, which is our destination vertex. We\ntherefore add this path to our solution. Since we have searched every neighbor of the source vertex, our algorithm is now complete, and our\nsolutions vector holds all the valid paths from the source to the destination.\n0\n1\n2\n3\n4\n3\nStack\n0\n3\nPath\nSolutions:\n[0, 1, 4, 2, 3]\n[0, 1, 4, 3]\n[0, 2, 3]\n[0, 2, 4, 3]\n[0, 3]\nAn implementation of this solution is shown below:\n1\nvoid find_all_paths_helper(const std::vector<std::vector<int32_t>>& graph,\n2\nint32_t int32_t std::vector<bool>&curr, dest, visited,\n3\nstd::vector<int32_t>& current_path,\n4\nstd::vector<std::vector<int32_t>>& solution) {\n5\ntrue;visited[curr] =\n6\ncurrent_path.push_back(curr);\n7\n8\nif (curr == dest) {\n9\n// we have reached the destination vertex, so append the current path to the solution\n10\nsolution.push_back(current_path);\n11\n} // if\n12\nelse {\n13\n// recurse into all adjacent vertices that are not visited\n14\nconst std::vector<int32_t>& neighbors = graph[curr];\n15\nfor (int32_t neighbor : neighbors) {\n16\nif (!visited[neighbor]) {\n17\nfind_all_paths_helper(graph, neighbor, dest, visited, current_path, solution);\n18\n} // if\n19\n} // for i\n20\n} // else\n21\n22\n// once you are done processing current vertex, remove it from path and mark it as unvisited\n23\ncurrent_path.pop_back();\n24\nfalse;visited[curr] =\n25\n} // find_all_paths_helper()\n26\n27\nstd::vector<std::vector<int32_t>> find_all_paths(const std::vector<std::vector<int32_t>>& graph,\n28\nint32_t int32_tsource, dest) {\n29\nstd::vector<bool> false);visited(graph.size(),\n30\nstd::vector<int32_t> current_path;\n31\nstd::vector<std::vector<int32_t>> solution;\n32\nfind_all_paths_helper(graph, source, dest, visited, current_path, solution);\n33\nreturn solution;\n34\n} // find_all_paths()\nExample 19.13 You are given ğ‘›devices. Some of these devices are connected, while some are not. If device ğ‘‹is directly connected to\ndevice ğ‘Œ, and device ğ‘Œis directly connected to device ğ‘, then device ğ‘‹is connected to device ğ‘.indirectly\nA network is a group of directly or indirectly connected devices. Two devices are a part of different networks if they are not connected in\nany manner, neither directly nor indirectly.\nğ‘–th ğ‘—thdevices, devices[i][j] = trueYou are given an ğ‘›Ã—ğ‘›adjacency matrix where if the and devices are directly connected,\ndevices[i][j] = false devices[i][i] = falseand otherwise. You may assume that without self loops. Implement the\nnum_devices() function, which returns the total number of networks that exist among the devices.\nint32_t num_devices(std::vector<std::vector<bool>>& devices);\nnum_devices()Example: Given the following devices, the function would return 3, since there exist three networks among these\ndevices (ğ´-ğ¶, ğ·-ğ¸, and ğ¹-ğ¼).\nA\nB\nC\nD\nE\nF\nG\nH\nI\n19.8 Algorithms for Articulation Points and Bridges\n759\nChapter 19 Exercise Solutions", "answer_embedding": null, "answer_confidence": null, "page_ids": ["1a3da172-d383-5da8-b297-3fd5ea9024dc", "5b3eb61a-78ca-5ab0-a3f1-002ac1c1cff4", "7b7d9dc6-5cd7-52df-b66e-d4548821bf99", "862d47c5-75db-5446-8ee5-19e543dc5181", "8c8f8242-6e2b-563a-af29-ebd95912031a", "942883f1-20a5-56b3-a5e0-a9ffafda687c", "9b0d4dd4-86c3-518e-a300-140b5431246b", "a732e97e-0ac4-53d2-b683-2ca489c035d6", "eeb12615-da5e-5489-a593-75fa07932e2c", "f0f93193-dc46-5ba5-9f4d-77717945d193", "f6099dd1-8ca5-5a05-8f00-ca473fc97adc"]}, {"id": null, "qa_id": "0be54f59-7cc4-5c78-be67-22245566eca3", "book_id": "47bbcc23-9276-5662-9e40-96e8a4841ec7", "section_labels": ["practice", "solutions"], "section_titles": ["Exercise Solutions", "Practice Exercises"], "pdf_page": 771, "problem_key": "4", "answer_number": 4, "answer_choice": "C", "answer_text": "Friends on Facebook are bidirectional: being friends with someone on Facebook means that the other person\nmust also be friends with you. Thus, a graph representing Facebookd friends is undirected. On the other hand, Twitter followers have a\n\"direction\": you can follow someone without forcing them to follow you back. Because instances exist where one person may be connected\nto another person but not the other way around, this graph is directed.", "answer_embedding": null, "answer_confidence": null, "page_ids": ["1a3da172-d383-5da8-b297-3fd5ea9024dc", "5b3eb61a-78ca-5ab0-a3f1-002ac1c1cff4", "7b7d9dc6-5cd7-52df-b66e-d4548821bf99", "862d47c5-75db-5446-8ee5-19e543dc5181", "8c8f8242-6e2b-563a-af29-ebd95912031a", "942883f1-20a5-56b3-a5e0-a9ffafda687c", "9b0d4dd4-86c3-518e-a300-140b5431246b", "a33ee040-cb9d-5bce-8fe4-7a2149f54fc9", "a732e97e-0ac4-53d2-b683-2ca489c035d6", "eeb12615-da5e-5489-a593-75fa07932e2c", "f0f93193-dc46-5ba5-9f4d-77717945d193", "f6099dd1-8ca5-5a05-8f00-ca473fc97adc"]}, {"id": null, "qa_id": "0be54f59-7cc4-5c78-be67-22245566eca3", "book_id": "47bbcc23-9276-5662-9e40-96e8a4841ec7", "section_labels": ["practice", "solutions"], "section_titles": ["Exercise Solutions", "Practice Exercises"], "pdf_page": 793, "problem_key": "4", "answer_number": 4, "answer_choice": "E", "answer_text": "Vertex ğ¸is added last. The process is shown below:", "answer_embedding": null, "answer_confidence": null, "page_ids": ["1a3da172-d383-5da8-b297-3fd5ea9024dc", "5b3eb61a-78ca-5ab0-a3f1-002ac1c1cff4", "7b7d9dc6-5cd7-52df-b66e-d4548821bf99", "862d47c5-75db-5446-8ee5-19e543dc5181", "8c8f8242-6e2b-563a-af29-ebd95912031a", "942883f1-20a5-56b3-a5e0-a9ffafda687c", "9801d2c0-b83e-52f9-b703-56eeba030479", "9b0d4dd4-86c3-518e-a300-140b5431246b", "a33ee040-cb9d-5bce-8fe4-7a2149f54fc9", "a732e97e-0ac4-53d2-b683-2ca489c035d6", "eeb12615-da5e-5489-a593-75fa07932e2c", "f0f93193-dc46-5ba5-9f4d-77717945d193", "f6099dd1-8ca5-5a05-8f00-ca473fc97adc"]}, {"id": null, "qa_id": "0be54f59-7cc4-5c78-be67-22245566eca3", "book_id": "47bbcc23-9276-5662-9e40-96e8a4841ec7", "section_labels": ["practice", "solutions"], "section_titles": ["Exercise Solutions", "Practice Exercises"], "pdf_page": 826, "problem_key": "4", "answer_number": 4, "answer_choice": "C", "answer_text": "The denominations in I are the just the standard coin denominations in real life, which we proved can be solved\nusing a greedy approach in example 21.4. The denominations in II do not work for 24Â¢, since the greedy solution would return 4 coins (20Â¢,\n1Â¢, 1Â¢, 1Â¢) when the optimal solution is 3 coins (8Â¢, 8Â¢, 8Â¢). We can prove that III is optimal using the same exchange argument that we\nused to prove I: we know the number of 1Â¢ coins in our solution must be less than 3, since otherwise we can replace these coins with a\nsingle 3Â¢ coin. We also know that the number of 3Â¢ and 9Â¢ coins are each less than 3 as well, for the same reason. Using a proof by cases,\nwe can show that:\nâ€¢ If the amount of change is greater than 27Â¢, then the greedy choice adds this coin to the solution. If this is not optimal, there must be\na way to return a change amount above 27Â¢ without a 27Â¢ coin. This involves at least 3 coins worth of 9Â¢, 3Â¢, or 1Â¢ coins, which\nwould not be optimal.\nâ€¢ If the amount of change is between 9Â¢ and 26Â¢, then the greedy choice would be to add a 9Â¢ coin to our solution. If this is not optimal,\nthere must be a way to return this change amount without a 9Â¢ coin. This would require at least 3 coins worth of 3Â¢ or 1Â¢ coins,\nwhich would not be optimal.\nâ€¢ If the amount of change is between 3Â¢ and 9Â¢, then the greedy choice would be to add a 3Â¢ coin to our solution. If this is not optimal,\nthere must be a way to return this change amount without a 3Â¢ coin. This would require at least 3 coins worth of 1Â¢ coins, which\nwould not be optimal.\nIf the amount of change is less than 3Â¢, we only have one type of coin that can be used, which trivially implies that the optimalâ€¢\nsolution must contain this coin.", "answer_embedding": null, "answer_confidence": null, "page_ids": ["1a3da172-d383-5da8-b297-3fd5ea9024dc", "5b3eb61a-78ca-5ab0-a3f1-002ac1c1cff4", "7b7d9dc6-5cd7-52df-b66e-d4548821bf99", "862d47c5-75db-5446-8ee5-19e543dc5181", "8c8f8242-6e2b-563a-af29-ebd95912031a", "942883f1-20a5-56b3-a5e0-a9ffafda687c", "9801d2c0-b83e-52f9-b703-56eeba030479", "9b0d4dd4-86c3-518e-a300-140b5431246b", "a33ee040-cb9d-5bce-8fe4-7a2149f54fc9", "a732e97e-0ac4-53d2-b683-2ca489c035d6", "a8bd50a1-a8c7-5431-824f-b2983d36f1ed", "eeb12615-da5e-5489-a593-75fa07932e2c", "f0f93193-dc46-5ba5-9f4d-77717945d193", "f6099dd1-8ca5-5a05-8f00-ca473fc97adc"]}, {"id": null, "qa_id": "0be54f59-7cc4-5c78-be67-22245566eca3", "book_id": "47bbcc23-9276-5662-9e40-96e8a4841ec7", "section_labels": ["practice", "solutions"], "section_titles": ["Exercise Solutions", "Practice Exercises"], "pdf_page": 873, "problem_key": "4", "answer_number": 4, "answer_choice": "E", "answer_text": "The upper bound is the best complete solution encountered so far. Similar to the explanation for the previous\nproblem, knowing the weight of the MST only allows you to identify whether to continue exploring the branch or not, but you should not\nupdate the upper bound until you compute the weight of a complete solution that is better than the best solution you have encountered so far.", "answer_embedding": null, "answer_confidence": null, "page_ids": ["1a3da172-d383-5da8-b297-3fd5ea9024dc", "5b3eb61a-78ca-5ab0-a3f1-002ac1c1cff4", "7b7d9dc6-5cd7-52df-b66e-d4548821bf99", "862d47c5-75db-5446-8ee5-19e543dc5181", "8c8f8242-6e2b-563a-af29-ebd95912031a", "942883f1-20a5-56b3-a5e0-a9ffafda687c", "9801d2c0-b83e-52f9-b703-56eeba030479", "9b0d4dd4-86c3-518e-a300-140b5431246b", "a33ee040-cb9d-5bce-8fe4-7a2149f54fc9", "a732e97e-0ac4-53d2-b683-2ca489c035d6", "a8bd50a1-a8c7-5431-824f-b2983d36f1ed", "e07bc6fe-0bb9-5892-9565-a839b6bcff01", "eeb12615-da5e-5489-a593-75fa07932e2c", "f0f93193-dc46-5ba5-9f4d-77717945d193", "f6099dd1-8ca5-5a05-8f00-ca473fc97adc"]}, {"id": null, "qa_id": "0be54f59-7cc4-5c78-be67-22245566eca3", "book_id": "47bbcc23-9276-5662-9e40-96e8a4841ec7", "section_labels": ["practice", "solutions"], "section_titles": ["Exercise Solutions", "Practice Exercises"], "pdf_page": 931, "problem_key": "4", "answer_number": 4, "answer_choice": "D", "answer_text": "If we use dynamic programming, the worst-case time complexity becomes Î˜(ğ‘›ğ‘˜), because there are ğ‘›ğ‘˜\nsubproblems we may have to solve (for each possible combination of ğ‘›and ğ‘˜), and solving for each subproblem takes constant time. See\nsection 23.1.4 for more detail.\nğ‘›th5. The correct answer is (B). In this example, for every additional person that goes to the event, there are two options that are possible:\nğ‘›th ğ‘›thâ€¢ This person remains single. How many ways can this occur? Because this person does not pair up with any of the other ğ‘›âˆ’1\nğ‘›thpeople, the total number of ways this can happen is exactly the same as the number of ways without this person present, or the\nnumber of ways people can remain single or paired up. If denotes the number of ways ğ‘›people can pair up, there are ağ‘›âˆ’1 ğ‘“(ğ‘›)\nğ‘›thtotal of pairing combinations possible if the person remains single.ğ‘“(ğ‘›âˆ’1)\nğ‘›th ğ‘›thâ€¢ This person pairs up with someone. How many ways can this occur? There are ways the person can pair up, one forğ‘›âˆ’1\nğ‘›theach of the other people present (i.e., the person has people to choose from). Now what about the people thatğ‘›âˆ’1 ğ‘›âˆ’1 ğ‘›âˆ’2\nğ‘›tharenâ€™t paired up with the person? The number of ways that these people can pair up is equal to the total number of ways that ğ‘›âˆ’2\npeople can remain single or pair up. Thus, if represents the number of ways that people can pair up, and for each ofğ‘“(ğ‘›âˆ’2) ğ‘›âˆ’2\nğ‘›ththese ways there are ways an additional person can pair up, the total number of pairing combinations possible if the personğ‘›âˆ’1\npairs up is the product of these two values, or (ğ‘›âˆ’1)Ã—ğ‘“(ğ‘›âˆ’2).\nThis problem involves overlapping subproblems (the number of ways ğ‘›people can pair up is dependent on the number of ways peopleğ‘›âˆ’1\ncan pair up, and so on), so we can use dynamic programming. Here, our recurrence relation is\nğ‘“(ğ‘›) ğ‘“(ğ‘›âˆ’1)+(ğ‘›âˆ’1)Ã—ğ‘“(ğ‘›âˆ’2)=\nğ‘›thwhere the number of ways to organize ğ‘›people is equal to the number of ways to organize people (if the person remains single)ğ‘›âˆ’1\nğ‘›thadded to the number of ways to organize people after pairing up the person with someone else. We would store the number ofğ‘›âˆ’2\npairing combinations possible for all values from 1 to ğ‘›, which can be done with a single array. As a result, since we are storing and\ntraversing through a single one-dimensional array with ğ‘›values, this algorithm has a time complexity of Î˜(ğ‘›).\n6. Thecorrectansweris(C).Thetotalnumberofcoincombinationsthatsumtoagivenvalueğ‘˜whengivencoindenominations[ğ‘–1,ğ‘–2,â€¦,ğ‘–ğ‘›]\ncan be computed by adding the number of coin combinations that sum to ğ‘˜âˆ’ğ‘–1, with the number of combinations that sum to ğ‘˜âˆ’ğ‘–2, â€¦,\nwith the number of combinations that sum to ğ‘˜âˆ’ğ‘–ğ‘›. Thus, the total number of subproblems we need to solve is Î˜(ğ‘›ğ‘˜), since we would have\nto add together values for all possible sums from 0 to ğ‘˜. One possible bottom-up solution for this problem is shown below:Î˜(ğ‘›)\n1\nint32_t num_combinations(int32_t const std::vector<int32_t>&target, denominations) {\n2\nstd::vector<int32_t> memo(target + 1);\n3\nmemo[0] = 1;\n// one way to make amount zero (with no coins)\n4\nfor (int32_t denom : denominations) {\n5\nfor (size_t i = denom; i < memo.size(); ++i) {\n6\nmemo[i] += memo[i - denom];\n// add ways to make amount i - denom\n7\n} // for i\n8\n} // for denom\n9\nreturn memo[target];\n10\n} // num_combinations()", "answer_embedding": null, "answer_confidence": null, "page_ids": ["1a3da172-d383-5da8-b297-3fd5ea9024dc", "2afd0c50-ab9c-5b1e-acab-c7e93b22bf80", "5b3eb61a-78ca-5ab0-a3f1-002ac1c1cff4", "7b7d9dc6-5cd7-52df-b66e-d4548821bf99", "862d47c5-75db-5446-8ee5-19e543dc5181", "8c8f8242-6e2b-563a-af29-ebd95912031a", "942883f1-20a5-56b3-a5e0-a9ffafda687c", "9801d2c0-b83e-52f9-b703-56eeba030479", "9b0d4dd4-86c3-518e-a300-140b5431246b", "a33ee040-cb9d-5bce-8fe4-7a2149f54fc9", "a732e97e-0ac4-53d2-b683-2ca489c035d6", "a8bd50a1-a8c7-5431-824f-b2983d36f1ed", "e07bc6fe-0bb9-5892-9565-a839b6bcff01", "eeb12615-da5e-5489-a593-75fa07932e2c", "f0f93193-dc46-5ba5-9f4d-77717945d193", "f6099dd1-8ca5-5a05-8f00-ca473fc97adc"]}, {"id": null, "qa_id": "0be54f59-7cc4-5c78-be67-22245566eca3", "book_id": "47bbcc23-9276-5662-9e40-96e8a4841ec7", "section_labels": ["practice", "solutions"], "section_titles": ["Exercise Solutions", "Practice Exercises"], "pdf_page": 958, "problem_key": "4", "answer_number": 4, "answer_choice": "A", "answer_text": "The purpose of estimating an upper bound is to quickly get a close enough answer to make the actual branch\nand bound process more efficient. Dynamic programming and brute force actually obtain the correct answer, so they shouldnâ€™t be used to\nestimate the upper bound (otherwise there is no point in actually running branch and bound after computing the initial upper bound).", "answer_embedding": null, "answer_confidence": null, "page_ids": ["1a3da172-d383-5da8-b297-3fd5ea9024dc", "2afd0c50-ab9c-5b1e-acab-c7e93b22bf80", "5b3eb61a-78ca-5ab0-a3f1-002ac1c1cff4", "7b7d9dc6-5cd7-52df-b66e-d4548821bf99", "862d47c5-75db-5446-8ee5-19e543dc5181", "8c8f8242-6e2b-563a-af29-ebd95912031a", "942883f1-20a5-56b3-a5e0-a9ffafda687c", "9801d2c0-b83e-52f9-b703-56eeba030479", "9b0d4dd4-86c3-518e-a300-140b5431246b", "a33ee040-cb9d-5bce-8fe4-7a2149f54fc9", "a732e97e-0ac4-53d2-b683-2ca489c035d6", "a8bd50a1-a8c7-5431-824f-b2983d36f1ed", "e07bc6fe-0bb9-5892-9565-a839b6bcff01", "eeb12615-da5e-5489-a593-75fa07932e2c", "f0f93193-dc46-5ba5-9f4d-77717945d193", "f5d6b0c4-2db1-5173-8428-b1cf083e7cc4", "f6099dd1-8ca5-5a05-8f00-ca473fc97adc"]}, {"id": null, "qa_id": "0be54f59-7cc4-5c78-be67-22245566eca3", "book_id": "47bbcc23-9276-5662-9e40-96e8a4841ec7", "section_labels": ["practice", "solutions"], "section_titles": ["Exercise Solutions", "Practice Exercises"], "pdf_page": 994, "problem_key": "4", "answer_number": 4, "answer_choice": "A", "answer_text": "This statement is true, since Dijkstraâ€™s algorithm is not guaranteed to work on graphs with negative edge\nweights. This is because Dijkstraâ€™s correctness rests on the assumption that after the shortest path to a vertex is discovered, it is not possible\nfor another path to have a better weight. However, once negative edges are introduced, this guarantee no longer holds, and it becomes\npossible for an unencountered negative edge to give us a better solution.", "answer_embedding": null, "answer_confidence": null, "page_ids": ["1a3da172-d383-5da8-b297-3fd5ea9024dc", "2afd0c50-ab9c-5b1e-acab-c7e93b22bf80", "5b3eb61a-78ca-5ab0-a3f1-002ac1c1cff4", "7b25559a-771c-5789-849e-761231306ccf", "7b7d9dc6-5cd7-52df-b66e-d4548821bf99", "862d47c5-75db-5446-8ee5-19e543dc5181", "8c8f8242-6e2b-563a-af29-ebd95912031a", "942883f1-20a5-56b3-a5e0-a9ffafda687c", "9801d2c0-b83e-52f9-b703-56eeba030479", "9b0d4dd4-86c3-518e-a300-140b5431246b", "a33ee040-cb9d-5bce-8fe4-7a2149f54fc9", "a732e97e-0ac4-53d2-b683-2ca489c035d6", "a8bd50a1-a8c7-5431-824f-b2983d36f1ed", "e07bc6fe-0bb9-5892-9565-a839b6bcff01", "eeb12615-da5e-5489-a593-75fa07932e2c", "f0f93193-dc46-5ba5-9f4d-77717945d193", "f5d6b0c4-2db1-5173-8428-b1cf083e7cc4", "f6099dd1-8ca5-5a05-8f00-ca473fc97adc"]}, {"id": null, "qa_id": "0be54f59-7cc4-5c78-be67-22245566eca3", "book_id": "47bbcc23-9276-5662-9e40-96e8a4841ec7", "section_labels": ["practice", "solutions"], "section_titles": ["Exercise Solutions", "Practice Exercises"], "pdf_page": 1053, "problem_key": "4", "answer_number": 4, "answer_choice": "D", "answer_text": "This problem can be solved using the sweep-line algorithm, where we scan over the line segments in ascending\norder of ğ‘¥-coordinate and check for intersections (the same algorithm described on section 26.2.2), with the added check of ensuring that\nthe intersection falls within with a disk (determining whether a point lies within a circle is a constant-time calculation). The time complexity\nof running the sweep-line algorithm optimally is Î˜(ğ‘›log(ğ‘›)).", "answer_embedding": null, "answer_confidence": null, "page_ids": ["1a3da172-d383-5da8-b297-3fd5ea9024dc", "2afd0c50-ab9c-5b1e-acab-c7e93b22bf80", "5b3eb61a-78ca-5ab0-a3f1-002ac1c1cff4", "6275fd1a-cffc-5d55-9e15-840a57b06dcd", "7b25559a-771c-5789-849e-761231306ccf", "7b7d9dc6-5cd7-52df-b66e-d4548821bf99", "862d47c5-75db-5446-8ee5-19e543dc5181", "8c8f8242-6e2b-563a-af29-ebd95912031a", "942883f1-20a5-56b3-a5e0-a9ffafda687c", "9801d2c0-b83e-52f9-b703-56eeba030479", "9b0d4dd4-86c3-518e-a300-140b5431246b", "a33ee040-cb9d-5bce-8fe4-7a2149f54fc9", "a732e97e-0ac4-53d2-b683-2ca489c035d6", "a8bd50a1-a8c7-5431-824f-b2983d36f1ed", "e07bc6fe-0bb9-5892-9565-a839b6bcff01", "eeb12615-da5e-5489-a593-75fa07932e2c", "f0f93193-dc46-5ba5-9f4d-77717945d193", "f5d6b0c4-2db1-5173-8428-b1cf083e7cc4", "f6099dd1-8ca5-5a05-8f00-ca473fc97adc"]}]}
{"type": "matched_pair", "qa_id": "3e183fa5-9dfe-5a58-b35f-038f1ba7322d", "question": {"id": null, "qa_id": "3e183fa5-9dfe-5a58-b35f-038f1ba7322d", "book_id": "47bbcc23-9276-5662-9e40-96e8a4841ec7", "section_labels": ["practice", "solutions"], "section_titles": ["Exercise Solutions", "Practice Exercises"], "pdf_page": 989, "problem_key": "6", "question_number": 6, "question_text": "You work for the food delivery startup DoorHash, and you need to deliver orders to a customer on the other side of town. You are given\n|ğ‘‰| |ğ¸|two undirected graphs with vertices and non-negative edges that represent the network of roads in your town. In both graphs, the\nvertices represent road intersections and the edges represent roads that connect these intersections. However, in the first graph, the edges\nare weighted by the total walking time between two intersections, while in the second graph, the edges are weighted by the total driving\ntime between two intersections. The two graphs share the same connections between intersections, with the only difference being the edge\nweights (due to differences in time between walking and driving). You want to find the path between your starting point and the intersection\nclosest to the destination house where the difference between total walking time and driving time is the greatest. Can you use Dijkstraâ€™s\nalgorithm to solve this problem, and if so, what is the time complexity if you use the most optimal data structures?\nÎ˜(|ğ‘‰|)A) Yes, you can use Dijkstraâ€™s algorithm with time complexity\nÎ˜(|ğ¸|log(|ğ‘‰|))B) Yes, you can use Dijkstraâ€™s algorithm with time complexity\nÎ˜(|ğ‘‰|2)C) Yes, you can use Dijkstraâ€™s algorithm with time complexity\nÎ˜(|ğ‘‰||ğ¸|log(|ğ‘‰|)D) Yes, you can use Dijkstraâ€™s algorithm with time complexity\nE) No, this problem cannot be solved with Dijkstraâ€™s algorithm\n|ğ‘‰|7. You are an engineer at an utility company tasked with analyzing substations on a power grid. You are given a directed graph with\n|ğ¸|vertices and non-negative edges, where each vertex represents a substation and each edge represents a transmission line that connects\ntwo substations. The edges in the graph are weighted by the percentage loss in signal strength that occurs when power travels between two\nsubstations (where a lower weight indicates lower loss). If every substation in the graph is connected to nearly every other substation, what\nis the time complexity of finding the minimum-loss path between two substations if you use Dijkstraâ€™s algorithm with the most optimal data\nstructures?\nÎ˜(|ğ‘‰|)A)\nÎ˜(|ğ¸|log(|ğ‘‰|))B)\nÎ˜(|ğ‘‰|2)C)\nÎ˜(|ğ‘‰||ğ¸|log(|ğ‘‰|)D)\nÎ˜(|ğ‘‰|3)E)\n1038\nChapter 26. Computational Geometry\nChapter 26 Practice Exercises\nDisclaimer: These practice questions are not official and may not have been vetted for course material. You may use these for practice, but\nyou should prioritize official resources from current staff for a more accurate depiction of what you need to know for assignments and exams.", "question_embedding": null, "page_ids": ["2207e17c-289e-5000-ace5-623e81db7b9b", "5b3eb61a-78ca-5ab0-a3f1-002ac1c1cff4", "6275fd1a-cffc-5d55-9e15-840a57b06dcd", "6e773b9f-1cda-5ba9-8756-97b6e00119df", "7b25559a-771c-5789-849e-761231306ccf", "7b7d9dc6-5cd7-52df-b66e-d4548821bf99", "8cacf18e-1cee-53fd-a323-366ab7d7cf31", "9801d2c0-b83e-52f9-b703-56eeba030479", "9b0d4dd4-86c3-518e-a300-140b5431246b", "a33ee040-cb9d-5bce-8fe4-7a2149f54fc9", "a8bd50a1-a8c7-5431-824f-b2983d36f1ed", "e07bc6fe-0bb9-5892-9565-a839b6bcff01", "eeb12615-da5e-5489-a593-75fa07932e2c", "f6099dd1-8ca5-5a05-8f00-ca473fc97adc"]}, "answers": [{"id": null, "qa_id": "3e183fa5-9dfe-5a58-b35f-038f1ba7322d", "book_id": "47bbcc23-9276-5662-9e40-96e8a4841ec7", "section_labels": ["practice", "solutions"], "section_titles": ["Exercise Solutions", "Practice Exercises"], "pdf_page": 126, "problem_key": "6", "answer_number": 6, "answer_choice": "E", "answer_text": "Algorithms involving complexities often involve splitting work over and over again and doing a constantlog(ğ‘›)\nnumber of operations for each split. This is true for both (C) and (D).", "answer_embedding": null, "answer_confidence": null, "page_ids": ["8cacf18e-1cee-53fd-a323-366ab7d7cf31", "f6099dd1-8ca5-5a05-8f00-ca473fc97adc"]}, {"id": null, "qa_id": "3e183fa5-9dfe-5a58-b35f-038f1ba7322d", "book_id": "47bbcc23-9276-5662-9e40-96e8a4841ec7", "section_labels": ["practice", "solutions"], "section_titles": ["Exercise Solutions", "Practice Exercises"], "pdf_page": 188, "problem_key": "6", "answer_number": 6, "answer_choice": "D", "answer_text": "Copy-swap is a technique devised to implement the overloaded assignment operator by leveraging existing\nimplementations of the copy constructor and destructor. With copy swap, the assignment of one entity to another creates a copy of the\noriginal entity, swaps this object so that it becomes the object being assigned to, and deallocates the previous object.\nThe correct answer is (B). Statement (B) is true, since the user may be able to do anything with the data via the pointer without any7.\nknowledge of thecontainer that holds it. Statement (A) is false, since primitive types are easier to copy if they are stored by value (since they\nare more lightweight than copying a pointer, which is what passing by reference does behind the scenes â€” see section 1.2.2). Statement (C)\nis false, since data can be initialized and modified in a container of pointers. Statement (D) is false, since shared data is better stored as\npointers or references, so that all the parts of the program can access the same data (as opposed to storing by value, which requires a copy).", "answer_embedding": null, "answer_confidence": null, "page_ids": ["2207e17c-289e-5000-ace5-623e81db7b9b", "8cacf18e-1cee-53fd-a323-366ab7d7cf31", "f6099dd1-8ca5-5a05-8f00-ca473fc97adc"]}, {"id": null, "qa_id": "3e183fa5-9dfe-5a58-b35f-038f1ba7322d", "book_id": "47bbcc23-9276-5662-9e40-96e8a4841ec7", "section_labels": ["practice", "solutions"], "section_titles": ["Exercise Solutions", "Practice Exercises"], "pdf_page": 211, "problem_key": "6", "answer_number": 6, "answer_choice": "C", "answer_text": "The vector reallocates with double the capacity when you try to insert an element that exceeds its capacity.\nCurrently, the capacity is 16, so a reallocation is triggered when you insert the 17th element, which doubles the capacity to 32. The next\nreallocation happens when you try to insert the 33rd element, which doubles the capacity to 64. The next reallocation happens when you try\nto insert the 65th element, which doubles the capacity to 128 (and so on).", "answer_embedding": null, "answer_confidence": null, "page_ids": ["2207e17c-289e-5000-ace5-623e81db7b9b", "8cacf18e-1cee-53fd-a323-366ab7d7cf31", "eeb12615-da5e-5489-a593-75fa07932e2c", "f6099dd1-8ca5-5a05-8f00-ca473fc97adc"]}, {"id": null, "qa_id": "3e183fa5-9dfe-5a58-b35f-038f1ba7322d", "book_id": "47bbcc23-9276-5662-9e40-96e8a4841ec7", "section_labels": ["practice", "solutions"], "section_titles": ["Exercise Solutions", "Practice Exercises"], "pdf_page": 281, "problem_key": "6", "answer_number": 6, "answer_choice": "A", "answer_text": "You do not need any additional space to complete this process: simply pop off the front element and readd it to\nthe back of the queue. Continue doing this for elements before you reach the final element; at this point, you can take the element outğ‘›âˆ’1\nand the other elements will still be in their original order.", "answer_embedding": null, "answer_confidence": null, "page_ids": ["2207e17c-289e-5000-ace5-623e81db7b9b", "8cacf18e-1cee-53fd-a323-366ab7d7cf31", "9b0d4dd4-86c3-518e-a300-140b5431246b", "eeb12615-da5e-5489-a593-75fa07932e2c", "f6099dd1-8ca5-5a05-8f00-ca473fc97adc"]}, {"id": null, "qa_id": "3e183fa5-9dfe-5a58-b35f-038f1ba7322d", "book_id": "47bbcc23-9276-5662-9e40-96e8a4841ec7", "section_labels": ["practice", "solutions"], "section_titles": ["Exercise Solutions", "Practice Exercises"], "pdf_page": 400, "problem_key": "6", "answer_number": 6, "answer_choice": "A", "answer_text": "Unlike vectors, lists do not perform any reallocation when elements are inserted, and the doubly-linked nature\nstd::list<>of the ensures that the worst-case time complexity of pushing and popping is Î˜(1). It follows from this that the amortized\ntime complexities of these operations must also be Î˜(1), since running a sequence of ğ‘›pushes and pops will take at most time in total,Î˜(ğ‘›)\nresulting in an amortized complexity of Î˜(1).Î˜(ğ‘›)âˆ•ğ‘›=\n.pop() .push()7. (a) In the worst case, takes time since it is guaranteed to remove only one element from the stack, but takes Î˜(ğ‘›)Î˜(1)\ntime, since you may have to remove all the other elements in the stack if you push in a value that is lower than everything in the stack.\n(b) If we look at the lifetime of any element that enters and leaves the stack, the total cost associated with that element is at most 2 (1 to\npush into the stack, and 1 when it is popped out). Thus, for any sequence of ğ‘›pushes and pops, the total cost incurred cannot be greater\nthan 2ğ‘›. Thus, the amortized complexity of push and pop are (essentially, a more expensive push also gets rid of more2ğ‘›âˆ•ğ‘›= Î˜(1)\nelements from the stack, which makes future pushes less likely to be as costly, resulting in a constant amortized cost for each operation).\nYou can look at the queue with two stacks problem in section 12.5 for a similar example.\n408\nChapter 13. Sets and Union-Find\nChapter 13 Exercise Solutions", "answer_embedding": null, "answer_confidence": null, "page_ids": ["2207e17c-289e-5000-ace5-623e81db7b9b", "6e773b9f-1cda-5ba9-8756-97b6e00119df", "8cacf18e-1cee-53fd-a323-366ab7d7cf31", "9b0d4dd4-86c3-518e-a300-140b5431246b", "eeb12615-da5e-5489-a593-75fa07932e2c", "f6099dd1-8ca5-5a05-8f00-ca473fc97adc"]}, {"id": null, "qa_id": "3e183fa5-9dfe-5a58-b35f-038f1ba7322d", "book_id": "47bbcc23-9276-5662-9e40-96e8a4841ec7", "section_labels": ["practice", "solutions"], "section_titles": ["Exercise Solutions", "Practice Exercises"], "pdf_page": 420, "problem_key": "6", "answer_number": 6, "answer_choice": "B", "answer_text": "If every element in the data structure is forced to keep track of its ultimate representative, a single union call\nmay require elements to have their representatives updated. This is the \"quick-find\" implementation of union find, which allowsÎ˜(ğ‘›)\nfind_set() union_set()to be done in constant time at the expense of a more expensive call.", "answer_embedding": null, "answer_confidence": null, "page_ids": ["2207e17c-289e-5000-ace5-623e81db7b9b", "6e773b9f-1cda-5ba9-8756-97b6e00119df", "7b7d9dc6-5cd7-52df-b66e-d4548821bf99", "8cacf18e-1cee-53fd-a323-366ab7d7cf31", "9b0d4dd4-86c3-518e-a300-140b5431246b", "eeb12615-da5e-5489-a593-75fa07932e2c", "f6099dd1-8ca5-5a05-8f00-ca473fc97adc"]}, {"id": null, "qa_id": "3e183fa5-9dfe-5a58-b35f-038f1ba7322d", "book_id": "47bbcc23-9276-5662-9e40-96e8a4841ec7", "section_labels": ["practice", "solutions"], "section_titles": ["Exercise Solutions", "Practice Exercises"], "pdf_page": 453, "problem_key": "6", "answer_number": 6, "answer_choice": "D", "answer_text": "Non-adaptive sorting algorithms may be simpler to implement than adaptive algorithms, as they do not have to\nexhibit different behavior depending on the outcomes of comparisons. However, this inability to change their operations depending on the\ninput may cause them to run slower in special situations, such as sorting a nearly-sorted array.", "answer_embedding": null, "answer_confidence": null, "page_ids": ["2207e17c-289e-5000-ace5-623e81db7b9b", "5b3eb61a-78ca-5ab0-a3f1-002ac1c1cff4", "6e773b9f-1cda-5ba9-8756-97b6e00119df", "7b7d9dc6-5cd7-52df-b66e-d4548821bf99", "8cacf18e-1cee-53fd-a323-366ab7d7cf31", "9b0d4dd4-86c3-518e-a300-140b5431246b", "eeb12615-da5e-5489-a593-75fa07932e2c", "f6099dd1-8ca5-5a05-8f00-ca473fc97adc"]}, {"id": null, "qa_id": "3e183fa5-9dfe-5a58-b35f-038f1ba7322d", "book_id": "47bbcc23-9276-5662-9e40-96e8a4841ec7", "section_labels": ["practice", "solutions"], "section_titles": ["Exercise Solutions", "Practice Exercises"], "pdf_page": 771, "problem_key": "6", "answer_number": 6, "answer_choice": "A", "answer_text": "The number of vertices is on the order of the number of edges (ğ¸â‰ˆğ‘‰), so the graph is sparse, and an adjacency\nlist should be used.", "answer_embedding": null, "answer_confidence": null, "page_ids": ["2207e17c-289e-5000-ace5-623e81db7b9b", "5b3eb61a-78ca-5ab0-a3f1-002ac1c1cff4", "6e773b9f-1cda-5ba9-8756-97b6e00119df", "7b7d9dc6-5cd7-52df-b66e-d4548821bf99", "8cacf18e-1cee-53fd-a323-366ab7d7cf31", "9b0d4dd4-86c3-518e-a300-140b5431246b", "a33ee040-cb9d-5bce-8fe4-7a2149f54fc9", "eeb12615-da5e-5489-a593-75fa07932e2c", "f6099dd1-8ca5-5a05-8f00-ca473fc97adc"]}, {"id": null, "qa_id": "3e183fa5-9dfe-5a58-b35f-038f1ba7322d", "book_id": "47bbcc23-9276-5662-9e40-96e8a4841ec7", "section_labels": ["practice", "solutions"], "section_titles": ["Exercise Solutions", "Practice Exercises"], "pdf_page": 793, "problem_key": "6", "answer_number": 6, "answer_choice": "B", "answer_text": "In scenario I, increasing the weight of an edge in the MST makes the MST worse, so the MST may change if\nthere is another edge that can be used to replace the edge that was modified. In scenario II, decreasing the weight of an edge in the MST\nonly makes the MST better, so the MST would not change. In scenario III, increasing the weight of an edge outside the MST makes the\nalternatives worse, so the MST would not change. In scenario IV, decreasing the weight of an edge outside the MST makes the alternatives\nbetter, so the MST may change.\n786\nChapter 21. Greedy Algorithms and Divide-and-Conquer\n21.2\nBrute Force\nA brute force algorithm is one that solves a problem in the most simple, direct, or obvious way. Brute force algorithms are not typically\ndistinguishable by structure or form, and two different brute force algorithms can be implemented completely differently. Regardless of how\na brute force algorithm is implemented, however, the goal of such an algorithm is to try out every possible solution, often relying on sheer\ncomputing power to do so. Because brute force algorithms check every possible answer to a problem, they are guaranteed to get the right answer\nfor the problem they are trying to solve.\nFor certain types of problems, brute force is the only way to go. For example, if you wanted to guess someoneâ€™s password, where each\nguess does not give you any information other than whether you are right or wrong, then you have no choice but to try everything. However, in\nmany cases, brute force does more work than necessary, and there are more efficient ways to solve a given problem, even if such solutions are\nnot immediately straightforward or obvious.\nTo highlight an example of the brute force process, suppose you are a cashier with forty coins â€” one quarter, three dimes, six nickels, and\nthirty pennies â€” and you want to use these coins to return 30Â¢ of change using as few coins as possible. If you rely on brute force to solve\nthis problem, you will have to check all possible subsets of coins, determine if they sum up to 30Â¢, and then return the subset that uses the\nfewest number of coins. A table depicting the subsets you would need to check is shown below (note that this table is abbreviated, since it only\ncontains subsets that sum to 30Â¢ â€” in reality, you would need to check possible subsets that can be created using the forty coins you have,all\neven those that do not sum up to the target amount).\n# Quarters\n# Dimes\n# Nickels\n# Pennies\n# Coins\n0\n0\n0\n30\n30\n0\n0\n1\n25\n26\n0\n0\n2\n20\n22\n0\n0\n3\n15\n18\n0\n0\n4\n10\n14\n0\n0\n5\n5\n10\n0\n0\n6\n0\n6\n0\n1\n0\n20\n21\n0\n1\n1\n15\n17\n0\n1\n2\n10\n13\n0\n1\n3\n5\n9\n0\n1\n4\n0\n5\n0\n2\n0\n10\n12\n0\n2\n1\n5\n8\n0\n2\n2\n0\n4\n0\n3\n0\n0\n3\n1\n0\n0\n5\n6\n1\n0\n1\n0\n2\nThe last row of the table â€” one quarter and one nickel â€” allows you to obtain 30Â¢ using the fewest number of coins, so this would be the\n240 240solution to the problem. However, we had to check possible subsets of coins before we could come up with this answer! The was\nobtained using the fundamental counting principle: since there are forty coins total and two possibilities for each of these coins (either included\n240.or excluded from a subset), the total number of possible subsets is 2Ã—2Ã—â€¦Ã—2=\n2ğ‘›possibleIn general, if there are ğ‘›total coins, there are a total of subsets that could potentially be our solution. If we use the brute force\n2ğ‘›subsetsapproach to solve the coin change problem, we would then have to check the sum of all to determine if it sums to the desired amount,\nand then choose the feasible subset that consists of the fewest number of coins. It takes time to count the number of coins in a subset andÎ˜(ğ‘›)\n2ğ‘›possibledetermine if it sums to the desired amount; since these operations are performed for all subsets, the time complexity of the brute\nÎ˜(ğ‘›2ğ‘›).force solution to the coin change problem is bounded above by This is computationally expensive and is pretty much infeasible for\nÎ˜(ğ‘›2ğ‘›)large values of ğ‘›! Luckily, there are ways to do better than by using algorithm families that can be used to improve the efficiency of\noptimization problems. One such family is the approach, which will be explored in the following section.greedy\n21.3\nGreedy Algorithms\nÂ¸ 21.3.1\nThe Greedy Approach and Optimization Problems\nGreedy algorithms can be used to solve certain types of problems in a manner that is often asymptotically faster than brute force. Before we\nbegin our discussion on greedy algorithms, we will first introduce a category of problems known as optimization problems. Optimization\nproblems involve minimizing or maximizing an given a set of constraints. We consider solutions that satisfy our constraintsobjective function\nas solutions, and the optimal solution is the best solution among the possible solutions in the feasible solution set. It is entirely valid forfeasible\nan optimization problem to have no constraints, and it is also valid for a problem to have more than one constraint.\nFor example, the coin change problem is an optimization problem, where the objective function is the number of coins returned, and the\nconstraint is that the change must sum up to 30Â¢. Other examples of optimization problems are shown below:\n1. Determine the time allocation to each of your final exams to maximize total points earned, given that you only have 24 hours left to study.\nâ€¢ maximization problemType of optimization problem:\nâ€¢ total points earned across all examsObjective function:\nâ€¢ you only have 24 hours left to studyConstraint(s):\n788\nChapter 21. Greedy Algorithms and Divide-and-Conquer\nHow can we prove that a greedy approach works? Optimization problems that are solvable using a greedy approach exhibit two key traits:\nan and the property. A problem with an optimal substructure is one whose optimal solution can beoptimal substructure greedy-choice\nconstructed using the optimal solutions of its subproblems (a is a version of the original problem, typically with a smaller input size,subproblem\nthat is solved on the way toward solving the original problem). The following illustrates the optimal substructure of the coin change problem,\nwhere the optimal solution of any change amount can be built using the optimal solutions of smaller change amounts (the example uses 41Â¢, but\nthis structure holds for any change amount desired). As an example, the optimal solution for 41Â¢ can be constructed by adding a 10Â¢ coin to the\noptimal solution for 31Â¢. In the context of greedy algorithms, we can prove optimal substructure by showing that, if we are given an optimal\nsolution to the subproblem that excludes the greedy choice, we can always combine this solution with the greedy choice to obtain an optimal\nsolution to the original problem. If a problem has an optimal substructure, we can always obtain an optimal solution if we perform a greedy\nchoice, and then combine this choice with the optimal solution of the subproblem that remains.\n41Â¢\n25Â¢\n10Â¢\n5Â¢\n1Â¢\n40Â¢\n25Â¢\n10Â¢\n5Â¢\n36Â¢\n25Â¢\n10Â¢\n1Â¢\n31Â¢\n25Â¢\n5Â¢\n1Â¢\n16Â¢\n10Â¢\n5Â¢\n1Â¢\nA problem satisfies the greedy-choice property if there exists at least one optimal solution that contains the first greedy choice. That is, if we\nmake a greedy choice on a problem that satisfies the greedy-choice property for a given greedy algorithm, there is guaranteed to be at least one\noptimal solution that includes the choice we just made. This ensures that a greedy choice can be safely made without ever preventing us from\nfinding an optimal solution.\nThese two characteristics give us a method for proving the efficacy of a greedy approach on an optimization problem. First, we want to\nframe the problem in a way such that only one subproblem remains after a greedy choice is made. Then, we want to show that the problem\nsatisfies the greedy-choice property for our greedy algorithm â€” this ensures that the greedy choice is always safe to make. Lastly, we want to\ndemonstrate that the problem has an optimal substructure, where an optimal solution for the entire problem can be obtained by combining the\ngreedy choice with the optimal solution of the subproblem that remains.\nIf we can prove that a problem has an optimal substructure and satisfies the greedy-choice property for a specific greedy algorithm, then we\nhave also successfully proven the correctness of the greedy algorithm on that problem. Why is this so? If a problem satisfies the greedy-choice\nproperty and has an optimal substructure, we can use to show that the greedy choice must always lead to an optimalmathematical induction\nsolution. This process is shown below.\nA Proof Using Mathematical Induction\nLet be the claim that a greedy algorithm always finds an optimal solution after ğ‘›greedy choices (where ğ‘›is the number of choicesğ‘ƒ(ğ‘›)\nneeded to obtain a solution) for problems that satisfy the greedy-choice property and have an optimal substructure.\nğ‘ƒ(ğ‘›) ğ‘›.Base Step: We want to show that is true for some initial value of\nIn this case, we can trivially show that is true. This is because the problem satisfies the greedy-choice property, which means the firstğ‘ƒ(1)\ngreedy choice must be a part of the optimal solution. Therefore, if a solution can be obtained after a single choice, then that solution must be\nthe optimal solution.\nâˆ€ğ‘˜â‰¥1, ğ‘ƒ(ğ‘˜)â†’ğ‘ƒ(ğ‘˜+1). ğ‘ƒ(ğ‘˜) ğ‘ƒ(ğ‘˜+1)Inductive Step: We want to show that That is, being true implies that is also true.\nSuppose we are given input for which greedy choices are needed before a solution is obtained. Via the greedy-choice property, weğ‘˜+1\nknow that the first greedy choice is part of some optimal solution. In addition, once we make a greedy choice, we are left with another\nsubproblem. Because our original problem has an optimal substructure, we know that the optimal solution for this remaining subproblem\ncan be combined with the greedy choice we just made to obtain an optimal solution for the entire problem. We just made a choice for the\nproblem that required choices to obtain a solution, so there are ğ‘˜choices left to make in the remaining subproblem. Since is trueğ‘˜+1 ğ‘ƒ(ğ‘˜)\nvia the inductive hypothesis, the greedy algorithm must return an optimal solution for the remaining subproblem with ğ‘˜choices. Thus, we\ncan combine this solution with the greedy choice to obtain an optimal solution for the original problem with choices, successfullyğ‘˜+1\nproving that is true.ğ‘ƒ(ğ‘˜+1)\nğ‘›â‰¥1.Thus, we can conclude using mathematical induction that is true for all This implies that a greedy algorithm will always produceğ‘ƒ(ğ‘›)\nan optimal solution for problems with an optimal substructure that satisfy the greedy-choice property for that greedy algorithm.\nTo demonstrate this procedure, letâ€™s consider the coin change problem for denominations of 25Â¢, 10Â¢, 5Â¢, and 1Â¢. To prove that greedily\nselecting the coin with the highest-denomination always leads to an optimal solution, we first want to frame the problem as one in which we\nmake a greedy choice and then are left with one subproblem to solve. This is relatively straightforward for the coin change problem. If we want\nto make change for ğ‘›cents, and the coin we greedily add to our solution has a value of ğ‘šcents, we are left with the subproblem of making\nchange for ğ‘›âˆ’ğ‘šcents.\nProblem:\nMake change for ğ‘›cents\nğ‘šÂ¢\n+\nSubproblem:\nMake change for ğ‘›âˆ’ğ‘šcents\n21.4 Divide-and-Conquer\n801\nThere are several ways to implement this problem, one of which is shown below. Here, we first sort the vector of side quests in order of\nexperience required. Then, we insert the attainable projects into a max-priority queue based on the experience rewarded by each side quest.\nAs long as this priority queue is not empty, we continuously pop off the side quest at the top, add its experience to our total, and push in any\nadditional quests that are now attainable with our new experience. After ğ‘˜quests are completed, we return our total experience as the solution.\n1\nstruct SideQuestCompare {\n2\nbool operator() (const constSideQuest& q1, SideQuest& q2) {\n3\nreturn q1.exp_required < q2.exp_required;\n4\n} // operator()()\n5\n};\n6\n7\nint32_t int32_t int32_tmax_experience(std::vector<SideQuest>& side_quests, init_exp, k) {\n8\nSideQuestCompare comp;\n9\nstd::sort(side_quests.begin(), side_quests.end(), comp);\n10\n11\nint32_t curr_exp = init_exp;\n12\nstd::priority_queue<int32_t> quest_pq;\n13\nfor (int32_t i = 0; k > 0; --k) {\n14\nwhile (i < side_quests.size() && curr_exp >= side_quests[i].exp_required) {\n15\nquest_pq.push(side_quests[i++].exp_rewarded);\n16\n} // while\n17\nif (!quest_pq.empty()) {\n18\ncurr_exp += quest_pq.top();\n19\nquest_pq.pop();\n20\n} // if\n21\n} // for i\n22\n23\nreturn curr_exp;\n24\n} // max_experience()\nBoth sorting the side quests (line 9) and pushing and popping the quests from the priority queue (lines 13-21) are bounded by a time complexity\nside_questsof Î˜(ğ‘›log(ğ‘›)), where ğ‘›is the number of side quests you are given in the vector. Since these steps serve as the bottleneck of the\nalgorithm, the overall time complexity of this solution is also Î˜(ğ‘›log(ğ‘›)).\n21.4\nDivide-and-Conquer\nÂ¸ 21.4.1\nDivide-and-Conquer and Independent Subproblems\nSuppose you are given a group assignment consisting of multiple questions that can be answered independently. If we assume that everyone in\nyour group is equally available and competent, what is the fastest way to get this assignment done? A reasonable approach would be to split the\nassignment up among the group members, have each member complete their assigned questions, and combine all of your answers at the end.\nThis is much faster than having someone complete all the questions on their own.\nThe same idea can be applied when developing algorithms for certain types of problems. As long as a given problem can be split up into\nsubproblems2different (where the answer to one subproblem does not depend on the answers to other subproblems), we canindependent\ndivide the problem into smaller components and solve each component separately, and then combine the solutions of these components to\nobtain a solution to the original problem. This is the foundation of the divide-and-conquer algorithmic approach. Divide-and-conquer is often\nimplemented recursively, with the following three steps applied at each level of the recursion:\nâ€¢ Divide a larger problem into smaller versions of the same problem that can be solved independently.\nConquer the subproblems by solving them individually (either by using recursion, or by using a straightforward approach if the inputâ€¢\nsize is small enough).\nâ€¢ Combine the solutions of the subproblems in a meaningful way to construct the solution for the original, larger problem.\nOriginal Problem\nSubproblem 1\nSubproblem 2\nâ€¦\nSubproblem ğ‘›\nSolution to\nSubproblem 1\nSolution to\nSubproblem 2\nSolutions to\nOther Subproblems\nSolution to\nSubproblem ğ‘›\nSolution to Original Problem\nDivide\nConquer\nCombine\n2What if we have subproblems, where the answer to one subproblem may depend on another? In that case, we would usedependent dynamic programming\ninstead,whichwillbecoveredinchapter23.\n804\nChapter 21. Greedy Algorithms and Divide-and-Conquer\nThe divide-and-conquer implementation is shown below (for simplicity, we will ignore overflow):\n1\nuint32_t power(uint32_t uint32_tx, n) {\n2\nif (n == 0) {\n3\nreturn 1;\n4\n} // if\n5\nint result = power(x, n / 2);\n6\nresult *= result;\n7\nif (n % 2 != 0) {\n// if n is odd\n8\nresult *= x;\n9\n} // if\n10\nreturn result;\n11\n} // power()\nWe can make this implementation tail recursive by adding an accumulator argument (covered in section 5.3) to perform the multiplication\nbefore the recursive call returns:\n1\nuint32_t power(uint32_t uint32_t uint32_tx, n, result = 1) {\n2\nif (n == 0) {\n3\nreturn result;\n4\n} // if\n5\nelse if (n % 2 == 0) {\n// even\n6\nreturn power(x x, n / 2, result);*\n7\n} // else if\n8\nelse {\n// odd\n9\nreturn power(x x, n / 2, result x);* *\n10\n} // else\n11\n} // power()\nThe divide-and-conquer solution to the power function can be expressed using the following recurrence relation:\nğ‘‡(ğ‘›) ğ‘‡(ğ‘›âˆ•2)+Î˜(1)=\nUsing the Master Theorem with 1, 2, and 0, we can conclude that the time complexity of this new solution is with respectğ‘= ğ‘= ğ‘= Î˜(log(ğ‘›))\nğ‘¥ğ‘›intoto the power value ğ‘›. By splitting independent subproblems with powers less than ğ‘›and using the solutions to these subproblems to\nğ‘¥ğ‘›,obtain the solution for we were able to bring the time complexity of our implementation down from to Î˜(log(ğ‘›)).Î˜(ğ‘›)\nÂ¸ 21.4.3\n(âœ½)Integer Multiplication and the Karatsuba Algorithm\nAnother prominent application of divide-and-conquer can be demonstrated using the Karatsuba algorithm, which is an optimized method that\ncan be used to multiply two integers. To understand the usefulness of Karatsuba, letâ€™s first consider the standard integer multiplication strategy\ntaught in grade school. Here, we first multiply the top number (1337) with the last digit in the final number (1). Then, we multiply the top\nnumber (1337) with the second-to-last digit of the bottom number (8), but with the result shifted one position to the left. Then, we multiply the\ntop number with the third-to-last digit, then the fourth-to-last digit, etc. shifting the result one position to the left each time. Once the top number\nis multiplied for all the digits of the bottom number, we add the results (in this case, 1337 + 106960 + 267400 = 375697) to get the final answer.\n1337\nÃ—\n281\n1337\n10696\n+ 2674\n375697\nWhat is the time complexity of this algorithm, in terms of the number of digits in the bigger input number, ğ‘›? Each multiplication would take\nÎ˜(ğ‘›2)time, and since we have to multiply the top digit once for every digit in the bottom number, computing the partial results takes time.Î˜(ğ‘›)\nThen, we have to add these ğ‘›numbers, each of which have digits. Adding two digit numbers also takes time, so adding ğ‘›ofÎ˜(ğ‘›) Î˜(ğ‘›) Î˜(ğ‘›)\nÎ˜(ğ‘›2)them takes a total of time. Since both of these steps occur sequentially, the time complexity of entire algorithm in terms of the number of\nÎ˜(ğ‘›2)+Î˜(ğ‘›2) Î˜(ğ‘›2). Î˜(ğ‘›2)?digits ğ‘›is Is there a way to do better than=\nThe Karatsuba algorithm reduces this time complexity by using a divide-and-conquer approach. To understand Karatsuba, first notice what\nhappens if we split a given number into two halves. We will denote the number in the left half as ğ‘and the number in the right half as ğ‘(for\nexample, after splitting the number 1337 in half, we end up with and 37).ğ‘= ğ‘=13\n1337\n13\nâŸâŸâŸ\nğ‘\n37\nâŸâŸâŸ\nğ‘\n21.4 Divide-and-Conquer\n807\n5\n1\n-3\n-4\n9\n-8\n2\n-1\n8\n-5\n-6\n2\n3\n-4\n-1\n7\n0\n1\n2\n3\n4\n5\n6\n7\n8\n9\n10\n11\n12\n13\n14\n15\nSum: 1\nBest so far: 9\n5\n1\n-3\n-4\n9\n-8\n2\n-1\n8\n-5\n-6\n2\n3\n-4\n-1\n7\n0\n1\n2\n3\n4\n5\n6\n7\n8\n9\n10\n11\n12\n13\n14\n15\nSum: -2\nBest so far: 9\n5\n1\n-3\n-4\n9\n-8\n2\n-1\n8\n-5\n-6\n2\n3\n-4\n-1\n7\n0\n1\n2\n3\n4\n5\n6\n7\n8\n9\n10\n11\n12\n13\n14\n15\nSum: -6\nBest so far: 9\nâ€¦\n5\n1\n-3\n-4\n9\n-8\n2\n-1\n8\n-5\n-6\n2\n3\n-4\n-1\n7\n0\n1\n2\n3\n4\n5\n6\n7\n8\n9\n10\n11\n12\n13\n14\n15\nSum: 7\nBest so far: 10\nThe code for the brute force approach is shown below:\n1\nint32_t max_subarray_sum(const std::vector<int32_t>& nums) {\n2\nint32_t std::numeric_limits<int32_t>::min();best =\n3\nfor (size_t i = 0; i < nums.size(); ++i) {\n4\nint32_t current_subarray_sum = 0;\n5\nfor (size_t j = i; j < nums.size(); ++j) {\n6\ncurrent_subarray_sum += nums[j];\n7\nbest = std::max(current_subarray_sum, best);\n8\n} // for j\n9\n} // for i\n10\nreturn best;\n11\n} // max_subarray_sum()\nÎ˜(ğ‘›2).The time complexity of this solution is Can we do better?\nWe can indeed do better if we use a divide-and-conquer approach. The key to notice here is that we can split the original input array into\nseveral subarrays whose individual solutions can be solved independently of other subarrays. That is, if we divide the initial array in half and\nrecursively identify the maximum subset sum of these halves (which can each be solved independently, without knowing on the maximum subset\nsum of the other half), we can combine this information to obtain the maximum subset sum of the entire array. An example is shown below:\n-4\n6\n3\n-7\n-6\n2\n5\n-8\n-4\n6\n3\n-7\n-6\n2\n5\n-8\n-4\n6\n3\n-7\nMax Subarray Sum: 9\n-6\n2\n5\n-8\nMax Subarray Sum: 7\n-4\n6\n3\n-7\n-6\n2\n5\n-8\nMax Subarray Sum: max(9, 7) = 9\n812\nChapter 21. Greedy Algorithms and Divide-and-Conquer\n6. Suppose you decided to help EECS 281 students by offering special 1-on-1 tutoring sessions on the day before the final exam. You send out\na sign-up form to every EECS 281 student in the class that allows them to sign up for these tutoring sessions. On this form, each student can\nsubmit their ideal start time and the expected duration of their 1-on-1 session (e.g., a student requesting an 11 AM start time and a duration\nof 45 minutes would like to have a session that lasts from 11 AM to 11:45 AM). Given multiple student requests, which of the following\ngreedy algorithms would allow you to help the greatest number of students? You may assume that all requests are restricted betweenalways\n8 AM and 8 PM on the day before the final exam.\nA) Greedily selecting the available student requests with the earliest desired start time\nB) Greedily selecting the available student requests with the earliest desired end time\nC) Greedily selecting the available student requests with the latest desired end time\nD) Greedily selecting the available student requests with the smallest desired duration\nE) More than one of the above\n7. Suppose you are beginning a road trip in a car that can go at most ğ‘šmiles on a full tank. Given an vector of ğ‘›integers representingunsorted\nthe distances of gas stations on your route (in miles) from your starting position, what is the worst-case time complexity of identifying the\nminimum number of stops you can make to travel to a destination ğ‘‘miles away without running out of gas (assuming you start with a full\ntank), if you use the most efficient algorithm?\nA) Î˜(ğ‘›)\nB) Î˜(ğ‘‘+ğ‘›)\nC) Î˜(ğ‘‘ğ‘›)\nD) Î˜(ğ‘›log(ğ‘›))\nE) Î˜(ğ‘‘ğ‘›log(ğ‘›))\n8. You decide to use a brute force algorithm to calculate the shortest distance between two vertices in a graph. Using this strategy, you obtain a\nsolution of 281. If your brute force algorithm is implemented correctly, which of the following can you safely assume?\nA) The optimal distance is exactly 281\nB) The optimal distance may be less than 281\nC) The optimal distance may be greater than 281\nD) All paths between the two vertices have a distance of 281\nE) We cannot safely assume any of the above statements\n9. Your friend is trying to solve the coin change problem to minimize the number of coins needed to make change given a set of coin\ndenominations. They have written two algorithms to solve the problem: one that uses brute force, and one that uses the greedy approach of\nalways selecting the highest denomination coin that is available. Assuming that both algorithms are implemented correctly, which of the\nfollowing outcomes is/are NOT possible when solving for the same target change amount with the same coin denominations?\nA) The brute force solution returns 281, and the greedy solution returns 280\nB) The brute force solution returns 281, and the greedy solution returns 281\nC) The brute force solution returns 281, and the greedy solution returns 282\nD) Both (A) and (C)\nE) All of (A), (B), and (C)\n10. Which of the following statements is FALSE regarding the divide-and-conquer algorithm family?\nA) Divide and conquer algorithms often have time complexities that involve a logarithmic term (e.g., log(ğ‘›))\nB) The Master Theorem can be a useful tool for analyzing the time complexity of divide-and-conquer algorithms\nC) Divide-and-conquer works best if a problem can be split up into multiple subproblems whose solutions depend on each other\nD) Divide-and-conquer algorithms can often be parallelized, where work is distributed to different processors and done simultaneously\nE) None of the above\n11. Which of the following problems can be solved using divide-and-conquer?\nA) Given a one-dimensional array of both positive and negative numbers, identify the subarray of numbers that produces the largest sum\nB) Given an array of integers, sort the array in ascending order\nğ‘šğ‘›C) Given two integers ğ‘šand ğ‘›, compute the value of\nD) Given multiple points on a two-dimensional plane, find the two points that are closest to each other\nE) All of the above\n12. Which of the following sorting algorithms utilize a divide-and-conquer (or combine-and-conquer) approach?\nI. Mergesort\nII. Quicksort\nIII. Heapsort\nA) I only\nB) II only\nC) I and II only\nD) I and III only\nE) I, II, and III\n814\nChapter 21. Greedy Algorithms and Divide-and-Conquer\nChapter 21 Exercise Solutions", "answer_embedding": null, "answer_confidence": null, "page_ids": ["2207e17c-289e-5000-ace5-623e81db7b9b", "5b3eb61a-78ca-5ab0-a3f1-002ac1c1cff4", "6e773b9f-1cda-5ba9-8756-97b6e00119df", "7b7d9dc6-5cd7-52df-b66e-d4548821bf99", "8cacf18e-1cee-53fd-a323-366ab7d7cf31", "9801d2c0-b83e-52f9-b703-56eeba030479", "9b0d4dd4-86c3-518e-a300-140b5431246b", "a33ee040-cb9d-5bce-8fe4-7a2149f54fc9", "eeb12615-da5e-5489-a593-75fa07932e2c", "f6099dd1-8ca5-5a05-8f00-ca473fc97adc"]}, {"id": null, "qa_id": "3e183fa5-9dfe-5a58-b35f-038f1ba7322d", "book_id": "47bbcc23-9276-5662-9e40-96e8a4841ec7", "section_labels": ["practice", "solutions"], "section_titles": ["Exercise Solutions", "Practice Exercises"], "pdf_page": 826, "problem_key": "6", "answer_number": 6, "answer_choice": "B", "answer_text": "This is a variation of the activity selection problem introduced in section 21.3.3. The correct greedy approach\nfor this type of problem is to select the request with the earliest end time.", "answer_embedding": null, "answer_confidence": null, "page_ids": ["2207e17c-289e-5000-ace5-623e81db7b9b", "5b3eb61a-78ca-5ab0-a3f1-002ac1c1cff4", "6e773b9f-1cda-5ba9-8756-97b6e00119df", "7b7d9dc6-5cd7-52df-b66e-d4548821bf99", "8cacf18e-1cee-53fd-a323-366ab7d7cf31", "9801d2c0-b83e-52f9-b703-56eeba030479", "9b0d4dd4-86c3-518e-a300-140b5431246b", "a33ee040-cb9d-5bce-8fe4-7a2149f54fc9", "a8bd50a1-a8c7-5431-824f-b2983d36f1ed", "eeb12615-da5e-5489-a593-75fa07932e2c", "f6099dd1-8ca5-5a05-8f00-ca473fc97adc"]}, {"id": null, "qa_id": "3e183fa5-9dfe-5a58-b35f-038f1ba7322d", "book_id": "47bbcc23-9276-5662-9e40-96e8a4841ec7", "section_labels": ["practice", "solutions"], "section_titles": ["Exercise Solutions", "Practice Exercises"], "pdf_page": 873, "problem_key": "6", "answer_number": 6, "answer_choice": "E", "answer_text": "Brute force involves iterating over all possibilities and returning the minimum distance, which would require\ntime since there are possible tours. In other words, brute force tries every possible permutation of these ğ‘›cities, and there areÎ˜(ğ‘›!) ğ‘›!\npermutations in total (ğ‘›locations to choose for location 1, ways to move from location 1 to location 2, ways to move fromğ‘›! ğ‘›âˆ’1 ğ‘›âˆ’2\nlocation 2 to location 3, â€¦, 1 way to move from location to location ğ‘›).ğ‘›âˆ’1", "answer_embedding": null, "answer_confidence": null, "page_ids": ["2207e17c-289e-5000-ace5-623e81db7b9b", "5b3eb61a-78ca-5ab0-a3f1-002ac1c1cff4", "6e773b9f-1cda-5ba9-8756-97b6e00119df", "7b7d9dc6-5cd7-52df-b66e-d4548821bf99", "8cacf18e-1cee-53fd-a323-366ab7d7cf31", "9801d2c0-b83e-52f9-b703-56eeba030479", "9b0d4dd4-86c3-518e-a300-140b5431246b", "a33ee040-cb9d-5bce-8fe4-7a2149f54fc9", "a8bd50a1-a8c7-5431-824f-b2983d36f1ed", "e07bc6fe-0bb9-5892-9565-a839b6bcff01", "eeb12615-da5e-5489-a593-75fa07932e2c", "f6099dd1-8ca5-5a05-8f00-ca473fc97adc"]}, {"id": null, "qa_id": "3e183fa5-9dfe-5a58-b35f-038f1ba7322d", "book_id": "47bbcc23-9276-5662-9e40-96e8a4841ec7", "section_labels": ["practice", "solutions"], "section_titles": ["Exercise Solutions", "Practice Exercises"], "pdf_page": 994, "problem_key": "6", "answer_number": 6, "answer_choice": "E", "answer_text": "This is a longest path problem rather than a shortest path problem (since you want to find the path with the\ngreatest difference between walking and driving), which cannot be solved using Dijkstraâ€™s algorithm.", "answer_embedding": null, "answer_confidence": null, "page_ids": ["2207e17c-289e-5000-ace5-623e81db7b9b", "5b3eb61a-78ca-5ab0-a3f1-002ac1c1cff4", "6e773b9f-1cda-5ba9-8756-97b6e00119df", "7b25559a-771c-5789-849e-761231306ccf", "7b7d9dc6-5cd7-52df-b66e-d4548821bf99", "8cacf18e-1cee-53fd-a323-366ab7d7cf31", "9801d2c0-b83e-52f9-b703-56eeba030479", "9b0d4dd4-86c3-518e-a300-140b5431246b", "a33ee040-cb9d-5bce-8fe4-7a2149f54fc9", "a8bd50a1-a8c7-5431-824f-b2983d36f1ed", "e07bc6fe-0bb9-5892-9565-a839b6bcff01", "eeb12615-da5e-5489-a593-75fa07932e2c", "f6099dd1-8ca5-5a05-8f00-ca473fc97adc"]}, {"id": null, "qa_id": "3e183fa5-9dfe-5a58-b35f-038f1ba7322d", "book_id": "47bbcc23-9276-5662-9e40-96e8a4841ec7", "section_labels": ["practice", "solutions"], "section_titles": ["Exercise Solutions", "Practice Exercises"], "pdf_page": 1053, "problem_key": "6", "answer_number": 6, "answer_choice": "C", "answer_text": "This is a bounding box problem, and we can solve it by iterating over all the points and keeping track of the\nsmallest and largest values of ğ‘¥and ğ‘¦(since we want the resulting rectangle to be parallel to the ğ‘¥- and ğ‘¦-axes). This solution would take\ntime given ğ‘›points.Î˜(ğ‘›)", "answer_embedding": null, "answer_confidence": null, "page_ids": ["2207e17c-289e-5000-ace5-623e81db7b9b", "5b3eb61a-78ca-5ab0-a3f1-002ac1c1cff4", "6275fd1a-cffc-5d55-9e15-840a57b06dcd", "6e773b9f-1cda-5ba9-8756-97b6e00119df", "7b25559a-771c-5789-849e-761231306ccf", "7b7d9dc6-5cd7-52df-b66e-d4548821bf99", "8cacf18e-1cee-53fd-a323-366ab7d7cf31", "9801d2c0-b83e-52f9-b703-56eeba030479", "9b0d4dd4-86c3-518e-a300-140b5431246b", "a33ee040-cb9d-5bce-8fe4-7a2149f54fc9", "a8bd50a1-a8c7-5431-824f-b2983d36f1ed", "e07bc6fe-0bb9-5892-9565-a839b6bcff01", "eeb12615-da5e-5489-a593-75fa07932e2c", "f6099dd1-8ca5-5a05-8f00-ca473fc97adc"]}]}
{"type": "matched_pair", "qa_id": "5162f4f4-1945-5613-a70d-335a406509bb", "question": {"id": null, "qa_id": "5162f4f4-1945-5613-a70d-335a406509bb", "book_id": "47bbcc23-9276-5662-9e40-96e8a4841ec7", "section_labels": ["practice", "solutions"], "section_titles": ["Exercise Solutions", "Practice Exercises"], "pdf_page": 955, "problem_key": "19", "question_number": 19, "question_text": "You want to identify the student with the highest percentage score in the class. At the end of the semester, you receive the individual\nassignment grades received by every student (but not the overall percentage grade). You first calculate the percentage score earned by\nthe first student in the class. Then, for each of the remaining students, you calculate the maximum score that could be attained by that\nstudent after each assignment is individually considered. If this maximum score is lower than the current best, you stop and move on to the\nnext student on the roster. Otherwise, the student is promising, and you continue to check their grades until they either obtain the highest\nscore or it becomes impossible for them to attain a score higher than the current best score encountered. What algorithm family is this an\nexample of?\nA) Backtracking\nB) Branch and bound\nC) Brute force\nD) Divide and conquer\nE) Dynamic programming\n25.7 Summary of Shortest Path Algorithms\n977\nChapter 25 Practice Exercises\nDisclaimer: These practice questions are not official and may not have been vetted for course material. You may use these for practice, but\nyou should prioritize official resources from current staff for a more accurate depiction of what you need to know for assignments and exams.", "question_embedding": null, "page_ids": ["cba6a615-1ed5-524b-b8f5-2097b53ee531", "fa3d76e7-f248-5f89-aa79-8ac7b5a3afa5"]}, "answers": [{"id": null, "qa_id": "5162f4f4-1945-5613-a70d-335a406509bb", "book_id": "47bbcc23-9276-5662-9e40-96e8a4841ec7", "section_labels": ["practice", "solutions"], "section_titles": ["Exercise Solutions", "Practice Exercises"], "pdf_page": 961, "problem_key": "19", "answer_number": 19, "answer_choice": "B", "answer_text": "You are trying to solve an optimization problem by dropping all solutions that are not good enough, so this is an\nexample of branch and bound.", "answer_embedding": null, "answer_confidence": null, "page_ids": ["cba6a615-1ed5-524b-b8f5-2097b53ee531", "fa3d76e7-f248-5f89-aa79-8ac7b5a3afa5"]}]}
{"type": "matched_pair", "qa_id": "802552bb-6e9f-59dc-a756-71c50f5a818e", "question": {"id": null, "qa_id": "802552bb-6e9f-59dc-a756-71c50f5a818e", "book_id": "47bbcc23-9276-5662-9e40-96e8a4841ec7", "section_labels": ["practice", "solutions"], "section_titles": ["Exercise Solutions", "Practice Exercises"], "pdf_page": 952, "problem_key": "5", "question_number": 5, "question_text": "Assume you are implementing a dynamic programming approach to the 0-1 knapsack problem, and you are trying to find the maximum\npossible value you can take in your knapsack of weight capacity 5. You have the following items:\nItem ID\nWeight\nValue\n1\n2\n$35\n2\n1\n$16\n3\n4\n$61\n4\n3\n$53\nThe memo for this problem is shown below. Some of the values in the memo have already been filled in (ID represented by memo row,\nweight represented by memo column).\nID/Weight\n0\n1\n2\n3\n4\n5\n0\n$0\n$0\n$0\n$0\n$0\n$0\n1\n$0\n$0\n$35\n$35\n2\n$0\n3\n$0\n4\n$0\nT\nAfter the memo is completely filled in, what would be the value of ğ‘‡?\nA) $61\nB) $64\nC) $69\nD) $70\nE) $88\n24.5 Unbounded Knapsack\n943", "question_embedding": null, "page_ids": ["1a3da172-d383-5da8-b297-3fd5ea9024dc", "2207e17c-289e-5000-ace5-623e81db7b9b", "5b3eb61a-78ca-5ab0-a3f1-002ac1c1cff4", "6275fd1a-cffc-5d55-9e15-840a57b06dcd", "6e773b9f-1cda-5ba9-8756-97b6e00119df", "7b25559a-771c-5789-849e-761231306ccf", "7b7d9dc6-5cd7-52df-b66e-d4548821bf99", "9801d2c0-b83e-52f9-b703-56eeba030479", "9f54d44a-cfe6-57f6-8db2-65e48017568e", "a33ee040-cb9d-5bce-8fe4-7a2149f54fc9", "a732e97e-0ac4-53d2-b683-2ca489c035d6", "a8bd50a1-a8c7-5431-824f-b2983d36f1ed", "afe605f5-a549-5395-b01b-3fe495903bb8", "e0326653-437b-5fe2-9a54-4baf2368d157", "e07bc6fe-0bb9-5892-9565-a839b6bcff01", "eeb12615-da5e-5489-a593-75fa07932e2c", "f0f93193-dc46-5ba5-9f4d-77717945d193", "f5d6b0c4-2db1-5173-8428-b1cf083e7cc4"]}, "answers": [{"id": null, "qa_id": "802552bb-6e9f-59dc-a756-71c50f5a818e", "book_id": "47bbcc23-9276-5662-9e40-96e8a4841ec7", "section_labels": ["practice", "solutions"], "section_titles": ["Exercise Solutions", "Practice Exercises"], "pdf_page": 161, "problem_key": "5", "answer_number": 5, "answer_choice": "E", "answer_text": "On line 6, we perform a recursive call with input size ğ‘›âˆ•7, which adds a term to our recurrence. Onğ‘‡(ğ‘›âˆ•7)\nğ‘›3bar(n) bar(n)lines 9-13, we perform a loop that executes a total of times; since we are given that runs in time, the totallog(ğ‘›)\nğ‘›3contribution of this loop can be expressed as log(ğ‘›). On lines 15-17, we perform a loop that makes a recursive call with input size ağ‘›âˆ•3\nğ‘›2Ã—ğ‘›2 ğ‘›4,bar()total of ğ‘›times, for a total contribution of ğ‘›ğ‘‡(ğ‘›âˆ•3). Lastly, on line 19, we call with an input size of which contributes=\nlog(ğ‘›4) work. Adding all of these terms together, we get the recurrence relation matching option (E).4log(ğ‘›)=\nğ‘‡(ğ‘›âˆ’4)+3ğ‘›âˆ’2, ğ‘‡(ğ‘›âˆ’2)+3ğ‘›is ğ‘‡(ğ‘›âˆ’4)+3ğ‘›+3ğ‘›âˆ’2.6. The correct answer is (C). We know that so the substitution after Whenğ‘‡(ğ‘›âˆ’2)=\nğ‘‡(ğ‘›âˆ’4)+3ğ‘›âˆ’2 ğ‘‡(ğ‘›âˆ’4)+3ğ‘›).substituting, make sure to substitute all instances of ğ‘›in the expression (e.g., is and notğ‘‡(ğ‘›âˆ’2)", "answer_embedding": null, "answer_confidence": null, "page_ids": ["afe605f5-a549-5395-b01b-3fe495903bb8", "e0326653-437b-5fe2-9a54-4baf2368d157"]}, {"id": null, "qa_id": "802552bb-6e9f-59dc-a756-71c50f5a818e", "book_id": "47bbcc23-9276-5662-9e40-96e8a4841ec7", "section_labels": ["practice", "solutions"], "section_titles": ["Exercise Solutions", "Practice Exercises"], "pdf_page": 188, "problem_key": "5", "answer_number": 5, "answer_choice": "C", "answer_text": "To copy an array of ğ‘›elements, you cannot do better than since you have to visit each element at leastÎ˜(ğ‘›)\nonce to copy it. There is no need to do any work beyond either; as the number of elements you have to copy grows, the number ofÎ˜(ğ‘›)\noperations you need will also grow linearly.", "answer_embedding": null, "answer_confidence": null, "page_ids": ["2207e17c-289e-5000-ace5-623e81db7b9b", "afe605f5-a549-5395-b01b-3fe495903bb8", "e0326653-437b-5fe2-9a54-4baf2368d157"]}, {"id": null, "qa_id": "802552bb-6e9f-59dc-a756-71c50f5a818e", "book_id": "47bbcc23-9276-5662-9e40-96e8a4841ec7", "section_labels": ["practice", "solutions"], "section_titles": ["Exercise Solutions", "Practice Exercises"], "pdf_page": 211, "problem_key": "5", "answer_number": 5, "answer_choice": "E", "answer_text": "All of the statements are true. Statement I is true because elements must be copied from one array to another\nduring reallocation, which can be an expensive process. Statement II is true because all pointer or iterator references to the old array would\nbe invalidated when the elements are copied to a new, larger array. Statement III is true because you may end up with a larger capacity\nthan you need, which would waste memory (e.g., you only need to store 65 elements, but your vector ends up with a capacity of 128 since\ncapacity is doubled with each reallocation, leaving 63 slots unused).", "answer_embedding": null, "answer_confidence": null, "page_ids": ["2207e17c-289e-5000-ace5-623e81db7b9b", "afe605f5-a549-5395-b01b-3fe495903bb8", "e0326653-437b-5fe2-9a54-4baf2368d157", "eeb12615-da5e-5489-a593-75fa07932e2c"]}, {"id": null, "qa_id": "802552bb-6e9f-59dc-a756-71c50f5a818e", "book_id": "47bbcc23-9276-5662-9e40-96e8a4841ec7", "section_labels": ["practice", "solutions"], "section_titles": ["Exercise Solutions", "Practice Exercises"], "pdf_page": 328, "problem_key": "5", "answer_number": 5, "answer_choice": "A", "answer_text": "Notice that the time rquired to pop elements grows much more rapidly than the time required to push elements\nas the number of elements you have to push or pop increases. This would point to a container where inserting is easy and removing is\ndifficult. Of the choices provided, an unsorted sequence container would make the most sense, as removing is a linear time operation due to\nthe unsorted nature of the container (you have to linear search for the element with the greatest priority to pop). An unsorted sequence\nÎ˜(ğ‘›2)container provides insertion and removal, which would be result in a and relationship in total if performed ğ‘›times.Î˜(ğ‘›) Î˜(ğ‘›)Î˜(1)\nThis fits with the data provided: the time for push grows linearly with ğ‘›, while the time for pop grows quadratically with ğ‘›. None of the\nother answer choices exhibit these same time complexities for push and pop.\nstd::priority_queue<> std::less(<)6. Thecorrectansweris(C).The defaultstothe comparatorifnocomparatorisexplicitly\nprovided, so larger elements have the greatest priority. Thus, the elements are popped out in descending order.\nstd::greater (>) abs(rhs - 25)7. The correct answer is (D). The comparator is in a format, so elements with a smaller value for\nhave greater priority and are popped out first. In other words, the elements are popped out in order of how far away they are from 25, with\nelements closer to 25 popped out before elements farther from 25.\nstd::priority_queue<>8. The correct answer is (D). The underlying container for a must be sequential and support constant time\nrandom access. This only applies for vectors and deques.\n.push() foo()9. The correct answer is (C). Each individual call to takes time, so the time complexity of isÎ˜(log(ğ‘›)) ğ‘›Ã—Î˜(log(ğ‘›))=\nÎ˜(ğ‘›log(ğ‘›)). However, if you use the range constructor, the input range can be heapified in time instead. This is why it is better toÎ˜(ğ‘›)\ninitialize a priority queue with a range of data using the range constructor (if possible), instead of pushing each element in one by one.", "answer_embedding": null, "answer_confidence": null, "page_ids": ["2207e17c-289e-5000-ace5-623e81db7b9b", "a732e97e-0ac4-53d2-b683-2ca489c035d6", "afe605f5-a549-5395-b01b-3fe495903bb8", "e0326653-437b-5fe2-9a54-4baf2368d157", "eeb12615-da5e-5489-a593-75fa07932e2c"]}, {"id": null, "qa_id": "802552bb-6e9f-59dc-a756-71c50f5a818e", "book_id": "47bbcc23-9276-5662-9e40-96e8a4841ec7", "section_labels": ["practice", "solutions"], "section_titles": ["Exercise Solutions", "Practice Exercises"], "pdf_page": 383, "problem_key": "5", "answer_number": 5, "answer_choice": "A", "answer_text": "On line 2, we create the following array:\n[15, 21, 43, 40, 28, 50, 54, 35]\nOn line 4, we increment each value in the array by one.\n[16, 22, 44, 41, 29, 51, 55, 36]\nmy_ints my_ints + 7, my_ints + 7On line 7, we range construct a vector using all values from to not including the value of\nsince end is exclusive:\n[16, 22, 44, 41, 29, 51, 55]\nvec.begin() vec.begin() + 4, vec.begin() + 4On line 8, we sort the vector from to not including the value at since end is\nstd::greater<>exclusive. Since is used, the elements in this range are sorted in descending order:\n[44, 41, 22, 16, 29, 51, 55]\nvec.end()On line 9, we reverse the entire vector. All elements are included since points one past the end of the vector:\n[55, 51, 29, 16, 22, 41, 44]\n388\nChapter 12. Amortization and Amortized Analysis\nChapter 12 Exercise Solutions", "answer_embedding": null, "answer_confidence": null, "page_ids": ["2207e17c-289e-5000-ace5-623e81db7b9b", "9f54d44a-cfe6-57f6-8db2-65e48017568e", "a732e97e-0ac4-53d2-b683-2ca489c035d6", "afe605f5-a549-5395-b01b-3fe495903bb8", "e0326653-437b-5fe2-9a54-4baf2368d157", "eeb12615-da5e-5489-a593-75fa07932e2c"]}, {"id": null, "qa_id": "802552bb-6e9f-59dc-a756-71c50f5a818e", "book_id": "47bbcc23-9276-5662-9e40-96e8a4841ec7", "section_labels": ["practice", "solutions"], "section_titles": ["Exercise Solutions", "Practice Exercises"], "pdf_page": 400, "problem_key": "5", "answer_number": 5, "answer_choice": "A", "answer_text": "The total amount of work required to perform ğ‘›operations can be expressed as:\nğ‘‡(ğ‘›) <ğ‘›+Î˜(ğ‘›) Î˜(ğ‘›)=1+2+1+4+1+1+1+8+1+â€¦=(1+1+1+â€¦)+(1+2+4+8+â€¦) =\nUsing aggregate analysis, we conclude that the amortized time complexity of a single operation is Î˜(1). (Note: the scenarioÎ˜(ğ‘›)âˆ•ğ‘›=\ndescribed in this problem is exactly what happens during vector reallocation.)", "answer_embedding": null, "answer_confidence": null, "page_ids": ["2207e17c-289e-5000-ace5-623e81db7b9b", "6e773b9f-1cda-5ba9-8756-97b6e00119df", "9f54d44a-cfe6-57f6-8db2-65e48017568e", "a732e97e-0ac4-53d2-b683-2ca489c035d6", "afe605f5-a549-5395-b01b-3fe495903bb8", "e0326653-437b-5fe2-9a54-4baf2368d157", "eeb12615-da5e-5489-a593-75fa07932e2c"]}, {"id": null, "qa_id": "802552bb-6e9f-59dc-a756-71c50f5a818e", "book_id": "47bbcc23-9276-5662-9e40-96e8a4841ec7", "section_labels": ["practice", "solutions"], "section_titles": ["Exercise Solutions", "Practice Exercises"], "pdf_page": 420, "problem_key": "5", "answer_number": 5, "answer_choice": "E", "answer_text": "The union find data structure is most useful for working with disjoint sets. All of the options are examples\nwhere this may be applicable, since they all deal with identifying or merging elements into disjoint sets.", "answer_embedding": null, "answer_confidence": null, "page_ids": ["2207e17c-289e-5000-ace5-623e81db7b9b", "6e773b9f-1cda-5ba9-8756-97b6e00119df", "7b7d9dc6-5cd7-52df-b66e-d4548821bf99", "9f54d44a-cfe6-57f6-8db2-65e48017568e", "a732e97e-0ac4-53d2-b683-2ca489c035d6", "afe605f5-a549-5395-b01b-3fe495903bb8", "e0326653-437b-5fe2-9a54-4baf2368d157", "eeb12615-da5e-5489-a593-75fa07932e2c"]}, {"id": null, "qa_id": "802552bb-6e9f-59dc-a756-71c50f5a818e", "book_id": "47bbcc23-9276-5662-9e40-96e8a4841ec7", "section_labels": ["practice", "solutions"], "section_titles": ["Exercise Solutions", "Practice Exercises"], "pdf_page": 453, "problem_key": "5", "answer_number": 5, "answer_choice": "D", "answer_text": "Both students require a sort that has a worst-case time complexity of Î˜(ğ‘›log(ğ‘›)), so quicksort is not an option.\nOf the remaining comparison sorts, both heapsort and mergesort can be done in worst-case time. Mergesort is stable, so itÎ˜(ğ‘›log(ğ‘›))\nwould allow Daniel to keep the relative order of elements in his array intact. Heapsort is not stable, so it would not work for Daniel. On the\nother hand, heapsort can be done in-place, which would work for Ryan (mergesort would not, since it requires auxiliary space on anÎ˜(ğ‘›)\narray). Thus, Daniel should use mergesort, and Ryan should use heapsort.", "answer_embedding": null, "answer_confidence": null, "page_ids": ["2207e17c-289e-5000-ace5-623e81db7b9b", "5b3eb61a-78ca-5ab0-a3f1-002ac1c1cff4", "6e773b9f-1cda-5ba9-8756-97b6e00119df", "7b7d9dc6-5cd7-52df-b66e-d4548821bf99", "9f54d44a-cfe6-57f6-8db2-65e48017568e", "a732e97e-0ac4-53d2-b683-2ca489c035d6", "afe605f5-a549-5395-b01b-3fe495903bb8", "e0326653-437b-5fe2-9a54-4baf2368d157", "eeb12615-da5e-5489-a593-75fa07932e2c"]}, {"id": null, "qa_id": "802552bb-6e9f-59dc-a756-71c50f5a818e", "book_id": "47bbcc23-9276-5662-9e40-96e8a4841ec7", "section_labels": ["practice", "solutions"], "section_titles": ["Exercise Solutions", "Practice Exercises"], "pdf_page": 491, "problem_key": "5", "answer_number": 5, "answer_choice": "B", "answer_text": "This is actually a binary search question. Consider the following array where the number 7 is missing.\n0\n1\n2\n3\n4\n5\n6\n8\n9\n10\n0\n1\n2\n3\n4\n5\n6\n7\n8\n9\nNotice that all numbers before the missing number share their values with their index positions (e.g., 0 at index 0, 1 at index 1, etc.), while\nall numbers after the missing number have a value one larger than their index positions (e.g., 8 at index 7, 9 at index 8, etc.). We can use\nthis knowledge to do a binary search. First, we visit the element in the middle and see if its value is equal to its index. If it is, then the\nmissing number has not occurred yet and must be to the right of the middle value. Otherwise, something before the middle value must have\nmessed the indices up, and the missing element must be to the left. Since binary search cuts the search space in half at every iteration, the\nworst-case time complexity of solving this problem is Î˜(log(ğ‘›)).\n518\nChapter 16. Strings and Sequences\n18. You are given two strings, as well as a fingerprint function that can be used to convert a string into an integer in constant time.\nint32_t get_string_fingerprint(const std::string& str);\nYour friend implements the following function, which they claim is able to check if two strings are equal in constant time.\n1\nbool are_strings_equal(const conststd::string& s1, std::string& s2) {\n2\nint32_t fingerprint1 = get_string_fingerprint(s1);\n3\nint32_t fingerprint2 = get_string_fingerprint(s2);\n4\nif (fingerprint1 == fingerprint2) {\n5\nreturn true;\n6\n} // if\n7\nreturn false;\n8\n} // are_strings_equal()\nIs your friendâ€™s implementation guaranteed to work as intended? Why or why not?\nstr,Implement a function that, given a string returns the longest prefix of the string that is also a suffix (excluding the entire word itself).19.\nIf no such prefix exists, return an empty string.\n(\"edited\")\"edited\", \"ed\",Example: Given the string you would return since that is the longest prefix that is also a suffix of the\n(\"edited\").same word\nlongest_prefix_suffix(conststd::string std::string& str);\nÎ˜(ğ‘›2),You should implement your solution so that the average-case time complexity is better than where ğ‘›is the length of the input string.\nÎ˜(ğ‘›2)(Reducing the worst-case time complexity below is also possible, but not required.)\nChapter 16 Exercise Solutions\n\"a\", \"ab\", \"ab10\", \"ab9\" (\"ab10\" \"ab9\"1. The correct answer is (B). The correct order is then then then comes before since 9 is\nlarger lexicographically compared to 1).\n2. Thecorrectansweris(C).Option(A)returnstruebecausecapitalletterscomebeforelowercaseletterslexicographically. Option(B)returns\n(\"0\" \"1\") \"eecs280\" \"eecs281\"true because the first character difference between the two strings and puts before lexicographically.\nstd::lexicographical_compare()Option (C) returns false because returns false if two strings are identical.\nstd::equal() operator==3. The correct answer is (E). All three statements are true. works on C strings while does not, and it can\nalso be used to check for a matching prefix (since you can pass in an iterator range representing the prefix you want to search). Statement III\nis true since only < and == are needed to implement the other four comparison operators:\nâ€¢ a != b is the same as !(a == b)\nâ€¢ a > b is the same as b < a\nâ€¢ a <= b is the same as !(b < a)\nâ€¢ a >= b is the same as !(a < b)", "answer_embedding": null, "answer_confidence": null, "page_ids": ["2207e17c-289e-5000-ace5-623e81db7b9b", "5b3eb61a-78ca-5ab0-a3f1-002ac1c1cff4", "6e773b9f-1cda-5ba9-8756-97b6e00119df", "7b7d9dc6-5cd7-52df-b66e-d4548821bf99", "9f54d44a-cfe6-57f6-8db2-65e48017568e", "a732e97e-0ac4-53d2-b683-2ca489c035d6", "afe605f5-a549-5395-b01b-3fe495903bb8", "e0326653-437b-5fe2-9a54-4baf2368d157", "eeb12615-da5e-5489-a593-75fa07932e2c", "f0f93193-dc46-5ba5-9f4d-77717945d193"]}, {"id": null, "qa_id": "802552bb-6e9f-59dc-a756-71c50f5a818e", "book_id": "47bbcc23-9276-5662-9e40-96e8a4841ec7", "section_labels": ["practice", "solutions"], "section_titles": ["Exercise Solutions", "Practice Exercises"], "pdf_page": 587, "problem_key": "5", "answer_number": 5, "answer_choice": "D", "answer_text": "The compression method provided works best when the keys are randomly distributed. The test scores are not\nevenly distributed; since each question is worth 5 points, scores can only take on the values 0, 5, 10, 15, â€¦, 90, 95, 100. The number of\nhours of sleep and number of credits taken by each student are also not evenly distributed and take on a rather restricted range of values.\nOnly the collection of student IDS at the university is random as the ID of any particular student in EECS 281 could be any 8-digit number.\ninsert()6. The correct answer is (B). The method does not do anything if the key already exists in the unordered map, as unordered maps\n\"Paoletti\" \"Darden\".cannot have duplicate keys. On line 3, the key is initialized with the value Lines 5 and 7 do not do anything\n\"Paoletti\" \"Darden\"since the key already exists in the table. Thus, the value of remains unchanged and is printed out on line 8.\n\"Angstadt\" \"Darden\"7. The correct answer is (A). Even though the key is initially created with the value on line 4, it is updated on\n\"Paoletti\". \"Paoletti\"line 6 to a value of Thus, is printed out on line 11.\n\"Paoletti\" \"Angstadt\"8. Thecorrectansweris(B).Priortoline10,therearethreekeysthatexistinthehashtable: (createdonline3),\n\"Darden\" operator[](created on line 4), and (created on line 9 â€“ recall that automatically inserts a key if it does not already exist).\n\"Paoletti\" 2.After is removed from the hash table on line 10, there are only two keys remaining, so line 12 prints out", "answer_embedding": null, "answer_confidence": null, "page_ids": ["1a3da172-d383-5da8-b297-3fd5ea9024dc", "2207e17c-289e-5000-ace5-623e81db7b9b", "5b3eb61a-78ca-5ab0-a3f1-002ac1c1cff4", "6e773b9f-1cda-5ba9-8756-97b6e00119df", "7b7d9dc6-5cd7-52df-b66e-d4548821bf99", "9f54d44a-cfe6-57f6-8db2-65e48017568e", "a732e97e-0ac4-53d2-b683-2ca489c035d6", "afe605f5-a549-5395-b01b-3fe495903bb8", "e0326653-437b-5fe2-9a54-4baf2368d157", "eeb12615-da5e-5489-a593-75fa07932e2c", "f0f93193-dc46-5ba5-9f4d-77717945d193"]}, {"id": null, "qa_id": "802552bb-6e9f-59dc-a756-71c50f5a818e", "book_id": "47bbcc23-9276-5662-9e40-96e8a4841ec7", "section_labels": ["practice", "solutions"], "section_titles": ["Exercise Solutions", "Practice Exercises"], "pdf_page": 771, "problem_key": "5", "answer_number": 5, "answer_choice": "D", "answer_text": "If person A got help from person B during office hours, it does not mean that person B also got help from\nperson A. Thus, a graph representing help during office hours would be directed. All the other examples are undirected, where a connection\nfrom A to B also implies a connection from B to A.", "answer_embedding": null, "answer_confidence": null, "page_ids": ["1a3da172-d383-5da8-b297-3fd5ea9024dc", "2207e17c-289e-5000-ace5-623e81db7b9b", "5b3eb61a-78ca-5ab0-a3f1-002ac1c1cff4", "6e773b9f-1cda-5ba9-8756-97b6e00119df", "7b7d9dc6-5cd7-52df-b66e-d4548821bf99", "9f54d44a-cfe6-57f6-8db2-65e48017568e", "a33ee040-cb9d-5bce-8fe4-7a2149f54fc9", "a732e97e-0ac4-53d2-b683-2ca489c035d6", "afe605f5-a549-5395-b01b-3fe495903bb8", "e0326653-437b-5fe2-9a54-4baf2368d157", "eeb12615-da5e-5489-a593-75fa07932e2c", "f0f93193-dc46-5ba5-9f4d-77717945d193"]}, {"id": null, "qa_id": "802552bb-6e9f-59dc-a756-71c50f5a818e", "book_id": "47bbcc23-9276-5662-9e40-96e8a4841ec7", "section_labels": ["practice", "solutions"], "section_titles": ["Exercise Solutions", "Practice Exercises"], "pdf_page": 793, "problem_key": "5", "answer_number": 5, "answer_choice": "B", "answer_text": "The total weight of the MST is 2 + 11 + 14 + 6 = 33.\nğ¶\nğ´\nğ·\nğµ\nğ¸\n19\n12\n16\n2\n11\n14\n6", "answer_embedding": null, "answer_confidence": null, "page_ids": ["1a3da172-d383-5da8-b297-3fd5ea9024dc", "2207e17c-289e-5000-ace5-623e81db7b9b", "5b3eb61a-78ca-5ab0-a3f1-002ac1c1cff4", "6e773b9f-1cda-5ba9-8756-97b6e00119df", "7b7d9dc6-5cd7-52df-b66e-d4548821bf99", "9801d2c0-b83e-52f9-b703-56eeba030479", "9f54d44a-cfe6-57f6-8db2-65e48017568e", "a33ee040-cb9d-5bce-8fe4-7a2149f54fc9", "a732e97e-0ac4-53d2-b683-2ca489c035d6", "afe605f5-a549-5395-b01b-3fe495903bb8", "e0326653-437b-5fe2-9a54-4baf2368d157", "eeb12615-da5e-5489-a593-75fa07932e2c", "f0f93193-dc46-5ba5-9f4d-77717945d193"]}, {"id": null, "qa_id": "802552bb-6e9f-59dc-a756-71c50f5a818e", "book_id": "47bbcc23-9276-5662-9e40-96e8a4841ec7", "section_labels": ["practice", "solutions"], "section_titles": ["Exercise Solutions", "Practice Exercises"], "pdf_page": 826, "problem_key": "5", "answer_number": 5, "answer_choice": "B", "answer_text": "Statement I is false because a greedy approach does not look back and undo any choices, so if a greedy approach\nis known to work and ğ‘¥is added to the solution, there must be at least one optimal solution that includes ğ‘¥. Statement II is false because an\noptimal substructure alone cannot prove that greedy always works: we also need to show that the greedy-choice property holds, and that\nevery greedy choice we make has the potential to be a valid solution. Statement III is true, since mathematical induction can be used to\nshow that a greedy approach is valid after identifying that the greedy-choice property and an optimal substructure holds for a given problem.", "answer_embedding": null, "answer_confidence": null, "page_ids": ["1a3da172-d383-5da8-b297-3fd5ea9024dc", "2207e17c-289e-5000-ace5-623e81db7b9b", "5b3eb61a-78ca-5ab0-a3f1-002ac1c1cff4", "6e773b9f-1cda-5ba9-8756-97b6e00119df", "7b7d9dc6-5cd7-52df-b66e-d4548821bf99", "9801d2c0-b83e-52f9-b703-56eeba030479", "9f54d44a-cfe6-57f6-8db2-65e48017568e", "a33ee040-cb9d-5bce-8fe4-7a2149f54fc9", "a732e97e-0ac4-53d2-b683-2ca489c035d6", "a8bd50a1-a8c7-5431-824f-b2983d36f1ed", "afe605f5-a549-5395-b01b-3fe495903bb8", "e0326653-437b-5fe2-9a54-4baf2368d157", "eeb12615-da5e-5489-a593-75fa07932e2c", "f0f93193-dc46-5ba5-9f4d-77717945d193"]}, {"id": null, "qa_id": "802552bb-6e9f-59dc-a756-71c50f5a818e", "book_id": "47bbcc23-9276-5662-9e40-96e8a4841ec7", "section_labels": ["practice", "solutions"], "section_titles": ["Exercise Solutions", "Practice Exercises"], "pdf_page": 873, "problem_key": "5", "answer_number": 5, "answer_choice": "A", "answer_text": "Heuristics do not always calculate the optimal solution. The precision of the calculation is sacrificed for speed,\nbut these algorithms to provide answers that are close enough. This is useful for solving problems like TSP where the actual process of\nfinding the best solution takes up a lot of time and may be too expensive to complete in practice.", "answer_embedding": null, "answer_confidence": null, "page_ids": ["1a3da172-d383-5da8-b297-3fd5ea9024dc", "2207e17c-289e-5000-ace5-623e81db7b9b", "5b3eb61a-78ca-5ab0-a3f1-002ac1c1cff4", "6e773b9f-1cda-5ba9-8756-97b6e00119df", "7b7d9dc6-5cd7-52df-b66e-d4548821bf99", "9801d2c0-b83e-52f9-b703-56eeba030479", "9f54d44a-cfe6-57f6-8db2-65e48017568e", "a33ee040-cb9d-5bce-8fe4-7a2149f54fc9", "a732e97e-0ac4-53d2-b683-2ca489c035d6", "a8bd50a1-a8c7-5431-824f-b2983d36f1ed", "afe605f5-a549-5395-b01b-3fe495903bb8", "e0326653-437b-5fe2-9a54-4baf2368d157", "e07bc6fe-0bb9-5892-9565-a839b6bcff01", "eeb12615-da5e-5489-a593-75fa07932e2c", "f0f93193-dc46-5ba5-9f4d-77717945d193"]}, {"id": null, "qa_id": "802552bb-6e9f-59dc-a756-71c50f5a818e", "book_id": "47bbcc23-9276-5662-9e40-96e8a4841ec7", "section_labels": ["practice", "solutions"], "section_titles": ["Exercise Solutions", "Practice Exercises"], "pdf_page": 958, "problem_key": "5", "answer_number": 5, "answer_choice": "C", "answer_text": "The final memo looks like this:\nID/Weight\n0\n1\n2\n3\n4\n5\n0\n$0\n$0\n$0\n$0\n$0\n$0\n1\n$0\n$0\n$35\n$35\n$35\n$35\n2\n$0\n$16\n$35\n$51\n$51\n$51\n3\n$0\n$16\n$35\n$51\n$61\n$77\n4\n$0\n$16\n$35\n$53\n$69\n$88\nğ‘‹â‰¥ğ‘Œto6. The correct answer is (B). For be true, the optimal solution considering only items 1-3 with a knapsack of capacity 3 must be\ngreater than or equal to the optimal solution considering only items 1-3 with a knapsack of capacity 4. For this to happen, the value of item\n3 cannot exceed the value of ğ‘‹â€” otherwise, it would be chosen for the knapsack of capacity 4, which would force ğ‘Œto be larger than ğ‘‹.\nAfter completing the partial memo up to the position of ğ‘‹, we determine that ğ‘‹= $47:\nID/Weight\n0\n1\n2\n3\n4\n5\n0\n$0\n$0\n$0\n$0\n$0\n$0\n1\n$0\n$0\n$27\n$27\n$27\n$27\n2\n$0\n$20\n$27\n$47\n$47\n$47\n3\n$0\n$20\n$27\n$47\nğ‘Œ\n4\n$0\nThus, for our first condition to be true, the value of item 3 cannot exceed $47. This leads us to our second condition: we want item 4\nto always end up in the optimal solution for a knapsack of capacity 5. For this to happen, the value of item 4 must be high enough that\ncombining it with item 1 ($27) would always exceed the value of taking items 2 and 3 instead (we do not need to consider the case of\ntaking item 4 with item 2 here, as this would never be optimal; you can only choose to take one of either items 1 or 2 alongside item 4 if the\nknapsack capacity is 5, and item 1 is worth more). We have determined that the largest possible value of item 3 is $47, so the total combined\nvalue of items 2 and 3 is at most $20 + $47 = $67. Thus, the combined value of taking items 4 and 1 must be at least $68 for item 4 to\nalways be in the optimal solution (a total of $67 would not work here, since we want item 4 to be contained in optimal solutions, whichall\nis not true in the case of a tie). Since item 1 is worth $27, the lowest possible value of item 4 to satisfy both conditions is $68 - $27 = $41.", "answer_embedding": null, "answer_confidence": null, "page_ids": ["1a3da172-d383-5da8-b297-3fd5ea9024dc", "2207e17c-289e-5000-ace5-623e81db7b9b", "5b3eb61a-78ca-5ab0-a3f1-002ac1c1cff4", "6e773b9f-1cda-5ba9-8756-97b6e00119df", "7b7d9dc6-5cd7-52df-b66e-d4548821bf99", "9801d2c0-b83e-52f9-b703-56eeba030479", "9f54d44a-cfe6-57f6-8db2-65e48017568e", "a33ee040-cb9d-5bce-8fe4-7a2149f54fc9", "a732e97e-0ac4-53d2-b683-2ca489c035d6", "a8bd50a1-a8c7-5431-824f-b2983d36f1ed", "afe605f5-a549-5395-b01b-3fe495903bb8", "e0326653-437b-5fe2-9a54-4baf2368d157", "e07bc6fe-0bb9-5892-9565-a839b6bcff01", "eeb12615-da5e-5489-a593-75fa07932e2c", "f0f93193-dc46-5ba5-9f4d-77717945d193", "f5d6b0c4-2db1-5173-8428-b1cf083e7cc4"]}, {"id": null, "qa_id": "802552bb-6e9f-59dc-a756-71c50f5a818e", "book_id": "47bbcc23-9276-5662-9e40-96e8a4841ec7", "section_labels": ["practice", "solutions"], "section_titles": ["Exercise Solutions", "Practice Exercises"], "pdf_page": 994, "problem_key": "5", "answer_number": 5, "answer_choice": "B", "answer_text": "This statement is false, since addition to every edge does not guarantee that the shortest path will remain the\nsame (see example 25.2). Thus, you cannot conclude that the shortest path between node ğ´and node ğµwill go through the same edges.", "answer_embedding": null, "answer_confidence": null, "page_ids": ["1a3da172-d383-5da8-b297-3fd5ea9024dc", "2207e17c-289e-5000-ace5-623e81db7b9b", "5b3eb61a-78ca-5ab0-a3f1-002ac1c1cff4", "6e773b9f-1cda-5ba9-8756-97b6e00119df", "7b25559a-771c-5789-849e-761231306ccf", "7b7d9dc6-5cd7-52df-b66e-d4548821bf99", "9801d2c0-b83e-52f9-b703-56eeba030479", "9f54d44a-cfe6-57f6-8db2-65e48017568e", "a33ee040-cb9d-5bce-8fe4-7a2149f54fc9", "a732e97e-0ac4-53d2-b683-2ca489c035d6", "a8bd50a1-a8c7-5431-824f-b2983d36f1ed", "afe605f5-a549-5395-b01b-3fe495903bb8", "e0326653-437b-5fe2-9a54-4baf2368d157", "e07bc6fe-0bb9-5892-9565-a839b6bcff01", "eeb12615-da5e-5489-a593-75fa07932e2c", "f0f93193-dc46-5ba5-9f4d-77717945d193", "f5d6b0c4-2db1-5173-8428-b1cf083e7cc4"]}, {"id": null, "qa_id": "802552bb-6e9f-59dc-a756-71c50f5a818e", "book_id": "47bbcc23-9276-5662-9e40-96e8a4841ec7", "section_labels": ["practice", "solutions"], "section_titles": ["Exercise Solutions", "Practice Exercises"], "pdf_page": 1053, "problem_key": "5", "answer_number": 5, "answer_choice": "E", "answer_text": "Just knowing that ğ‘„touches ğ‘ƒseven times is not enough to make any conclusion without performing epsilon\ntests in case ğ‘„intersects a vertex of polygon ğ‘ƒ. If you wiggle ğ‘„up and down by some small distance and the number of intersections\nremains odd, you can then conclude that ğ‘„is in the polygon; otherwise, if the number of intersections become even, then you can conclude\nthat ğ‘„is outside the polygon.", "answer_embedding": null, "answer_confidence": null, "page_ids": ["1a3da172-d383-5da8-b297-3fd5ea9024dc", "2207e17c-289e-5000-ace5-623e81db7b9b", "5b3eb61a-78ca-5ab0-a3f1-002ac1c1cff4", "6275fd1a-cffc-5d55-9e15-840a57b06dcd", "6e773b9f-1cda-5ba9-8756-97b6e00119df", "7b25559a-771c-5789-849e-761231306ccf", "7b7d9dc6-5cd7-52df-b66e-d4548821bf99", "9801d2c0-b83e-52f9-b703-56eeba030479", "9f54d44a-cfe6-57f6-8db2-65e48017568e", "a33ee040-cb9d-5bce-8fe4-7a2149f54fc9", "a732e97e-0ac4-53d2-b683-2ca489c035d6", "a8bd50a1-a8c7-5431-824f-b2983d36f1ed", "afe605f5-a549-5395-b01b-3fe495903bb8", "e0326653-437b-5fe2-9a54-4baf2368d157", "e07bc6fe-0bb9-5892-9565-a839b6bcff01", "eeb12615-da5e-5489-a593-75fa07932e2c", "f0f93193-dc46-5ba5-9f4d-77717945d193", "f5d6b0c4-2db1-5173-8428-b1cf083e7cc4"]}]}
{"type": "matched_pair", "qa_id": "8082b655-79af-52f0-8682-b609f627c19f", "question": {"id": null, "qa_id": "8082b655-79af-52f0-8682-b609f627c19f", "book_id": "47bbcc23-9276-5662-9e40-96e8a4841ec7", "section_labels": ["practice", "solutions"], "section_titles": ["Exercise Solutions", "Practice Exercises"], "pdf_page": 955, "problem_key": "16", "question_number": 16, "question_text": "You are given access to proprietary, state-of-the-art trading software that allows you to view the value of certain stocks in the future. You\ncurrent_prices future_prices, current_prices[i]are given two arrays of stock prices, and where represents the price of\nğ‘–th ğ‘–thfuture_prices[i]the stock today, and represents the price of the stock a year from now. Knowing this information, you want\nto maximize your profits by buying these stocks today and selling them a year from now. However, the limitations of the software prevent\nbudgetyou from purchasing more than one share of an individual stock, and you have a that you cannot exceed. Implement a function\nthat returns the maximum total profit you can earn by selecting the stocks to buy within your budget constraints.\nint32_t max_stock_profit(const std::vector<int32_t>& current_prices,\nconst std::vector<int32_t>& int32_tfuture_prices, budget);\n19,Example: Given the following stocks and a budget of $40, you would return since that is the maximum profit you can earn without\ngoing over budget (buying stocks 1 and 3 for $38 today and selling for $57 a year from now):\nStock Number\n0\n1\n2\n3\n4\nCurrent Price\n$11\n$24\n$18\n$14\n$29\nFuture Price\n$17\n$35\n$13\n$22\n$41", "question_embedding": null, "page_ids": ["a33ee040-cb9d-5bce-8fe4-7a2149f54fc9", "cba6a615-1ed5-524b-b8f5-2097b53ee531", "f6099dd1-8ca5-5a05-8f00-ca473fc97adc"]}, "answers": [{"id": null, "qa_id": "8082b655-79af-52f0-8682-b609f627c19f", "book_id": "47bbcc23-9276-5662-9e40-96e8a4841ec7", "section_labels": ["practice", "solutions"], "section_titles": ["Exercise Solutions", "Practice Exercises"], "pdf_page": 126, "problem_key": "16", "answer_number": 16, "answer_choice": "B", "answer_text": "If is bounded above by and bounded below by ğ¶(ğ‘›), and all three functions are strictly increasing,ğ´(ğ‘›) ğµ(ğ‘›)\nthen must also be bounded below by (otherwise, it could not be an upper bound to ğ´(ğ‘›), which is also bounded below by ğ¶(ğ‘›)).ğµ(ğ‘›) ğ¶(ğ‘›)\nThis matches option (B). Note that the other three options are all possible, but only (B) is true in all cases.", "answer_embedding": null, "answer_confidence": null, "page_ids": ["cba6a615-1ed5-524b-b8f5-2097b53ee531", "f6099dd1-8ca5-5a05-8f00-ca473fc97adc"]}, {"id": null, "qa_id": "8082b655-79af-52f0-8682-b609f627c19f", "book_id": "47bbcc23-9276-5662-9e40-96e8a4841ec7", "section_labels": ["practice", "solutions"], "section_titles": ["Exercise Solutions", "Practice Exercises"], "pdf_page": 771, "problem_key": "16", "answer_number": 16, "answer_choice": "D", "answer_text": "A breadth-first search encounters vertices in order of distance from the source node. In this case, the path\nlength from ğ‘†to ğ·is longer than the path length from ğ‘†to any other vertex, so vertex ğ·would be discovered last during the search.", "answer_embedding": null, "answer_confidence": null, "page_ids": ["a33ee040-cb9d-5bce-8fe4-7a2149f54fc9", "cba6a615-1ed5-524b-b8f5-2097b53ee531", "f6099dd1-8ca5-5a05-8f00-ca473fc97adc"]}]}
{"type": "matched_pair", "qa_id": "c645464f-3f7f-5e4b-b177-4887b1380452", "question": {"id": null, "qa_id": "c645464f-3f7f-5e4b-b177-4887b1380452", "book_id": "47bbcc23-9276-5662-9e40-96e8a4841ec7", "section_labels": ["practice", "solutions"], "section_titles": ["Exercise Solutions", "Practice Exercises"], "pdf_page": 1050, "problem_key": "2", "question_number": 2, "question_text": "You are given an array of ğ‘›points on an ğ‘¥ğ‘¦-plane, and you want to find the closest pair of points in the array. Which of the following\nstatements is TRUE?\nÎ˜(ğ‘›2)An optimal brute force solution for this problem runs in time, and an optimal divide-and-conquer solution runs inA) Î˜(ğ‘›log(ğ‘›))\ntime\nÎ˜(2ğ‘›)B) An optimal brute force solution for this problem runs in time, and an optimal divide-and-conquer solution runs in Î˜(ğ‘›log(ğ‘›))\ntime\nÎ˜(ğ‘›2)C) An optimal brute force solution for this problem runs in time, and an optimal divide-and-conquer solution runs in Î˜(log(ğ‘›))\ntime\nÎ˜(2ğ‘›)D) An optimal brute force solution for this problem runs in time, and an optimal divide-and-conquer solution runs in Î˜(log(ğ‘›))\ntime\nÎ˜(2ğ‘›) Î˜(ğ‘›2)E) An optimal brute force solution for this problem runs in time, and an optimal divide-and-conquer solution runs in time\nğ‘¥â‰¥1 ğ‘¦â‰¥1.3. Youaregivenğ‘›linesegments, whoseendpointshaveintegercoordinates where and Thetwoendpointsofanylinesegment(ğ‘¥,ğ‘¦)\nare distinct, and ğ‘›is guaranteed to be non-zero. Consider the following function:\n1\nstruct int32_t int32_tPoint { x; y; };\n2\nstruct Segment { Point a; Point b; };\n3\n4\ndouble foo(const std::vector<Segment>& segments) {\n5\nstd::vector<std::pair<double, int32_t>> ends;\n6\nfor (const Segment& s : segments) {\n7\ndouble static_cast<double>(s.a.y) static_cast<double>(s.a.x);slope_a = /\n8\ndouble static_cast<double>(s.b.y) static_cast<double>(s.b.x);slope_b = /\n9\nends.push_back({std::min(slope_a, slope_b), -1});\n10\nends.push_back({std::max(slope_a, slope_b), +1});\n11\n} // for s\n12\nstd::sort(ends.begin(), ends.end());\n13\nint32_t count = 0, best = 0;\n14\ndouble slope = 0;\n15\nfor (const auto& p : ends) {\n16\ncount -= p.second;\n17\nif (count > best) {\n18\nbest = count;\n19\nslope = p.first;\n20\n} // if\n21\n} // for end\n22\nreturn slope;\n23\n} // foo()\nWhat does this function attempt to do, given a vector of line segments?\nA) It returns the slope of the longest line segment in the vector\nB) It returns the slope of a line through the origin that crosses as few line segments as possible\nC) It returns the slope of a line through the origin that crosses as many line segments as possible\nD) It returns the slope of a line that crosses as many segment endpoints as possible\nE) It returns the slope that is shared by the greatest number of line segments in the vector", "question_embedding": null, "page_ids": ["2207e17c-289e-5000-ace5-623e81db7b9b", "2afd0c50-ab9c-5b1e-acab-c7e93b22bf80", "5b3eb61a-78ca-5ab0-a3f1-002ac1c1cff4", "6275fd1a-cffc-5d55-9e15-840a57b06dcd", "6e773b9f-1cda-5ba9-8756-97b6e00119df", "7b25559a-771c-5789-849e-761231306ccf", "8c8f8242-6e2b-563a-af29-ebd95912031a", "8f645308-041e-5dc2-8a84-efc4ca2daac4", "942883f1-20a5-56b3-a5e0-a9ffafda687c", "9f54d44a-cfe6-57f6-8db2-65e48017568e", "a33ee040-cb9d-5bce-8fe4-7a2149f54fc9", "a732e97e-0ac4-53d2-b683-2ca489c035d6", "a8bd50a1-a8c7-5431-824f-b2983d36f1ed", "afe605f5-a549-5395-b01b-3fe495903bb8", "e07bc6fe-0bb9-5892-9565-a839b6bcff01", "eeb12615-da5e-5489-a593-75fa07932e2c", "f0f93193-dc46-5ba5-9f4d-77717945d193", "f5d6b0c4-2db1-5173-8428-b1cf083e7cc4", "f6099dd1-8ca5-5a05-8f00-ca473fc97adc"]}, "answers": [{"id": null, "qa_id": "c645464f-3f7f-5e4b-b177-4887b1380452", "book_id": "47bbcc23-9276-5662-9e40-96e8a4841ec7", "section_labels": ["practice", "solutions"], "section_titles": ["Exercise Solutions", "Practice Exercises"], "pdf_page": 126, "problem_key": "2", "answer_number": 2, "answer_choice": "A", "answer_text": "None of the statements are true. The asymptotic efficiency of algorithms deals with how runtime increases\nÎ˜(ğ‘›2)with the size of the input as the size of the input increases bound. For instance, as the size of the input grows, we can reason that a\nalgorithm will see its runtime increase much more drastically than a algorithm. However, it does not guarantee that an algorithmÎ˜(ğ‘›log(ğ‘›))\nÎ˜(ğ‘›2)with a time complexity will always run faster than an algorithm with a time complexity, since there are other factorsÎ˜(ğ‘›log(ğ‘›))\nat play (e.g., the algorithm with the larger complexity class may have been run in a best-case scenario or may have better constants and\nlower-order terms that make it faster for a given input size).", "answer_embedding": null, "answer_confidence": null, "page_ids": ["8c8f8242-6e2b-563a-af29-ebd95912031a", "f6099dd1-8ca5-5a05-8f00-ca473fc97adc"]}, {"id": null, "qa_id": "c645464f-3f7f-5e4b-b177-4887b1380452", "book_id": "47bbcc23-9276-5662-9e40-96e8a4841ec7", "section_labels": ["practice", "solutions"], "section_titles": ["Exercise Solutions", "Practice Exercises"], "pdf_page": 161, "problem_key": "2", "answer_number": 2, "answer_choice": "B", "answer_text": "This function is not tail recursive, so additional stack frames will be needed for the recursive call on line 5.\nHow many stack frames are needed? The number of stack frames needed is equal to the number of recursive calls we will encounter before\nreaching the base case; since we are halving ğ‘›with each recursive call, this comes out to Î˜(log(ğ‘›)). The function uses constant auxiliary\nspace outside the recursive call, so we can conclude that the auxiliary space usage of the entire function is also Î˜(log(ğ‘›)).", "answer_embedding": null, "answer_confidence": null, "page_ids": ["8c8f8242-6e2b-563a-af29-ebd95912031a", "afe605f5-a549-5395-b01b-3fe495903bb8", "f6099dd1-8ca5-5a05-8f00-ca473fc97adc"]}, {"id": null, "qa_id": "c645464f-3f7f-5e4b-b177-4887b1380452", "book_id": "47bbcc23-9276-5662-9e40-96e8a4841ec7", "section_labels": ["practice", "solutions"], "section_titles": ["Exercise Solutions", "Practice Exercises"], "pdf_page": 188, "problem_key": "2", "answer_number": 2, "answer_choice": "D", "answer_text": "Using the formula for calculating the index, we get row num_columns + column = 5 9 + 6 = 45 + 6 = 51.Ã— Ã—\nj sz - 1, arr[sz], j3. The correct answer is (D). When has a value of the program attempts to access which is invalid. To fix this, must\nsz - 1 sz.be less than rather than just\nThe correct answer is (A). Statement (A) is false, since the copy constructor is not the only thing that needs to be overloaded for the4.\ncontainer to manage its dynamic memory properly. You will also need to implement the other members of the big three (destructor and\noverloaded assignment operator).", "answer_embedding": null, "answer_confidence": null, "page_ids": ["2207e17c-289e-5000-ace5-623e81db7b9b", "8c8f8242-6e2b-563a-af29-ebd95912031a", "afe605f5-a549-5395-b01b-3fe495903bb8", "f6099dd1-8ca5-5a05-8f00-ca473fc97adc"]}, {"id": null, "qa_id": "c645464f-3f7f-5e4b-b177-4887b1380452", "book_id": "47bbcc23-9276-5662-9e40-96e8a4841ec7", "section_labels": ["practice", "solutions"], "section_titles": ["Exercise Solutions", "Practice Exercises"], "pdf_page": 211, "problem_key": "2", "answer_number": 2, "answer_choice": "D", "answer_text": "The worst-case time complexity of insertion assuming reallocation is Î˜(ğ‘›), since you would have to move\nall the existing data to a new underlying array. Without reallocation, however, the worst-case time complexity could still be if theÎ˜(ğ‘›)\ninsertion takes place at the front of the vector, which would require all subsequent elements to be shifted over by one position.\n.resize()3. The correct answer is (D). When you call on a vector, you actually change the number of elements it contains. On the\n.reserve(),other hand, if you call you only reserve space for more elements, but you do not create them. Hence, you cannot use\n.push_back() on a vector that has been resized, since you would be adding elements on top of the elements you already created using\n.resize() (i.e., if you want 20 elements in your vector and nothing more, resizing the vector would initialize 20 elements in the vector,\n.push_back()and using would add a 21st element instead of modifying the 1st element). Meanwhile, after reserving space for a vector\nto hold more elements, you still must add the elements themselves. For instance, if you reserve a vector to hold 20 elements, it now has the\ncapacity to hold 20 elements, but it does not actually have any elements yet (similar to how an empty 5-gallon bucket hold 5 gallons ofcan\noperator[]water, butitdoesnotactuallyholdanywater). Thus, youcannotuse onavectorthatonlyhasspacereserved, astheelements\nyou want to create do not exist yet. The only ways to ensure that a vector has the number of elements you want it to have are to either resize\noperator[] .push_back().the vector and modify each element using or reserve space for the vector and add the elements using", "answer_embedding": null, "answer_confidence": null, "page_ids": ["2207e17c-289e-5000-ace5-623e81db7b9b", "8c8f8242-6e2b-563a-af29-ebd95912031a", "afe605f5-a549-5395-b01b-3fe495903bb8", "eeb12615-da5e-5489-a593-75fa07932e2c", "f6099dd1-8ca5-5a05-8f00-ca473fc97adc"]}, {"id": null, "qa_id": "c645464f-3f7f-5e4b-b177-4887b1380452", "book_id": "47bbcc23-9276-5662-9e40-96e8a4841ec7", "section_labels": ["practice", "solutions"], "section_titles": ["Exercise Solutions", "Practice Exercises"], "pdf_page": 246, "problem_key": "2", "answer_number": 2, "answer_choice": "D", "answer_text": "You cannot remove the last element in a singly-linked list in constant time, regardless of whether you have a tail\nnext nullptr,pointer or not. This is because you have to set the pointer of the node before the one being deleted to which you cannot\naccess in constant time if the list is singly-linked. Option (A) is true, because you need to visit every value in the list during a traversal,\nwhich takes since it takes constant time to visit each element. Option (B) is true if the element you want to find is the last one youÎ˜(ğ‘›)\nencounter in the list (or if it does not exist in the list). Option (C) is correct because, if you are given a pointer to the element to insert at,\nyou can set its internal pointers after the insertion without have to do a separate traversal.", "answer_embedding": null, "answer_confidence": null, "page_ids": ["2207e17c-289e-5000-ace5-623e81db7b9b", "8c8f8242-6e2b-563a-af29-ebd95912031a", "8f645308-041e-5dc2-8a84-efc4ca2daac4", "afe605f5-a549-5395-b01b-3fe495903bb8", "eeb12615-da5e-5489-a593-75fa07932e2c", "f6099dd1-8ca5-5a05-8f00-ca473fc97adc"]}, {"id": null, "qa_id": "c645464f-3f7f-5e4b-b177-4887b1380452", "book_id": "47bbcc23-9276-5662-9e40-96e8a4841ec7", "section_labels": ["practice", "solutions"], "section_titles": ["Exercise Solutions", "Practice Exercises"], "pdf_page": 328, "problem_key": "2", "answer_number": 2, "answer_choice": "C", "answer_text": "If the underlying priority queue container is unsorted, then the item with the highest priority that you want\nto remove could be anywhere in the container, which would require a linear search before you can remove it. On the other hand, if the\ncontainer is sorted, you know where the highest priority element is and can remove it in constant time.\n3. Thecorrectansweris(B).Whilealloftheseoptionsinvolveachoicetobemadedependingonsomesortofpriority(suchastheimportance\nof an exam), the scenario in option (B) bases its priority on FIFO arrival order, which is more similar to the functionality of a standard\nqueue rather than a priority queue.", "answer_embedding": null, "answer_confidence": null, "page_ids": ["2207e17c-289e-5000-ace5-623e81db7b9b", "8c8f8242-6e2b-563a-af29-ebd95912031a", "8f645308-041e-5dc2-8a84-efc4ca2daac4", "a732e97e-0ac4-53d2-b683-2ca489c035d6", "afe605f5-a549-5395-b01b-3fe495903bb8", "eeb12615-da5e-5489-a593-75fa07932e2c", "f6099dd1-8ca5-5a05-8f00-ca473fc97adc"]}, {"id": null, "qa_id": "c645464f-3f7f-5e4b-b177-4887b1380452", "book_id": "47bbcc23-9276-5662-9e40-96e8a4841ec7", "section_labels": ["practice", "solutions"], "section_titles": ["Exercise Solutions", "Practice Exercises"], "pdf_page": 383, "problem_key": "2", "answer_number": 2, "answer_choice": "D", "answer_text": "Many implementations of STL algorithms are public for anyone to view, so option (D) is false. Options (A),\n(B), and (C) are all true: the STL can make code more concise and readable, since you can just include and use a pre-implemented function\nthat satisfies your needs; the STL allows reuse of algorithms with different data structures through the use of iterators; and the STL can\nminimize explicit dynamic memory usage by handling memory allocation behind the scenes for you.\nstd::sort()3. The correct answer is (D). The STL algorithm libraryâ€™s algorithm takes in two random access iterators. Containers\nstd::sort().that have iterators that do not support random access (such as lists) cannot be sorted using Statements I and III are true:\nstd::sort() runs in worst-case time, and it can be used to sort a vector of strings (in fact, if a container supports randomÎ˜(ğ‘›log(ğ‘›))\nstd::sort() operator<access iterators, can sort the container as long as the type of its elements supports or can be compared using\nthe passed in comparator argument).\n.rend()4. The correct answer is (D). The reverse iterator returned by points to the theoretical position the first element in abefore\n.end(),container, and not the last element itself (you can think of this as analogous to which points to the position one past the end, and\nnot the last element itself). All of the other options are true.", "answer_embedding": null, "answer_confidence": null, "page_ids": ["2207e17c-289e-5000-ace5-623e81db7b9b", "8c8f8242-6e2b-563a-af29-ebd95912031a", "8f645308-041e-5dc2-8a84-efc4ca2daac4", "9f54d44a-cfe6-57f6-8db2-65e48017568e", "a732e97e-0ac4-53d2-b683-2ca489c035d6", "afe605f5-a549-5395-b01b-3fe495903bb8", "eeb12615-da5e-5489-a593-75fa07932e2c", "f6099dd1-8ca5-5a05-8f00-ca473fc97adc"]}, {"id": null, "qa_id": "c645464f-3f7f-5e4b-b177-4887b1380452", "book_id": "47bbcc23-9276-5662-9e40-96e8a4841ec7", "section_labels": ["practice", "solutions"], "section_titles": ["Exercise Solutions", "Practice Exercises"], "pdf_page": 400, "problem_key": "2", "answer_number": 2, "answer_choice": "B", "answer_text": "In amortized analysis, we average the time required to perform a sequence of operations over all the operations\n.shove_back() .push_back()performed. Since the special operation works similarly to when the array is not at capacity, we\n.shove_back()would expect such a call for to take time. However, when the array is at full capacity, we have to reallocate andÎ˜(1)\nsort the contents of the original array, which takes a dominating time. Using aggregate analysis, we therefore see that theÎ˜(ğ‘›log(ğ‘›))\n.shove_back()amortized complexity of a call to is Î˜(log(ğ‘›)).Î˜(ğ‘›log(ğ‘›))âˆ•ğ‘›=", "answer_embedding": null, "answer_confidence": null, "page_ids": ["2207e17c-289e-5000-ace5-623e81db7b9b", "6e773b9f-1cda-5ba9-8756-97b6e00119df", "8c8f8242-6e2b-563a-af29-ebd95912031a", "8f645308-041e-5dc2-8a84-efc4ca2daac4", "9f54d44a-cfe6-57f6-8db2-65e48017568e", "a732e97e-0ac4-53d2-b683-2ca489c035d6", "afe605f5-a549-5395-b01b-3fe495903bb8", "eeb12615-da5e-5489-a593-75fa07932e2c", "f6099dd1-8ca5-5a05-8f00-ca473fc97adc"]}, {"id": null, "qa_id": "c645464f-3f7f-5e4b-b177-4887b1380452", "book_id": "47bbcc23-9276-5662-9e40-96e8a4841ec7", "section_labels": ["practice", "solutions"], "section_titles": ["Exercise Solutions", "Practice Exercises"], "pdf_page": 453, "problem_key": "2", "answer_number": 2, "answer_choice": "A", "answer_text": "Of the 5 sorting algorithms, insertion sort is adaptive, which allows it to perform better on nearly sorted input.", "answer_embedding": null, "answer_confidence": null, "page_ids": ["2207e17c-289e-5000-ace5-623e81db7b9b", "5b3eb61a-78ca-5ab0-a3f1-002ac1c1cff4", "6e773b9f-1cda-5ba9-8756-97b6e00119df", "8c8f8242-6e2b-563a-af29-ebd95912031a", "8f645308-041e-5dc2-8a84-efc4ca2daac4", "9f54d44a-cfe6-57f6-8db2-65e48017568e", "a732e97e-0ac4-53d2-b683-2ca489c035d6", "afe605f5-a549-5395-b01b-3fe495903bb8", "eeb12615-da5e-5489-a593-75fa07932e2c", "f6099dd1-8ca5-5a05-8f00-ca473fc97adc"]}, {"id": null, "qa_id": "c645464f-3f7f-5e4b-b177-4887b1380452", "book_id": "47bbcc23-9276-5662-9e40-96e8a4841ec7", "section_labels": ["practice", "solutions"], "section_titles": ["Exercise Solutions", "Practice Exercises"], "pdf_page": 491, "problem_key": "2", "answer_number": 2, "answer_choice": "D", "answer_text": "The doubly-linked list is the only container that supports before any given iterator. Arrays and dequesÎ˜(1)\nmay require elements to be shifted after the insertion point, which could take time. Singly-linked lists do not provide direct access toÎ˜(ğ‘›)\nprevious node, so you may need a traversal to find and update the next pointer of the the node directly before the insertion point.Î˜(ğ‘›)\n[1, 3, 2, 6, 5, 4]3. The correct answer is (D). The data vector of a binary heap is neither sorted nor ordered. For example, is a\nvalid min-binary heap, but the contents of the vector are not sorted in ascending order. Additionally, adding an element to a binary heap\nmay change the relative ordering of elements already in the heap, which indicates that the data vector is also not ordered. To illustrate this,\n[8, 2, 4]:consider the array representation of\n8\n4\n2\nNow, letâ€™s add 9 to the binary heap and fix the heap invariant:\n8\n4\n2\n9\n8\n4\n9\n2\n9\n4\n8\n2\n[9, 8, 4, 2].The underlying data vector of the binary heap now stores the values Notice that the relative order of 2 and 4 were\nswitched after the insertion, with 2 now ending up after 4 when it was before 4 earlier.", "answer_embedding": null, "answer_confidence": null, "page_ids": ["2207e17c-289e-5000-ace5-623e81db7b9b", "5b3eb61a-78ca-5ab0-a3f1-002ac1c1cff4", "6e773b9f-1cda-5ba9-8756-97b6e00119df", "8c8f8242-6e2b-563a-af29-ebd95912031a", "8f645308-041e-5dc2-8a84-efc4ca2daac4", "9f54d44a-cfe6-57f6-8db2-65e48017568e", "a732e97e-0ac4-53d2-b683-2ca489c035d6", "afe605f5-a549-5395-b01b-3fe495903bb8", "eeb12615-da5e-5489-a593-75fa07932e2c", "f0f93193-dc46-5ba5-9f4d-77717945d193", "f6099dd1-8ca5-5a05-8f00-ca473fc97adc"]}, {"id": null, "qa_id": "c645464f-3f7f-5e4b-b177-4887b1380452", "book_id": "47bbcc23-9276-5662-9e40-96e8a4841ec7", "section_labels": ["practice", "solutions"], "section_titles": ["Exercise Solutions", "Practice Exercises"], "pdf_page": 689, "problem_key": "2", "answer_number": 2, "answer_choice": "E", "answer_text": "An internal node has children; all four nodes have children, so they are all internal nodes.\n2ğ‘›âˆ’13. The correct answer is (E). In the case of a rightward-facing stick tree, the last element would be found at index for an array-based\nÎ˜(2ğ‘›).binary tree. Thus, the worst-case auxiliary space complexity would be", "answer_embedding": null, "answer_confidence": null, "page_ids": ["2207e17c-289e-5000-ace5-623e81db7b9b", "5b3eb61a-78ca-5ab0-a3f1-002ac1c1cff4", "6e773b9f-1cda-5ba9-8756-97b6e00119df", "8c8f8242-6e2b-563a-af29-ebd95912031a", "8f645308-041e-5dc2-8a84-efc4ca2daac4", "942883f1-20a5-56b3-a5e0-a9ffafda687c", "9f54d44a-cfe6-57f6-8db2-65e48017568e", "a732e97e-0ac4-53d2-b683-2ca489c035d6", "afe605f5-a549-5395-b01b-3fe495903bb8", "eeb12615-da5e-5489-a593-75fa07932e2c", "f0f93193-dc46-5ba5-9f4d-77717945d193", "f6099dd1-8ca5-5a05-8f00-ca473fc97adc"]}, {"id": null, "qa_id": "c645464f-3f7f-5e4b-b177-4887b1380452", "book_id": "47bbcc23-9276-5662-9e40-96e8a4841ec7", "section_labels": ["practice", "solutions"], "section_titles": ["Exercise Solutions", "Practice Exercises"], "pdf_page": 771, "problem_key": "2", "answer_number": 2, "answer_choice": "B", "answer_text": "This statement is not always true: parallel edges may exist that have different weights.The distance required to\ngo to a certain vertex may be different depending on the path you take.", "answer_embedding": null, "answer_confidence": null, "page_ids": ["2207e17c-289e-5000-ace5-623e81db7b9b", "5b3eb61a-78ca-5ab0-a3f1-002ac1c1cff4", "6e773b9f-1cda-5ba9-8756-97b6e00119df", "8c8f8242-6e2b-563a-af29-ebd95912031a", "8f645308-041e-5dc2-8a84-efc4ca2daac4", "942883f1-20a5-56b3-a5e0-a9ffafda687c", "9f54d44a-cfe6-57f6-8db2-65e48017568e", "a33ee040-cb9d-5bce-8fe4-7a2149f54fc9", "a732e97e-0ac4-53d2-b683-2ca489c035d6", "afe605f5-a549-5395-b01b-3fe495903bb8", "eeb12615-da5e-5489-a593-75fa07932e2c", "f0f93193-dc46-5ba5-9f4d-77717945d193", "f6099dd1-8ca5-5a05-8f00-ca473fc97adc"]}, {"id": null, "qa_id": "c645464f-3f7f-5e4b-b177-4887b1380452", "book_id": "47bbcc23-9276-5662-9e40-96e8a4841ec7", "section_labels": ["practice", "solutions"], "section_titles": ["Exercise Solutions", "Practice Exercises"], "pdf_page": 826, "problem_key": "2", "answer_number": 2, "answer_choice": "E", "answer_text": "Both (B) and (D) are optimization problems: (B) seeks to find the maximum profits under a set of constraints,\nwhile (D) seeks to find the minimum total weight required to connect all vertices in a graph.", "answer_embedding": null, "answer_confidence": null, "page_ids": ["2207e17c-289e-5000-ace5-623e81db7b9b", "5b3eb61a-78ca-5ab0-a3f1-002ac1c1cff4", "6e773b9f-1cda-5ba9-8756-97b6e00119df", "8c8f8242-6e2b-563a-af29-ebd95912031a", "8f645308-041e-5dc2-8a84-efc4ca2daac4", "942883f1-20a5-56b3-a5e0-a9ffafda687c", "9f54d44a-cfe6-57f6-8db2-65e48017568e", "a33ee040-cb9d-5bce-8fe4-7a2149f54fc9", "a732e97e-0ac4-53d2-b683-2ca489c035d6", "a8bd50a1-a8c7-5431-824f-b2983d36f1ed", "afe605f5-a549-5395-b01b-3fe495903bb8", "eeb12615-da5e-5489-a593-75fa07932e2c", "f0f93193-dc46-5ba5-9f4d-77717945d193", "f6099dd1-8ca5-5a05-8f00-ca473fc97adc"]}, {"id": null, "qa_id": "c645464f-3f7f-5e4b-b177-4887b1380452", "book_id": "47bbcc23-9276-5662-9e40-96e8a4841ec7", "section_labels": ["practice", "solutions"], "section_titles": ["Exercise Solutions", "Practice Exercises"], "pdf_page": 873, "problem_key": "2", "answer_number": 2, "answer_choice": "D", "answer_text": "Only statement II is false, since branch and bound continues to explore the remaining search space in case\na better solution can be found. Statement I is true, since branch and bound can be used to find the optimal solution of a problem, and\nstatement III is true, since a pruning function that prunes too much can result in an incorrect solution, and a pruning function that prunes\ntoo little may degrade performance since time is spent exploring paths that could have been discarded.", "answer_embedding": null, "answer_confidence": null, "page_ids": ["2207e17c-289e-5000-ace5-623e81db7b9b", "5b3eb61a-78ca-5ab0-a3f1-002ac1c1cff4", "6e773b9f-1cda-5ba9-8756-97b6e00119df", "8c8f8242-6e2b-563a-af29-ebd95912031a", "8f645308-041e-5dc2-8a84-efc4ca2daac4", "942883f1-20a5-56b3-a5e0-a9ffafda687c", "9f54d44a-cfe6-57f6-8db2-65e48017568e", "a33ee040-cb9d-5bce-8fe4-7a2149f54fc9", "a732e97e-0ac4-53d2-b683-2ca489c035d6", "a8bd50a1-a8c7-5431-824f-b2983d36f1ed", "afe605f5-a549-5395-b01b-3fe495903bb8", "e07bc6fe-0bb9-5892-9565-a839b6bcff01", "eeb12615-da5e-5489-a593-75fa07932e2c", "f0f93193-dc46-5ba5-9f4d-77717945d193", "f6099dd1-8ca5-5a05-8f00-ca473fc97adc"]}, {"id": null, "qa_id": "c645464f-3f7f-5e4b-b177-4887b1380452", "book_id": "47bbcc23-9276-5662-9e40-96e8a4841ec7", "section_labels": ["practice", "solutions"], "section_titles": ["Exercise Solutions", "Practice Exercises"], "pdf_page": 931, "problem_key": "2", "answer_number": 2, "answer_choice": "D", "answer_text": "Statement (D) is false because divide-and-conquer is used to solve problems with independent subproblems,\nwhile dynamic programming is best used to for problems with overlapping (dependent) subproblems. Statement (A) is true because the\nsolution of a repeated subproblem is stored in a memo the first time it is computed, so that it does not need to be recomputed if it is needed\nagain. Statement (B) is true because top-down dynamic programming only computes subproblems that are encountered during the recursive\ncalls down to the base case. Statement (C) is true because dynamic programming can bring down the runtime of a recursive function by\nstoring the solutions of repeated subproblems so that they donâ€™t need to be recomputed.", "answer_embedding": null, "answer_confidence": null, "page_ids": ["2207e17c-289e-5000-ace5-623e81db7b9b", "2afd0c50-ab9c-5b1e-acab-c7e93b22bf80", "5b3eb61a-78ca-5ab0-a3f1-002ac1c1cff4", "6e773b9f-1cda-5ba9-8756-97b6e00119df", "8c8f8242-6e2b-563a-af29-ebd95912031a", "8f645308-041e-5dc2-8a84-efc4ca2daac4", "942883f1-20a5-56b3-a5e0-a9ffafda687c", "9f54d44a-cfe6-57f6-8db2-65e48017568e", "a33ee040-cb9d-5bce-8fe4-7a2149f54fc9", "a732e97e-0ac4-53d2-b683-2ca489c035d6", "a8bd50a1-a8c7-5431-824f-b2983d36f1ed", "afe605f5-a549-5395-b01b-3fe495903bb8", "e07bc6fe-0bb9-5892-9565-a839b6bcff01", "eeb12615-da5e-5489-a593-75fa07932e2c", "f0f93193-dc46-5ba5-9f4d-77717945d193", "f6099dd1-8ca5-5a05-8f00-ca473fc97adc"]}, {"id": null, "qa_id": "c645464f-3f7f-5e4b-b177-4887b1380452", "book_id": "47bbcc23-9276-5662-9e40-96e8a4841ec7", "section_labels": ["practice", "solutions"], "section_titles": ["Exercise Solutions", "Practice Exercises"], "pdf_page": 958, "problem_key": "2", "answer_number": 2, "answer_choice": "B", "answer_text": "There are a total of ğ‘›ğ‘subproblems that need to be solved, each taking time (see section 24.2.3). Since weÎ˜(1)\nonly solve each unique subproblem once using dynamic programming, the overall time complexity of a DP solution is Î˜(ğ‘›ğ‘).", "answer_embedding": null, "answer_confidence": null, "page_ids": ["2207e17c-289e-5000-ace5-623e81db7b9b", "2afd0c50-ab9c-5b1e-acab-c7e93b22bf80", "5b3eb61a-78ca-5ab0-a3f1-002ac1c1cff4", "6e773b9f-1cda-5ba9-8756-97b6e00119df", "8c8f8242-6e2b-563a-af29-ebd95912031a", "8f645308-041e-5dc2-8a84-efc4ca2daac4", "942883f1-20a5-56b3-a5e0-a9ffafda687c", "9f54d44a-cfe6-57f6-8db2-65e48017568e", "a33ee040-cb9d-5bce-8fe4-7a2149f54fc9", "a732e97e-0ac4-53d2-b683-2ca489c035d6", "a8bd50a1-a8c7-5431-824f-b2983d36f1ed", "afe605f5-a549-5395-b01b-3fe495903bb8", "e07bc6fe-0bb9-5892-9565-a839b6bcff01", "eeb12615-da5e-5489-a593-75fa07932e2c", "f0f93193-dc46-5ba5-9f4d-77717945d193", "f5d6b0c4-2db1-5173-8428-b1cf083e7cc4", "f6099dd1-8ca5-5a05-8f00-ca473fc97adc"]}, {"id": null, "qa_id": "c645464f-3f7f-5e4b-b177-4887b1380452", "book_id": "47bbcc23-9276-5662-9e40-96e8a4841ec7", "section_labels": ["practice", "solutions"], "section_titles": ["Exercise Solutions", "Practice Exercises"], "pdf_page": 994, "problem_key": "2", "answer_number": 2, "answer_choice": "B", "answer_text": "Only statement II is true. Statement I is false because Dijkstraâ€™s algorithm is not limited to undirected graphs,\nas directed graphs are supported without any issues. Statement III is false because Dijkstraâ€™s algorithm can only find the shortest path to\neach vertex from a single source vertex, rather than for all pairs of vertices, if it is only run once. Statement II is true because the linear\n|ğ‘‰|2,|ğ¸|search implementation is preferred for dense graphs, as the number of edges is on the order of which would cause the priority\nÎ˜(|ğ‘‰|2 Î˜(|ğ‘‰|2)Î˜(|ğ¸|log(|ğ‘‰|)) log(|ğ‘‰|)),queue implementation to run with a time complexity of as opposed to for a linear search.=", "answer_embedding": null, "answer_confidence": null, "page_ids": ["2207e17c-289e-5000-ace5-623e81db7b9b", "2afd0c50-ab9c-5b1e-acab-c7e93b22bf80", "5b3eb61a-78ca-5ab0-a3f1-002ac1c1cff4", "6e773b9f-1cda-5ba9-8756-97b6e00119df", "7b25559a-771c-5789-849e-761231306ccf", "8c8f8242-6e2b-563a-af29-ebd95912031a", "8f645308-041e-5dc2-8a84-efc4ca2daac4", "942883f1-20a5-56b3-a5e0-a9ffafda687c", "9f54d44a-cfe6-57f6-8db2-65e48017568e", "a33ee040-cb9d-5bce-8fe4-7a2149f54fc9", "a732e97e-0ac4-53d2-b683-2ca489c035d6", "a8bd50a1-a8c7-5431-824f-b2983d36f1ed", "afe605f5-a549-5395-b01b-3fe495903bb8", "e07bc6fe-0bb9-5892-9565-a839b6bcff01", "eeb12615-da5e-5489-a593-75fa07932e2c", "f0f93193-dc46-5ba5-9f4d-77717945d193", "f5d6b0c4-2db1-5173-8428-b1cf083e7cc4", "f6099dd1-8ca5-5a05-8f00-ca473fc97adc"]}, {"id": null, "qa_id": "c645464f-3f7f-5e4b-b177-4887b1380452", "book_id": "47bbcc23-9276-5662-9e40-96e8a4841ec7", "section_labels": ["practice", "solutions"], "section_titles": ["Exercise Solutions", "Practice Exercises"], "pdf_page": 1053, "problem_key": "2", "answer_number": 2, "answer_choice": "A", "answer_text": "With a brute force approach, you would need to check the distances between every pair of points and take the\nÎ˜(ğ‘›2) Î˜(ğ‘›2)minimum; this would take since there are pairs that will need to be checked. With divide-and-conquer, the time complexity of\nsolving this problem can be brought down to Î˜(ğ‘›log(ğ‘›)), with an explanation of this process covered in section 26.3.2.", "answer_embedding": null, "answer_confidence": null, "page_ids": ["2207e17c-289e-5000-ace5-623e81db7b9b", "2afd0c50-ab9c-5b1e-acab-c7e93b22bf80", "5b3eb61a-78ca-5ab0-a3f1-002ac1c1cff4", "6275fd1a-cffc-5d55-9e15-840a57b06dcd", "6e773b9f-1cda-5ba9-8756-97b6e00119df", "7b25559a-771c-5789-849e-761231306ccf", "8c8f8242-6e2b-563a-af29-ebd95912031a", "8f645308-041e-5dc2-8a84-efc4ca2daac4", "942883f1-20a5-56b3-a5e0-a9ffafda687c", "9f54d44a-cfe6-57f6-8db2-65e48017568e", "a33ee040-cb9d-5bce-8fe4-7a2149f54fc9", "a732e97e-0ac4-53d2-b683-2ca489c035d6", "a8bd50a1-a8c7-5431-824f-b2983d36f1ed", "afe605f5-a549-5395-b01b-3fe495903bb8", "e07bc6fe-0bb9-5892-9565-a839b6bcff01", "eeb12615-da5e-5489-a593-75fa07932e2c", "f0f93193-dc46-5ba5-9f4d-77717945d193", "f5d6b0c4-2db1-5173-8428-b1cf083e7cc4", "f6099dd1-8ca5-5a05-8f00-ca473fc97adc"]}]}
{"type": "matched_pair", "qa_id": "c9e4ff44-af5a-5782-ad04-fc12ef8e0725", "question": {"id": null, "qa_id": "c9e4ff44-af5a-5782-ad04-fc12ef8e0725", "book_id": "47bbcc23-9276-5662-9e40-96e8a4841ec7", "section_labels": ["practice", "solutions"], "section_titles": ["Exercise Solutions", "Practice Exercises"], "pdf_page": 765, "problem_key": "7", "question_number": 7, "question_text": "Suppose you have a binary tree of height 281, where the leaf nodes have height 1, and you want to search for an element ğ‘˜. You know that ğ‘˜\nexists as a distinct element in this tree, and that it is a leaf node. Which of the following statements is FALSE?\nA) If you conduct a depth-first search, youâ€™ll never have to store more than 281 nodes in memory\nB) Conducting a breadth-first search would likely require much more memory than a depth-first search\nC) Using a stack to implement this search is preferable to using a queue\nD) The path from the root to element ğ‘˜returned by a BFS is shorter than the path returned by a DFS\nE) None of the above\n778\nChapter 20. Minimum Spanning Trees\nChapter 20 Practice Exercises\nDisclaimer: These practice questions are not official and may not have been vetted for course material. You may use these for practice, but\nyou should prioritize official resources from current staff for a more accurate depiction of what you need to know for assignments and exams.\n|ğ‘‰|1. Which of the following statements must be TRUE regarding the minimum spanning tree (MST) of a graph with vertices?\nI. The MST is acyclic.\n|ğ‘‰|II. The MST has edges.\nIII. The MST cannot include the edge with the largest weight in the original graph.\nA) I only\nB) II only\nC) I and II only\nD) II and III only\nE) I, II, and III\n|ğ‘‰| |ğ¸|2. Given a sparse graph with vertices and edges that is represented using an adjacency list, what is the time complexity of running the\nheap implementation of Primâ€™s algorithm on this graph, provided that you use a binary heap as the underlying structure of your heap?\nÎ˜(|ğ‘‰|+|ğ¸|)A)\nÎ˜(|ğ¸|log(|ğ‘‰|))B)\nÎ˜(|ğ‘‰||ğ¸|log(|ğ‘‰|))C)\nÎ˜(|ğ‘‰|2)D)\nÎ˜(|ğ‘‰|3)E)", "question_embedding": null, "page_ids": ["2afd0c50-ab9c-5b1e-acab-c7e93b22bf80", "5b3eb61a-78ca-5ab0-a3f1-002ac1c1cff4", "6275fd1a-cffc-5d55-9e15-840a57b06dcd", "7b25559a-771c-5789-849e-761231306ccf", "7b7d9dc6-5cd7-52df-b66e-d4548821bf99", "862d47c5-75db-5446-8ee5-19e543dc5181", "9b0d4dd4-86c3-518e-a300-140b5431246b", "a33ee040-cb9d-5bce-8fe4-7a2149f54fc9", "a8bd50a1-a8c7-5431-824f-b2983d36f1ed", "ac0618f6-44f6-59d5-be17-b53f2933ead5", "afe605f5-a549-5395-b01b-3fe495903bb8", "e07bc6fe-0bb9-5892-9565-a839b6bcff01", "eeb12615-da5e-5489-a593-75fa07932e2c", "f5d6b0c4-2db1-5173-8428-b1cf083e7cc4", "f6099dd1-8ca5-5a05-8f00-ca473fc97adc"]}, "answers": [{"id": null, "qa_id": "c9e4ff44-af5a-5782-ad04-fc12ef8e0725", "book_id": "47bbcc23-9276-5662-9e40-96e8a4841ec7", "section_labels": ["practice", "solutions"], "section_titles": ["Exercise Solutions", "Practice Exercises"], "pdf_page": 126, "problem_key": "7", "answer_number": 7, "answer_choice": "D", "answer_text": "If the input size is too small, the relationship may not be revealed. Plotting out runtimes is most revealing when\nthe input size is large.", "answer_embedding": null, "answer_confidence": null, "page_ids": ["ac0618f6-44f6-59d5-be17-b53f2933ead5", "f6099dd1-8ca5-5a05-8f00-ca473fc97adc"]}, {"id": null, "qa_id": "c9e4ff44-af5a-5782-ad04-fc12ef8e0725", "book_id": "47bbcc23-9276-5662-9e40-96e8a4841ec7", "section_labels": ["practice", "solutions"], "section_titles": ["Exercise Solutions", "Practice Exercises"], "pdf_page": 161, "problem_key": "7", "answer_number": 7, "answer_choice": "C", "answer_text": "Option (A) does not work because the value of ğ‘cannot depend on the input size ğ‘›. Option (B) does not work\nbecause it is not in the correct form (two different recursive calls that split the input into different sizes). Option (D) does not work because\n1. Option (E) does not work because it is also not in the correct form (the input size must be divided). Only option (C) works, whereğ‘<\n11, 13, and 1âˆ•2.ğ‘= ğ‘= ğ‘=", "answer_embedding": null, "answer_confidence": null, "page_ids": ["ac0618f6-44f6-59d5-be17-b53f2933ead5", "afe605f5-a549-5395-b01b-3fe495903bb8", "f6099dd1-8ca5-5a05-8f00-ca473fc97adc"]}, {"id": null, "qa_id": "c9e4ff44-af5a-5782-ad04-fc12ef8e0725", "book_id": "47bbcc23-9276-5662-9e40-96e8a4841ec7", "section_labels": ["practice", "solutions"], "section_titles": ["Exercise Solutions", "Practice Exercises"], "pdf_page": 211, "problem_key": "7", "answer_number": 7, "answer_choice": "C", "answer_text": "The vector allocates space four times. The first allocation occurs on line 2, where the vectorâ€™s underlying array\nis initially set to a size of 2 (with the values initialized to zero). The second allocation occurs on line 3, since the requested capacity of 4 is\nlarger than the existing capacity of 2. This is what the vector looks like after the second allocation:\n0\n0\nundef\nundef\nNext, the loop on line 4 inserts 7 elements to the back of the vector. Pushing back the 3rd of these elements forces a reallocation since there\nwould be 5 elements after the insertion, but only an existing capacity of 4. This reallocation doubles the vectorâ€™s capacity to 8. Following\nthis, the insertion of the 7th element in this loop increases the size of the vector to 9, which forces another reallocation of the vector from a\ncapacity of 8 to a capacity of 16.\n.reserve()8. Thecorrectansweris(B).The callonline2reservesthevectorâ€™scapacityto10,butitdoesnotactuallycreateanyelements.\nThus, trying to index into the values on line 5 causes undefined behavior, since you cannot index a vector with a position that is larger than\nits size (which is still zero).", "answer_embedding": null, "answer_confidence": null, "page_ids": ["ac0618f6-44f6-59d5-be17-b53f2933ead5", "afe605f5-a549-5395-b01b-3fe495903bb8", "eeb12615-da5e-5489-a593-75fa07932e2c", "f6099dd1-8ca5-5a05-8f00-ca473fc97adc"]}, {"id": null, "qa_id": "c9e4ff44-af5a-5782-ad04-fc12ef8e0725", "book_id": "47bbcc23-9276-5662-9e40-96e8a4841ec7", "section_labels": ["practice", "solutions"], "section_titles": ["Exercise Solutions", "Practice Exercises"], "pdf_page": 281, "problem_key": "7", "answer_number": 7, "answer_choice": "D", "answer_text": "When you push back an element into the circular buffer, you increment the back iterator; if this back iterator\nends up at the same position as the first element in the circular buffer (the front iterator), you would know that your circular buffer is full.", "answer_embedding": null, "answer_confidence": null, "page_ids": ["9b0d4dd4-86c3-518e-a300-140b5431246b", "ac0618f6-44f6-59d5-be17-b53f2933ead5", "afe605f5-a549-5395-b01b-3fe495903bb8", "eeb12615-da5e-5489-a593-75fa07932e2c", "f6099dd1-8ca5-5a05-8f00-ca473fc97adc"]}, {"id": null, "qa_id": "c9e4ff44-af5a-5782-ad04-fc12ef8e0725", "book_id": "47bbcc23-9276-5662-9e40-96e8a4841ec7", "section_labels": ["practice", "solutions"], "section_titles": ["Exercise Solutions", "Practice Exercises"], "pdf_page": 420, "problem_key": "7", "answer_number": 7, "answer_choice": "B", "answer_text": "An element has a representative equal to itself if it is the ultimate representative of its disjoint set. Since every\nunion_set()element has its representative equal to itself, each element must be in its own disjoint set â€” because of this, a call to would\nmerge two sets of size one, and thus will only be able to update one representative.\nfind_set()8. The correct answer is (C). The worst-case performance of depends on length of the representative chain from an element\nto its ultimate representative. Normally, this would be since you could have a representative chain in the form of a stick (where A is anÎ˜(ğ‘›)\nultimate representative, Bâ€™s representative is A, Câ€™s representative is B, etc.). However, if you enforce that the smaller set is always updated\nto be part of the larger set after a union, then the maximum length of a representative chain drops down from to Î˜(log(ğ‘›)), which alsoÎ˜(ğ‘›)\nfind_set()reduces the worst-case time complexity of a single call.\n{0, 2, 3, 5, 7, 8, 9} {1, 4, 6}.9. The correct answer is (C). There are two disjoint sets: and One strategy is to count the\nnumber of elements with a representative equal to itself, since this is the number of ultimate representatives that exist in the container.", "answer_embedding": null, "answer_confidence": null, "page_ids": ["7b7d9dc6-5cd7-52df-b66e-d4548821bf99", "9b0d4dd4-86c3-518e-a300-140b5431246b", "ac0618f6-44f6-59d5-be17-b53f2933ead5", "afe605f5-a549-5395-b01b-3fe495903bb8", "eeb12615-da5e-5489-a593-75fa07932e2c", "f6099dd1-8ca5-5a05-8f00-ca473fc97adc"]}, {"id": null, "qa_id": "c9e4ff44-af5a-5782-ad04-fc12ef8e0725", "book_id": "47bbcc23-9276-5662-9e40-96e8a4841ec7", "section_labels": ["practice", "solutions"], "section_titles": ["Exercise Solutions", "Practice Exercises"], "pdf_page": 453, "problem_key": "7", "answer_number": 7, "answer_choice": "E", "answer_text": "The best external sorts are divide-and-conquer sorting algorithms, which allow the input to be divided across\nmultiple workers, individually sorted, and then merged together. Of the provided sorts, mergesort falls into this category.", "answer_embedding": null, "answer_confidence": null, "page_ids": ["5b3eb61a-78ca-5ab0-a3f1-002ac1c1cff4", "7b7d9dc6-5cd7-52df-b66e-d4548821bf99", "9b0d4dd4-86c3-518e-a300-140b5431246b", "ac0618f6-44f6-59d5-be17-b53f2933ead5", "afe605f5-a549-5395-b01b-3fe495903bb8", "eeb12615-da5e-5489-a593-75fa07932e2c", "f6099dd1-8ca5-5a05-8f00-ca473fc97adc"]}, {"id": null, "qa_id": "c9e4ff44-af5a-5782-ad04-fc12ef8e0725", "book_id": "47bbcc23-9276-5662-9e40-96e8a4841ec7", "section_labels": ["practice", "solutions"], "section_titles": ["Exercise Solutions", "Practice Exercises"], "pdf_page": 530, "problem_key": "7", "answer_number": 7, "answer_choice": "C", "answer_text": "The function returns true if the back half of the string is equal to the front half (notice the use of reverse iterators\nin the input range). Thus, the function would only return true if given a palindrome (a word spelled the same forward and backward), which\nis only true for option (C).\n17.9 Solving Problems Using Hash Tables\n575\nselect(const int64_tstd::optional<std::string> std::string& table_name, row_id,â€¢\nconst std::string& column_name);\ntable_name row_id column_name.â€“ Returnsthevalueofthecellinthetable associatedwiththerowwithID andcolumnname\nstd::nullopt. select() \"Students\",If no such value exists, return For example, if is called with a table name of a\n1, \"GPA\", \"3.9\".row ID of and a column name of you would return\nAn outline of this class is provided below:\n1\nclass Database {\n2\nprivate:\n3\n// TODO: Add any data structures here!\n4\npublic:\n5\nbool create(const TableInfo& table_info) {\n6\n// TODO: Implement this\n7\n} // create()\n8\n9\nint64_t insert(const conststd::string& table_name, std::vector<std::string>& row_data) {\n10\n// TODO: Implement this\n11\n} // insert()\n12\n13\nbool remove(const int64_tstd::string& table_name, row_id) {\n14\n// TODO: Implement this\n15\n} // remove()\n16\n17\nselect(const int64_tstd::optional<std::string> std::string& table_name, row_id,\n18\nconst std::string& column_name) {\n19\n// TODO: Implement this\n20\n} // select()\n21\n};\nChapter 17 Exercise Solutions", "answer_embedding": null, "answer_confidence": null, "page_ids": ["5b3eb61a-78ca-5ab0-a3f1-002ac1c1cff4", "7b7d9dc6-5cd7-52df-b66e-d4548821bf99", "862d47c5-75db-5446-8ee5-19e543dc5181", "9b0d4dd4-86c3-518e-a300-140b5431246b", "ac0618f6-44f6-59d5-be17-b53f2933ead5", "afe605f5-a549-5395-b01b-3fe495903bb8", "eeb12615-da5e-5489-a593-75fa07932e2c", "f6099dd1-8ca5-5a05-8f00-ca473fc97adc"]}, {"id": null, "qa_id": "c9e4ff44-af5a-5782-ad04-fc12ef8e0725", "book_id": "47bbcc23-9276-5662-9e40-96e8a4841ec7", "section_labels": ["practice", "solutions"], "section_titles": ["Exercise Solutions", "Practice Exercises"], "pdf_page": 771, "problem_key": "7", "answer_number": 7, "answer_choice": "D", "answer_text": "For a binary tree, there is only one way to get to each node. Because of this, the path returned by a breadth-first\nsearch would be the same as the path returned by a depth-first search. The other statements are all true. For option (A), a DFS explores\nvertices in the graph one branch at a time, so the most nodes that would need to be stored in memory at any point in time is bounded by the\nlength of the longest possible path between two vertices (in this case, 281). For option (B), a BFS visits the tree one level at a time, so all\nthe nodes at a single level may need to be stored in the underlying queue at the same time (which is a lot greater than 281 for the final level,\nsince ğ‘˜is a leaf node). For option (C), a stack is preferable because a DFS is preferable to a BFS, for the reasons discussed above.", "answer_embedding": null, "answer_confidence": null, "page_ids": ["5b3eb61a-78ca-5ab0-a3f1-002ac1c1cff4", "7b7d9dc6-5cd7-52df-b66e-d4548821bf99", "862d47c5-75db-5446-8ee5-19e543dc5181", "9b0d4dd4-86c3-518e-a300-140b5431246b", "a33ee040-cb9d-5bce-8fe4-7a2149f54fc9", "ac0618f6-44f6-59d5-be17-b53f2933ead5", "afe605f5-a549-5395-b01b-3fe495903bb8", "eeb12615-da5e-5489-a593-75fa07932e2c", "f6099dd1-8ca5-5a05-8f00-ca473fc97adc"]}, {"id": null, "qa_id": "c9e4ff44-af5a-5782-ad04-fc12ef8e0725", "book_id": "47bbcc23-9276-5662-9e40-96e8a4841ec7", "section_labels": ["practice", "solutions"], "section_titles": ["Exercise Solutions", "Practice Exercises"], "pdf_page": 826, "problem_key": "7", "answer_number": 7, "answer_choice": "D", "answer_text": "This is the breakpoint selection problem introduced in section 21.3.4: to solve this problem, we sort the gas\nstations in ascending order and greedily select the last gas station we can reach before running out of gas. The bottleneck of this algorithm\nis the sorting step, which takes time.Î˜(ğ‘›log(ğ‘›))", "answer_embedding": null, "answer_confidence": null, "page_ids": ["5b3eb61a-78ca-5ab0-a3f1-002ac1c1cff4", "7b7d9dc6-5cd7-52df-b66e-d4548821bf99", "862d47c5-75db-5446-8ee5-19e543dc5181", "9b0d4dd4-86c3-518e-a300-140b5431246b", "a33ee040-cb9d-5bce-8fe4-7a2149f54fc9", "a8bd50a1-a8c7-5431-824f-b2983d36f1ed", "ac0618f6-44f6-59d5-be17-b53f2933ead5", "afe605f5-a549-5395-b01b-3fe495903bb8", "eeb12615-da5e-5489-a593-75fa07932e2c", "f6099dd1-8ca5-5a05-8f00-ca473fc97adc"]}, {"id": null, "qa_id": "c9e4ff44-af5a-5782-ad04-fc12ef8e0725", "book_id": "47bbcc23-9276-5662-9e40-96e8a4841ec7", "section_labels": ["practice", "solutions"], "section_titles": ["Exercise Solutions", "Practice Exercises"], "pdf_page": 873, "problem_key": "7", "answer_number": 7, "answer_choice": "C", "answer_text": "Statement I is false because there is no guarantee that branch and bound will make the program run faster; it is\npossible that we generate permutations in an order such that the first permutation is better than our initial upper bound, the next permutation\nis better than the first permutation, and so on â€” in this case, nothing gets pruned, and the program does not run faster. Statement II is false\nfor similar reasons, we could end up exploring branches in a way such that we are not able to prune anything, which would yield a time\ncomplexity that is the same as brute force. Statement III is true: if you overestimate the cost of extending a partial solution, you may end up\ntreating the path is not promising even though it actually may lead to the optimal solution.", "answer_embedding": null, "answer_confidence": null, "page_ids": ["5b3eb61a-78ca-5ab0-a3f1-002ac1c1cff4", "7b7d9dc6-5cd7-52df-b66e-d4548821bf99", "862d47c5-75db-5446-8ee5-19e543dc5181", "9b0d4dd4-86c3-518e-a300-140b5431246b", "a33ee040-cb9d-5bce-8fe4-7a2149f54fc9", "a8bd50a1-a8c7-5431-824f-b2983d36f1ed", "ac0618f6-44f6-59d5-be17-b53f2933ead5", "afe605f5-a549-5395-b01b-3fe495903bb8", "e07bc6fe-0bb9-5892-9565-a839b6bcff01", "eeb12615-da5e-5489-a593-75fa07932e2c", "f6099dd1-8ca5-5a05-8f00-ca473fc97adc"]}, {"id": null, "qa_id": "c9e4ff44-af5a-5782-ad04-fc12ef8e0725", "book_id": "47bbcc23-9276-5662-9e40-96e8a4841ec7", "section_labels": ["practice", "solutions"], "section_titles": ["Exercise Solutions", "Practice Exercises"], "pdf_page": 931, "problem_key": "7", "answer_number": 7, "answer_choice": "D", "answer_text": "In the naÃ¯ve recursive approach, the auxiliary space required is equal to the recursion depth, which is ğ‘›(the full\nrecursion depth is needed because computing Fibonacci numbers recursively is not tail recursive since you would need to return the sum of\ntwo recursive calls). With dynamic programming, the auxiliary space becomes the size of the memo, which when optimally implemented\nğ‘›thwould have a size of ğ‘›(to store every Fibonacci number up to the number).", "answer_embedding": null, "answer_confidence": null, "page_ids": ["2afd0c50-ab9c-5b1e-acab-c7e93b22bf80", "5b3eb61a-78ca-5ab0-a3f1-002ac1c1cff4", "7b7d9dc6-5cd7-52df-b66e-d4548821bf99", "862d47c5-75db-5446-8ee5-19e543dc5181", "9b0d4dd4-86c3-518e-a300-140b5431246b", "a33ee040-cb9d-5bce-8fe4-7a2149f54fc9", "a8bd50a1-a8c7-5431-824f-b2983d36f1ed", "ac0618f6-44f6-59d5-be17-b53f2933ead5", "afe605f5-a549-5395-b01b-3fe495903bb8", "e07bc6fe-0bb9-5892-9565-a839b6bcff01", "eeb12615-da5e-5489-a593-75fa07932e2c", "f6099dd1-8ca5-5a05-8f00-ca473fc97adc"]}, {"id": null, "qa_id": "c9e4ff44-af5a-5782-ad04-fc12ef8e0725", "book_id": "47bbcc23-9276-5662-9e40-96e8a4841ec7", "section_labels": ["practice", "solutions"], "section_titles": ["Exercise Solutions", "Practice Exercises"], "pdf_page": 958, "problem_key": "7", "answer_number": 7, "answer_choice": "D", "answer_text": "For the fractional knapsack problem, the optimal solution can be obtained by greedily taking the items with the\nhighest value-to-weight ratio until you run out of space. In this case, the value-to-weight ratios are shown below:\nItem\n1\n2\n3\n4\n5\nWeight\n4\n10\n6\n8\n2\nValue\n5\n7\n9\n6\n4\nRatio\n1.25\n0.7\n1.5\n0.75\n2\nThus, the optimal solution would take item 5 first, then item 3, then item 1, then half of item 4 (to fill the knapsack up to capacity), yielding\na total value of 4 + 9 + 5 + 3 = 21.", "answer_embedding": null, "answer_confidence": null, "page_ids": ["2afd0c50-ab9c-5b1e-acab-c7e93b22bf80", "5b3eb61a-78ca-5ab0-a3f1-002ac1c1cff4", "7b7d9dc6-5cd7-52df-b66e-d4548821bf99", "862d47c5-75db-5446-8ee5-19e543dc5181", "9b0d4dd4-86c3-518e-a300-140b5431246b", "a33ee040-cb9d-5bce-8fe4-7a2149f54fc9", "a8bd50a1-a8c7-5431-824f-b2983d36f1ed", "ac0618f6-44f6-59d5-be17-b53f2933ead5", "afe605f5-a549-5395-b01b-3fe495903bb8", "e07bc6fe-0bb9-5892-9565-a839b6bcff01", "eeb12615-da5e-5489-a593-75fa07932e2c", "f5d6b0c4-2db1-5173-8428-b1cf083e7cc4", "f6099dd1-8ca5-5a05-8f00-ca473fc97adc"]}, {"id": null, "qa_id": "c9e4ff44-af5a-5782-ad04-fc12ef8e0725", "book_id": "47bbcc23-9276-5662-9e40-96e8a4841ec7", "section_labels": ["practice", "solutions"], "section_titles": ["Exercise Solutions", "Practice Exercises"], "pdf_page": 994, "problem_key": "7", "answer_number": 7, "answer_choice": "C", "answer_text": "Since every substation in the graph is connected to nearly every other substation, this is a dense graph, so the\nÎ˜(|ğ‘‰|) |ğ‘‰|optimal implementation of Dijkstraâ€™s algorithm involves a linear search. This implementation takes time with vertices.", "answer_embedding": null, "answer_confidence": null, "page_ids": ["2afd0c50-ab9c-5b1e-acab-c7e93b22bf80", "5b3eb61a-78ca-5ab0-a3f1-002ac1c1cff4", "7b25559a-771c-5789-849e-761231306ccf", "7b7d9dc6-5cd7-52df-b66e-d4548821bf99", "862d47c5-75db-5446-8ee5-19e543dc5181", "9b0d4dd4-86c3-518e-a300-140b5431246b", "a33ee040-cb9d-5bce-8fe4-7a2149f54fc9", "a8bd50a1-a8c7-5431-824f-b2983d36f1ed", "ac0618f6-44f6-59d5-be17-b53f2933ead5", "afe605f5-a549-5395-b01b-3fe495903bb8", "e07bc6fe-0bb9-5892-9565-a839b6bcff01", "eeb12615-da5e-5489-a593-75fa07932e2c", "f5d6b0c4-2db1-5173-8428-b1cf083e7cc4", "f6099dd1-8ca5-5a05-8f00-ca473fc97adc"]}, {"id": null, "qa_id": "c9e4ff44-af5a-5782-ad04-fc12ef8e0725", "book_id": "47bbcc23-9276-5662-9e40-96e8a4841ec7", "section_labels": ["practice", "solutions"], "section_titles": ["Exercise Solutions", "Practice Exercises"], "pdf_page": 1053, "problem_key": "7", "answer_number": 7, "answer_choice": "A", "answer_text": "Only statement I is true, since the Shoelace formula performs a constant-time calculation for each vertex of the\npolygon, which takes time overall. Statement II is false so no separate check needs to be done for double-covered trapezoidal regions,Î˜(ğ‘›)\nsince they regions automatically cancel each other out during the summation. Statement III is false since the Shoelace formula can find the\narea of any simple polygon, without any restriction on shape or orientation.", "answer_embedding": null, "answer_confidence": null, "page_ids": ["2afd0c50-ab9c-5b1e-acab-c7e93b22bf80", "5b3eb61a-78ca-5ab0-a3f1-002ac1c1cff4", "6275fd1a-cffc-5d55-9e15-840a57b06dcd", "7b25559a-771c-5789-849e-761231306ccf", "7b7d9dc6-5cd7-52df-b66e-d4548821bf99", "862d47c5-75db-5446-8ee5-19e543dc5181", "9b0d4dd4-86c3-518e-a300-140b5431246b", "a33ee040-cb9d-5bce-8fe4-7a2149f54fc9", "a8bd50a1-a8c7-5431-824f-b2983d36f1ed", "ac0618f6-44f6-59d5-be17-b53f2933ead5", "afe605f5-a549-5395-b01b-3fe495903bb8", "e07bc6fe-0bb9-5892-9565-a839b6bcff01", "eeb12615-da5e-5489-a593-75fa07932e2c", "f5d6b0c4-2db1-5173-8428-b1cf083e7cc4", "f6099dd1-8ca5-5a05-8f00-ca473fc97adc"]}]}
{"type": "matched_pair", "qa_id": "f03fdb9e-83bc-5941-9246-554738ffe404", "question": {"id": null, "qa_id": "f03fdb9e-83bc-5941-9246-554738ffe404", "book_id": "47bbcc23-9276-5662-9e40-96e8a4841ec7", "section_labels": ["practice", "solutions"], "section_titles": ["Exercise Solutions", "Practice Exercises"], "pdf_page": 955, "problem_key": "18", "question_number": 18, "question_text": "Suppose you aretryingto breakinto yourprofessorâ€™s computer topeek atthe finalexamsurprise themwith a thankyou note for allthework\nthat was put into the course. You noticed during lecture that your professor had a 9-character password, so you are randomly generating\npasswords of length 9. What algorithm family is this an example of?\nA) Backtracking\nB) Branch and bound\nC) Brute force\nD) Divide and conquer\nE) Dynamic programming", "question_embedding": null, "page_ids": ["9b0d4dd4-86c3-518e-a300-140b5431246b", "a33ee040-cb9d-5bce-8fe4-7a2149f54fc9", "cba6a615-1ed5-524b-b8f5-2097b53ee531", "fa3d76e7-f248-5f89-aa79-8ac7b5a3afa5"]}, "answers": [{"id": null, "qa_id": "f03fdb9e-83bc-5941-9246-554738ffe404", "book_id": "47bbcc23-9276-5662-9e40-96e8a4841ec7", "section_labels": ["practice", "solutions"], "section_titles": ["Exercise Solutions", "Practice Exercises"], "pdf_page": 281, "problem_key": "18", "answer_number": 18, "answer_choice": "B", "answer_text": "This class uses a queue to implement the behavior of a stack. This is because, after every insertion, all the\npreviously existing elements in the queue are popped out and reinserted back in the queue. This ensures that the most recently insert element\nis always at the front of the queue, which essentially recreates the functionality of a stack.\n10.7 Solving Problems Using Priority Queues\n307\nÂ¸ 10.7.3\nMerging Sorted Arrays\nExample 10.11 Suppose you are given ğ‘˜sorted arrays of size ğ‘›each. Devise an time-efficient algorithm that merges the arrays into a\nsingle larger, sorted array.\nThe naÃ¯ve approach would be to insert all the elements into an array of size ğ‘›ğ‘˜, and then run a sorting algorithm on the entire array. However,\nthis approach is inefficient, since sorting an array of size ğ‘›ğ‘˜takes time. Instead, we will look at two better solutions that can beÎ˜(ğ‘›ğ‘˜log(ğ‘›ğ‘˜))\nused to solve this problem, one that uses heaps and one that uses recursion.\nIn the heap solution, we first create a min-heap and insert the first element of each of the ğ‘˜sorted arrays. Then, while the min-heap has a\nsize greater than zero, remove the element at the top of the heap, push it to the output array, and insert the next element in the array that the\nnewly pushed in element originated from. To illustrate this process, suppose you are given the following four sorted arrays:\n3\n5\n10 16\n2\n4\n8\n12\n1\n7\n1511\n6\n9\n13 14\nFirst, we will declare a min-heap and push in the first value of each of the ğ‘˜sorted arrays:\nArray 1\n3\n5\n10 16\nArray 2\n2\n4\n8\n12\nArray 3\n1\n7\n1511\nArray 4\n6\n9\n13 14\nMin-Heap\n1\n2\n3\n6\nOutput\nWe then pop the top element off the heap and push it into our output array. Since the element we pushed to the output array belongs to array 3,\nwe push the next element in array 3 into the min-heap.\nArray 1\n3\n5\n10 16\nArray 2\n2\n4\n8\n12\nArray 3\n1\n7\n1511\nArray 4\n6\n9\n13 14\nMin-Heap\n2\n6\n3\n7\nOutput\n1\nThe top element is now 2, which belongs to array 2. Thus, we push 2 into the output vector and push the next value in array 2 into the min-heap.\nArray 1\n3\n5\n10 16\nArray 2\n2\n4\n8\n12\nArray 3\n1\n7\n1511\nArray 4\n6\n9\n13 14\nMin-Heap\n3\n6\n4\n7\nOutput\n1\n2\n316\nChapter 10. Priority Queues and Heaps\nChapter 10 Exercise Solutions", "answer_embedding": null, "answer_confidence": null, "page_ids": ["9b0d4dd4-86c3-518e-a300-140b5431246b", "cba6a615-1ed5-524b-b8f5-2097b53ee531"]}, {"id": null, "qa_id": "f03fdb9e-83bc-5941-9246-554738ffe404", "book_id": "47bbcc23-9276-5662-9e40-96e8a4841ec7", "section_labels": ["practice", "solutions"], "section_titles": ["Exercise Solutions", "Practice Exercises"], "pdf_page": 771, "problem_key": "18", "answer_number": 18, "answer_choice": "A", "answer_text": "There can be multiple paths to the target vertex that consist of the same number of edges. BFS will always find\none of these paths, but there is no guarantee that this path will be the shortest weighted path (e.g., if there are two paths with the fewest\npossible number of edges, but with different total weights, you cannot guarantee which path BFS will discover).\n766\nChapter 20. Minimum Spanning Trees\nAs an example, consider the following weighted, undirected graph:\nA\nB\nE\nC\nD\n8\n3\n7\n2\n5\n6\n4\nA spanning tree that minimizes total edge weight is shown below, with a total weight of 2 + 3 + 5 + 7 = 17. Since there is no way to connect all\nthe vertices in the graph with a total edge cost less than 17, this is a valid MST of the previous graph.\nA\nB\nE\nC\nD\n3\n7\n2\n5\nNote that it is possible for a graph to have multiple valid MSTs if more than one unique spanning tree minimizes total edge weight. For instance,\nif we adjusted the weight of edge ğµğ¸to 7, there would be two valid MSTs, which are shown below. This is because there are two different\nedges we can include to connect vertex E to our MST, both of which share the same edge weight.\nA\nB\nE\nC\nD\n3\n7\n2\n7\n5\n6\n4\nA\nB\nE\nC\nD\n3\n7\n2\n5\nA\nB\nE\nC\nD\n3\n7\n2\n5\nExample 20.1 Prove or disprove that a shortest edge in a graph must be included in its MST.unique\nTo show that a unique shortest edge will always be included in a MST, we can use proof by contradiction. Suppose that the unique shortest edge\nis included in the MST. If this were the case, we would be able to add this unique shortest edge to the MST to create a cycle. Then, if wenot\nwere to remove some other edge from this cycle, our new spanning tree would have a lower weight than before. This results in a contradiction:\nbecause we were able to create a spanning tree with a lower weight, our initial spanning tree without the unique shortest edge must not have\nbeen a valid MST!\nMinimum spanning trees have significant practical applications in many computer science problems. For example, a MST can be used to\nefficiently connect different data centers using heavy duty fiber-optic cables (which can be quite expensive). To find out which pairs of data\ncenters you should connect so that all data centers are reachable from each other using the lowest cost possible, you can represent these data\ncenters as a graph and calculate its MST. Spanning trees also show up in the field of networking: Ethernet networking systems, for instance, rely\non spanning trees to ensure that data in a network do not get stuck in cycles, which wastes network resources and consumes bandwidth at the\nexpense of other network traffic (known as a storm). Lastly, as you will see in chapter 22, minimum spanning trees can be usedbroadcast\nto approximate solutions to complex problems such as the (TSP), which, given a graph of cities and distancestraveling salesperson problem\nbetween pairs of cities, seeks to find the shortest route that visits each city exactly once and starts and ends at the same origin city.\nBecause of how useful minimum spanning trees are in computer science, it would be remiss of us not to explore MSTs and MST algorithms\nin this course. In this chapter, we will focus on two important algorithms that can be used to find a minimum spanning tree of a weighted,\nundirected graph: and algorithm.Primâ€™s algorithm Kruskalâ€™s\n20.2\nPrimâ€™s Algorithm\nPrimâ€™s algorithm is an algorithm that can be used to find a MST of a weighted, connected, and undirected graph. This algorithm works by\ngrowing a tree from a single vertex, greedily selecting vertices to add to the tree based on the edge weights of the graph. The steps of Primâ€™s\nalgorithm are as follows:\n1. A tree is initialized starting from a single vertex that is arbitrarily chosen from the graph. The vertex chosen does not matter, as Primâ€™s\nwill always return a valid MST regardless of which vertex is used as a starting point. However, if there are multiple MSTs that exist\nwithin a graph, the choice of starting vertex could affect the MST found by the algorithm.\n2. Then, of the edges that connect the tree to vertices not yet in the tree, the algorithm finds the edge with the lowest weight and adds it to\nthe tree. This ends up growing the tree by connecting a new vertex that was previously not in the tree.\n3. Step 2 is then repeated until all the vertices are in the tree. After the algorithm completes, the final tree is a valid minimum spanning tree\nof the entire graph.\n20.4 Comparing Primâ€™s and Kruskalâ€™s Algorithms\n781\nChapter 20 Exercise Solutions", "answer_embedding": null, "answer_confidence": null, "page_ids": ["9b0d4dd4-86c3-518e-a300-140b5431246b", "a33ee040-cb9d-5bce-8fe4-7a2149f54fc9", "cba6a615-1ed5-524b-b8f5-2097b53ee531"]}, {"id": null, "qa_id": "f03fdb9e-83bc-5941-9246-554738ffe404", "book_id": "47bbcc23-9276-5662-9e40-96e8a4841ec7", "section_labels": ["practice", "solutions"], "section_titles": ["Exercise Solutions", "Practice Exercises"], "pdf_page": 961, "problem_key": "18", "answer_number": 18, "answer_choice": "C", "answer_text": "You are randomly trying all possible passwords of length 9, so this is an example of brute force. Knowing that\na specific 9-character combination does not work will give you any additional information on the remaining possible combinations.", "answer_embedding": null, "answer_confidence": null, "page_ids": ["9b0d4dd4-86c3-518e-a300-140b5431246b", "a33ee040-cb9d-5bce-8fe4-7a2149f54fc9", "cba6a615-1ed5-524b-b8f5-2097b53ee531", "fa3d76e7-f248-5f89-aa79-8ac7b5a3afa5"]}]}
{"type": "matched_pair", "qa_id": "f132cfcc-3391-5b7e-b78c-e8bb8cc29401", "question": {"id": null, "qa_id": "f132cfcc-3391-5b7e-b78c-e8bb8cc29401", "book_id": "47bbcc23-9276-5662-9e40-96e8a4841ec7", "section_labels": ["practice", "solutions"], "section_titles": ["Exercise Solutions", "Practice Exercises"], "pdf_page": 989, "problem_key": "3", "question_number": 3, "question_text": "True or false? Given a directed graph ğºwith non-negative edge weights, finding the shortest path from node ğ´to another node ğ‘in the\ngraph using Dijkstraâ€™s algorithm is always faster than finding the shortest path from node ğ´to every other node in ğº.\nA) True\nB) False", "question_embedding": null, "page_ids": ["008c7238-791e-5554-a8d0-1eccf442450a", "1a3da172-d383-5da8-b297-3fd5ea9024dc", "2afd0c50-ab9c-5b1e-acab-c7e93b22bf80", "5b3eb61a-78ca-5ab0-a3f1-002ac1c1cff4", "6275fd1a-cffc-5d55-9e15-840a57b06dcd", "6e773b9f-1cda-5ba9-8756-97b6e00119df", "7b25559a-771c-5789-849e-761231306ccf", "7b7d9dc6-5cd7-52df-b66e-d4548821bf99", "8cacf18e-1cee-53fd-a323-366ab7d7cf31", "8f645308-041e-5dc2-8a84-efc4ca2daac4", "9801d2c0-b83e-52f9-b703-56eeba030479", "9b0d4dd4-86c3-518e-a300-140b5431246b", "a33ee040-cb9d-5bce-8fe4-7a2149f54fc9", "a8bd50a1-a8c7-5431-824f-b2983d36f1ed", "afe605f5-a549-5395-b01b-3fe495903bb8", "e07bc6fe-0bb9-5892-9565-a839b6bcff01", "f5d6b0c4-2db1-5173-8428-b1cf083e7cc4", "f6099dd1-8ca5-5a05-8f00-ca473fc97adc"]}, "answers": [{"id": null, "qa_id": "f132cfcc-3391-5b7e-b78c-e8bb8cc29401", "book_id": "47bbcc23-9276-5662-9e40-96e8a4841ec7", "section_labels": ["practice", "solutions"], "section_titles": ["Exercise Solutions", "Practice Exercises"], "pdf_page": 53, "problem_key": "3", "answer_number": 3, "answer_choice": "A", "answer_text": "Members in a custom object are initialized in the order they are listed. Members in a base class are initialized\nbefore members in classes that derive from it.\nconst4. The correct answer is (D). The placement on line 4 indicates that the pointer cannot be modified, but the integer it stores can.\nOnly option (D) modifies the pointer and not the value it points to, which would cause a compilation error.\nconst5. The correct answer is (D). The that is applied to the member function on line 4 indicates that the member function is not allowed\nclass bar),to modify the member variables of the itself (in this case, the value of provided that the member variable is not marked\nmutable constas (which gives member functions the permission to modify a variable). By this logic, statements II and III are true.\nbaz const int32_t baz const int32_tStatement I is false because the function argument itself is not marked as (e.g., instead of\nbaz), so the member function is still able to change its value.\nNon-const non-const const6. The correct answer is (C). member functions can only be called by objects (a object cannot invoke a\nnon-const member function, since such a function does not guarantee it does not modify any of the objectâ€™s members). Thus, option (C)\nf2 const, do_something()would result in a compilation error, since is but is not.\nexplicit7. The correct answer is (D). The keyword prevents the compiler from using a one-argument constructor to construct an object\nPerson int32_t explicitfrom an implicit type conversion. The object takes an as its only argument, so without the keyword, the\nPerson int32_t int32_t Personassignment of a object with an would cause the to be implicitly converted into an object of type\nexplicitusing the one-argument constructor. Adding the keyword prevents this. Options (A), (C), and (E) do not involve an implicit\ntype conversion, and option (B) would not compile regardless.\n56\nChapter 2. File and Stream I/O\nChapter 2 Exercise Solutions\n>> std::getline()1. The correct answer is (A). The extraction operator ignores leading whitespace, but the does not (instead,\nstd::getline() '\\n'reads all characters up to the next delimitation character, which is by default).\nstd::cin operator>>2. The correct answer is (B). When you read something from the standard input stream using either or\nstd::getline(), std::cinyou also extract it from the stream. There are two places where is being read: the extraction op-\nwhile std::getline() operator>>erator in the loop on line 5, and the call to on line 6. ignores leading whitespace, while\nstd::getline() consumes everything up to the next newline character. With this information, we will walk through the input file and\nobserve what happens when it is redirected via standard input:\noperator>> 17 num.â€¢ First, we use to read in the first value from the input stream. This reads the number into After this first\nextraction, the stream now looks like this:\nnum=17\nline=\"\"\ninput.txt\nâˆ™22âˆ™âˆ™âˆ™âˆ™14 19 10 13 15âˆ™âˆ™27âˆ™âˆ™âˆ™12âˆ™âˆ™20Â¶ Â¶Â¶âˆ™Â¶âˆ™âˆ™Â¶ Â¶ Â¶ Â¶\nstd::getline()â€¢ Next, extracts everything up to the next newline, and then discards the newline character.\nnum=17\nline=\"âˆ™22âˆ™âˆ™âˆ™âˆ™14\"\ninput.txt\n19 10 13 15âˆ™âˆ™27âˆ™âˆ™âˆ™12âˆ™âˆ™20Â¶Â¶âˆ™Â¶âˆ™âˆ™Â¶ Â¶ Â¶ Â¶\ncounter 1.â€¢ is incremented to\noperator>> num, 19.â€¢ The next call to reads the next number into or\nnum=19\nline=\"âˆ™22âˆ™âˆ™âˆ™âˆ™14\"\ninput.txt\n10 13 15âˆ™âˆ™27âˆ™âˆ™âˆ™12âˆ™âˆ™20Â¶Â¶âˆ™Â¶âˆ™âˆ™Â¶ Â¶ Â¶ Â¶\nstd::getline()â€¢ then reads in all characters up to the next newline, and then discards this newline. However, there is nothing\nstd::getline()before the next newline, so does not extract anything.\nnum=19\nline=\"\"\ninput.txt\n10 13 15âˆ™âˆ™27âˆ™âˆ™âˆ™12âˆ™âˆ™20Â¶âˆ™Â¶âˆ™âˆ™Â¶ Â¶ Â¶ Â¶\ncounter 2.â€¢ is incremented to\noperator>> num, 10â€¢ The next call to reads the next number into or (all whitespace is ignored up to this point).\nnum=10\nline=\"\"\ninput.txt\n13 15âˆ™âˆ™27âˆ™âˆ™âˆ™12âˆ™âˆ™20Â¶ Â¶ Â¶\n84\nChapter 3. Command Line Parsing\nChapter 3 Exercise Solutions\n\"<\" \"dictionary.txt\" argc argv.1. The correct answer is (C). The input redirection components of and do not contribute to and\nargcThus, is the number of other items in the command line, which comes out to 11.\nzip date2. The correct answer is (B). Both and require additional arguments to be provided if they are specified, so these two command\nrequired_argument. verboseline options should be defined with a On the other hand, does not take in any subsequent arguments\nno_argument. optional_argumentif it is specified, so it should be defined with Notice that indicates that an argument is optional\nspecified, which does not apply here.if the option is\nz d)3. The correct answer is (E). Options that require arguments (in this case, and should be followed by a colon.\nlong_opts getopt_long()4. The correct answer is (C). The last item of the array should be an option with all zeros, so that knows\nstatic,when there are no more option choices remaining. The options array can be defined as and the additional colon is needed for the\ngetopt_long()short options string within the function call, but not in the option declaration itself.\noptargThecorrectansweris(C).Forcommandlineoptionsthatacceptarguments, isaC-stringthatstoresthevaluesofthesearguments.5.\nbanana/b grape/g6. The correct answer is (A). If or is specified on the command line, they must be followed with an additional\napple/a, orange/o, pear/pargument. If or is specified, they must be followed with no additional argument. The only command for\nb 12 g).which this is not true is (A), since is specified without an argument after it (the is the argument for Note that there is no restriction\ngetopt_long().on including an option more than once for\nswitch7. The correct answer is (D). The statement here does not compile because the newly created variables are not scoped properly â€”\nthe lifetime of the string instantiated on line 5 extends past its specific case, which is not allowed. To fix this, curly braces can be added to\neach case, as shown:\n1\nint32_t num;\n2\nstd::cin >> num;\n3\nswitch (num) {\n4\ncase 1:\n5\n{\n6\nstd::string str = \"yes\";\n7\nstd::cout << str << '\\n';\n8\nbreak;\n9\n}\n10\ncase 0:\n11\n{\n12\nstd::string str = \"no\";\n13\nstd::cout << str << '\\n';\n14\nbreak;\n15\n}\n16\ndefault:\n17\n{\n18\nbreak;\n19\n}\n20\n}\n'l' initial_level optarg 'h'8. The completed code is shown below. The case sets to the value of as an integer, and the case sets\nhard_mode to true.\n1\nclass Game {\n2\nint initial_level = 0;\n3\nbool false;hard_mode =\n4\npublic:\n5\nvoid get_options(int char**argc, argv);\n6\n/* ... other members ... */\n7\n};\n8\n9\nvoid Game::get_options(int char**argc, argv) {\n10\nint option = 0;\n11\nint index = 0;\n12\nstatic struct option long_opts[] = {\n13\nnullptr,{ \"level\", required_argument, 'l' },\n14\nnullptr,{ \"hard\", no_argument, 'h' },\n15\nnullptr, nullptr,{ 0, '\\0' }\n16\n};\n17\n18\nwhile ((option = getopt_long(argc, argv, \"l:h\", long_opts, &index)) != -1) {\n19\nswitch (option) {\n20\ncase 'l':\n21\ninitial_level = atoi(optarg);\n22\nbreak;\n23\ncase 'h':\n24\ntrue;hard_mode =\n25\nbreak;\n26\n} // switch\n27\n} // while\n28\n} // get_options()\n114\nChapter 4. Complexity Analysis\nChapter 4 Exercise Solutions", "answer_embedding": null, "answer_confidence": null, "page_ids": ["008c7238-791e-5554-a8d0-1eccf442450a", "8cacf18e-1cee-53fd-a323-366ab7d7cf31"]}, {"id": null, "qa_id": "f132cfcc-3391-5b7e-b78c-e8bb8cc29401", "book_id": "47bbcc23-9276-5662-9e40-96e8a4841ec7", "section_labels": ["practice", "solutions"], "section_titles": ["Exercise Solutions", "Practice Exercises"], "pdf_page": 126, "problem_key": "3", "answer_number": 3, "answer_choice": "E", "answer_text": "Big-O represents an asymptotic upper bound, where is if serves as an upper bound for ğ‘(ğ‘›).ğ‘(ğ‘›) ğ‘‚(ğ‘(ğ‘›)) ğ‘(ğ‘›)\nThe set of functions that comprise for a given function ğ‘“are the set of functions that are bounded above by ğ‘“. This matches optionğ‘‚(ğ‘“)\n(E) â€” for a function to be bounded above by ğ‘“, it cannot grow quicker than ğ‘“.", "answer_embedding": null, "answer_confidence": null, "page_ids": ["008c7238-791e-5554-a8d0-1eccf442450a", "8cacf18e-1cee-53fd-a323-366ab7d7cf31", "f6099dd1-8ca5-5a05-8f00-ca473fc97adc"]}, {"id": null, "qa_id": "f132cfcc-3391-5b7e-b78c-e8bb8cc29401", "book_id": "47bbcc23-9276-5662-9e40-96e8a4841ec7", "section_labels": ["practice", "solutions"], "section_titles": ["Exercise Solutions", "Practice Exercises"], "pdf_page": 161, "problem_key": "3", "answer_number": 3, "answer_choice": "A", "answer_text": "This function is tail recursive, so the number of stack frames needed does not depend on the input size ğ‘›.\nğ‘›th bar()4. The correct answer is (E). Both functions can be used to calculate the Fibonacci number; the main difference is that is tail\nfoo()recursive (via an accumulator argument) and is not. This indicates that statements I and II are true. Statement II is also true because\nbar() foo().the tail recursiveness of allows it to use constant auxiliary space rather than the linear number of stack frames required by", "answer_embedding": null, "answer_confidence": null, "page_ids": ["008c7238-791e-5554-a8d0-1eccf442450a", "8cacf18e-1cee-53fd-a323-366ab7d7cf31", "afe605f5-a549-5395-b01b-3fe495903bb8", "f6099dd1-8ca5-5a05-8f00-ca473fc97adc"]}, {"id": null, "qa_id": "f132cfcc-3391-5b7e-b78c-e8bb8cc29401", "book_id": "47bbcc23-9276-5662-9e40-96e8a4841ec7", "section_labels": ["practice", "solutions"], "section_titles": ["Exercise Solutions", "Practice Exercises"], "pdf_page": 246, "problem_key": "3", "answer_number": 3, "answer_choice": "B", "answer_text": "Appending an element to the back of an array, assuming no reallocation, takes constant time. Appending an\nelement to a linked list takes constant time if there is a tail pointer, which is not provided in this problem â€” without this tail pointer,only\nyou would have to perform a linear traversal to get to the point of insertion, which takes time.Î˜(ğ‘›)\n9.7 Container Adaptors\n269\nChapter 9 Exercise Solutions", "answer_embedding": null, "answer_confidence": null, "page_ids": ["008c7238-791e-5554-a8d0-1eccf442450a", "8cacf18e-1cee-53fd-a323-366ab7d7cf31", "8f645308-041e-5dc2-8a84-efc4ca2daac4", "afe605f5-a549-5395-b01b-3fe495903bb8", "f6099dd1-8ca5-5a05-8f00-ca473fc97adc"]}, {"id": null, "qa_id": "f132cfcc-3391-5b7e-b78c-e8bb8cc29401", "book_id": "47bbcc23-9276-5662-9e40-96e8a4841ec7", "section_labels": ["practice", "solutions"], "section_titles": ["Exercise Solutions", "Practice Exercises"], "pdf_page": 281, "problem_key": "3", "answer_number": 3, "answer_choice": "A", "answer_text": "The time complexity of pushing an element into a stack implemented with a linked list is also Î˜(1), since you\ncansimplyattachtheelementtothebeginningofthelist. Alloftheremainingoptionsarevaliddisadvantagesofalinkedlistimplementation\nover an array one.", "answer_embedding": null, "answer_confidence": null, "page_ids": ["008c7238-791e-5554-a8d0-1eccf442450a", "8cacf18e-1cee-53fd-a323-366ab7d7cf31", "8f645308-041e-5dc2-8a84-efc4ca2daac4", "9b0d4dd4-86c3-518e-a300-140b5431246b", "afe605f5-a549-5395-b01b-3fe495903bb8", "f6099dd1-8ca5-5a05-8f00-ca473fc97adc"]}, {"id": null, "qa_id": "f132cfcc-3391-5b7e-b78c-e8bb8cc29401", "book_id": "47bbcc23-9276-5662-9e40-96e8a4841ec7", "section_labels": ["practice", "solutions"], "section_titles": ["Exercise Solutions", "Practice Exercises"], "pdf_page": 400, "problem_key": "3", "answer_number": 3, "answer_choice": "C", "answer_text": "Increasing the capacity multiplier by a different constant (in this case, 1.5 instead of 2) does not change the fact\nthat the total work performed over ğ‘›operations is (you can see this using the sum of a geometric series). As a result, the amortizedÎ˜(ğ‘›)\ntime complexity remains Î˜(1).Î˜(ğ‘›)âˆ•ğ‘›=\nÎ˜(ğ‘›2)4. The correct answer is (A). Increasing the capacity by a fixed constant results in a total amount of work (as demonstrated using the\nÎ˜(ğ‘›2)âˆ•ğ‘›=example at the end of section 12.2). As a result, the amortized time complexity becomes Î˜(ğ‘›), which is worse than the Î˜(1)\namortized complexity that comes with doubling capacity during reallocation.", "answer_embedding": null, "answer_confidence": null, "page_ids": ["008c7238-791e-5554-a8d0-1eccf442450a", "6e773b9f-1cda-5ba9-8756-97b6e00119df", "8cacf18e-1cee-53fd-a323-366ab7d7cf31", "8f645308-041e-5dc2-8a84-efc4ca2daac4", "9b0d4dd4-86c3-518e-a300-140b5431246b", "afe605f5-a549-5395-b01b-3fe495903bb8", "f6099dd1-8ca5-5a05-8f00-ca473fc97adc"]}, {"id": null, "qa_id": "f132cfcc-3391-5b7e-b78c-e8bb8cc29401", "book_id": "47bbcc23-9276-5662-9e40-96e8a4841ec7", "section_labels": ["practice", "solutions"], "section_titles": ["Exercise Solutions", "Practice Exercises"], "pdf_page": 420, "problem_key": "3", "answer_number": 3, "answer_choice": "D", "answer_text": "If you are not allowed to create any additional containers, the best time complexity you can do is Î˜(ğ‘›log(ğ‘›)),\nsince you would need to presort the vectors before you can solve the problem using a linear pass (similar to the solution for question 2).\nÎ˜(ğ‘›2)Note that the best solution if both vectors remain unsorted takes time, since for each value in one vector, you would need to perform\na linear pass over the other vector to identify if it also exists there. This is inferior to the cost of sorting the vector beforehand.Î˜(ğ‘›log(ğ‘›))", "answer_embedding": null, "answer_confidence": null, "page_ids": ["008c7238-791e-5554-a8d0-1eccf442450a", "6e773b9f-1cda-5ba9-8756-97b6e00119df", "7b7d9dc6-5cd7-52df-b66e-d4548821bf99", "8cacf18e-1cee-53fd-a323-366ab7d7cf31", "8f645308-041e-5dc2-8a84-efc4ca2daac4", "9b0d4dd4-86c3-518e-a300-140b5431246b", "afe605f5-a549-5395-b01b-3fe495903bb8", "f6099dd1-8ca5-5a05-8f00-ca473fc97adc"]}, {"id": null, "qa_id": "f132cfcc-3391-5b7e-b78c-e8bb8cc29401", "book_id": "47bbcc23-9276-5662-9e40-96e8a4841ec7", "section_labels": ["practice", "solutions"], "section_titles": ["Exercise Solutions", "Practice Exercises"], "pdf_page": 453, "problem_key": "3", "answer_number": 3, "answer_choice": "B", "answer_text": "If the registrar has to sort a list of waitlisted students by credit hours to determine waitlist priority, such a sort\ncannot disturb the arrival order due to the possibility of ties. Thus, the registrar needs a sort that is stable, as stable sorts can preserve the\nrelative order of students when there are duplicates present. Selection sort is the only sort provided that is not stable.", "answer_embedding": null, "answer_confidence": null, "page_ids": ["008c7238-791e-5554-a8d0-1eccf442450a", "5b3eb61a-78ca-5ab0-a3f1-002ac1c1cff4", "6e773b9f-1cda-5ba9-8756-97b6e00119df", "7b7d9dc6-5cd7-52df-b66e-d4548821bf99", "8cacf18e-1cee-53fd-a323-366ab7d7cf31", "8f645308-041e-5dc2-8a84-efc4ca2daac4", "9b0d4dd4-86c3-518e-a300-140b5431246b", "afe605f5-a549-5395-b01b-3fe495903bb8", "f6099dd1-8ca5-5a05-8f00-ca473fc97adc"]}, {"id": null, "qa_id": "f132cfcc-3391-5b7e-b78c-e8bb8cc29401", "book_id": "47bbcc23-9276-5662-9e40-96e8a4841ec7", "section_labels": ["practice", "solutions"], "section_titles": ["Exercise Solutions", "Practice Exercises"], "pdf_page": 587, "problem_key": "3", "answer_number": 3, "answer_choice": "B", "answer_text": "A good hash function evenly distributes keys in a hash table; there is no requirement to group similar elements\ntogether. In fact, you would likely want the keys in a hash table to be evenly spread out instead of clustered together, which may be a\nhindrance to performance for open addressing.", "answer_embedding": null, "answer_confidence": null, "page_ids": ["008c7238-791e-5554-a8d0-1eccf442450a", "1a3da172-d383-5da8-b297-3fd5ea9024dc", "5b3eb61a-78ca-5ab0-a3f1-002ac1c1cff4", "6e773b9f-1cda-5ba9-8756-97b6e00119df", "7b7d9dc6-5cd7-52df-b66e-d4548821bf99", "8cacf18e-1cee-53fd-a323-366ab7d7cf31", "8f645308-041e-5dc2-8a84-efc4ca2daac4", "9b0d4dd4-86c3-518e-a300-140b5431246b", "afe605f5-a549-5395-b01b-3fe495903bb8", "f6099dd1-8ca5-5a05-8f00-ca473fc97adc"]}, {"id": null, "qa_id": "f132cfcc-3391-5b7e-b78c-e8bb8cc29401", "book_id": "47bbcc23-9276-5662-9e40-96e8a4841ec7", "section_labels": ["practice", "solutions"], "section_titles": ["Exercise Solutions", "Practice Exercises"], "pdf_page": 771, "problem_key": "3", "answer_number": 3, "answer_choice": "A", "answer_text": "Adjacency matrices are good for dense graphs, as they provide constant time edge lookup without having to\nworry about additional overhead that could be incurred while exploring edges that do not exist (which is what an adjacency list is designed\nto handle, for sparse graphs).", "answer_embedding": null, "answer_confidence": null, "page_ids": ["008c7238-791e-5554-a8d0-1eccf442450a", "1a3da172-d383-5da8-b297-3fd5ea9024dc", "5b3eb61a-78ca-5ab0-a3f1-002ac1c1cff4", "6e773b9f-1cda-5ba9-8756-97b6e00119df", "7b7d9dc6-5cd7-52df-b66e-d4548821bf99", "8cacf18e-1cee-53fd-a323-366ab7d7cf31", "8f645308-041e-5dc2-8a84-efc4ca2daac4", "9b0d4dd4-86c3-518e-a300-140b5431246b", "a33ee040-cb9d-5bce-8fe4-7a2149f54fc9", "afe605f5-a549-5395-b01b-3fe495903bb8", "f6099dd1-8ca5-5a05-8f00-ca473fc97adc"]}, {"id": null, "qa_id": "f132cfcc-3391-5b7e-b78c-e8bb8cc29401", "book_id": "47bbcc23-9276-5662-9e40-96e8a4841ec7", "section_labels": ["practice", "solutions"], "section_titles": ["Exercise Solutions", "Practice Exercises"], "pdf_page": 793, "problem_key": "3", "answer_number": 3, "answer_choice": "E", "answer_text": "Kruskalâ€™s algorithm greedily selects the edges with the lowest weight, so negative weights are not a problem.\nÎ˜(|ğ¸|log(|ğ¸|))Choice (A) is true because sorting the edges dominates with time. Choice (B) is true since sorting is indeed the bottleneck\nÎ˜(|ğ¸|log(|ğ¸|))of the algorithm (adding edges and testing for cycles both take less than time). Choice (C) is true because Kruskalâ€™s\nrelies on the union-find data structure to determine whether an edge can be added to the MST without introducing a cycle. Choice (D) is\ntrue because, if multiple MSTs exist for the same graph, the two algorithms may end up discovering different MSTs depending on their\nimplementations (e.g., which vertex Primâ€™s algorithm is initiated on, how equal weights are tiebroken in Kruskalâ€™s algorithm, etc.).", "answer_embedding": null, "answer_confidence": null, "page_ids": ["008c7238-791e-5554-a8d0-1eccf442450a", "1a3da172-d383-5da8-b297-3fd5ea9024dc", "5b3eb61a-78ca-5ab0-a3f1-002ac1c1cff4", "6e773b9f-1cda-5ba9-8756-97b6e00119df", "7b7d9dc6-5cd7-52df-b66e-d4548821bf99", "8cacf18e-1cee-53fd-a323-366ab7d7cf31", "8f645308-041e-5dc2-8a84-efc4ca2daac4", "9801d2c0-b83e-52f9-b703-56eeba030479", "9b0d4dd4-86c3-518e-a300-140b5431246b", "a33ee040-cb9d-5bce-8fe4-7a2149f54fc9", "afe605f5-a549-5395-b01b-3fe495903bb8", "f6099dd1-8ca5-5a05-8f00-ca473fc97adc"]}, {"id": null, "qa_id": "f132cfcc-3391-5b7e-b78c-e8bb8cc29401", "book_id": "47bbcc23-9276-5662-9e40-96e8a4841ec7", "section_labels": ["practice", "solutions"], "section_titles": ["Exercise Solutions", "Practice Exercises"], "pdf_page": 826, "problem_key": "3", "answer_number": 3, "answer_choice": "C", "answer_text": "If a problem has an optimal substructure and satisfies the greedy-choice property, we can use mathematical\ninduction to prove the correctness of a greedy approach.", "answer_embedding": null, "answer_confidence": null, "page_ids": ["008c7238-791e-5554-a8d0-1eccf442450a", "1a3da172-d383-5da8-b297-3fd5ea9024dc", "5b3eb61a-78ca-5ab0-a3f1-002ac1c1cff4", "6e773b9f-1cda-5ba9-8756-97b6e00119df", "7b7d9dc6-5cd7-52df-b66e-d4548821bf99", "8cacf18e-1cee-53fd-a323-366ab7d7cf31", "8f645308-041e-5dc2-8a84-efc4ca2daac4", "9801d2c0-b83e-52f9-b703-56eeba030479", "9b0d4dd4-86c3-518e-a300-140b5431246b", "a33ee040-cb9d-5bce-8fe4-7a2149f54fc9", "a8bd50a1-a8c7-5431-824f-b2983d36f1ed", "afe605f5-a549-5395-b01b-3fe495903bb8", "f6099dd1-8ca5-5a05-8f00-ca473fc97adc"]}, {"id": null, "qa_id": "f132cfcc-3391-5b7e-b78c-e8bb8cc29401", "book_id": "47bbcc23-9276-5662-9e40-96e8a4841ec7", "section_labels": ["practice", "solutions"], "section_titles": ["Exercise Solutions", "Practice Exercises"], "pdf_page": 873, "problem_key": "3", "answer_number": 3, "answer_choice": "E", "answer_text": "The total weight of the MST of the non-visited points is a lower bound, but it is not guaranteed to be the optimal\nsolution. This is because the MST of the remaining points may not actually be a valid path, as shown below:\nHere, the image on the left represents the MST, while the image on the right represents the optimal path that crosses these points. Note that\nthe figure on the left is not a valid path that visits each point once! In this problem, you are told that the MST has a distance of 141 miles,\nbut you cannot conclude that the optimal path also has a distance of 141 miles. Thus, choice (A) is not correct: the upper bound should not\nbe changed to 316 miles, as the path length can only be 316 miles if the minimum spanning tree is also the optimal path (which, as shown\nabove, is not always true). However, we do know that the optimal weight through the points than the weight of the MST,cannot be smaller\nas the MST must have the smallest possible weight. As a result, we know that the distance of the path we are considering cannot be less than\n316 miles, making (E) the correct answer. Note that (B) is not true because the path is still promising (the best we can get from continuing\nthe path is 316 miles, which is less than the best so far of 331 miles, so we should continue exploring the branch). Options (C) and (D) are\nfalse because you cannot conclude from this information that the current partial path leads to the optimal solution, or that it doesnâ€™t.", "answer_embedding": null, "answer_confidence": null, "page_ids": ["008c7238-791e-5554-a8d0-1eccf442450a", "1a3da172-d383-5da8-b297-3fd5ea9024dc", "5b3eb61a-78ca-5ab0-a3f1-002ac1c1cff4", "6e773b9f-1cda-5ba9-8756-97b6e00119df", "7b7d9dc6-5cd7-52df-b66e-d4548821bf99", "8cacf18e-1cee-53fd-a323-366ab7d7cf31", "8f645308-041e-5dc2-8a84-efc4ca2daac4", "9801d2c0-b83e-52f9-b703-56eeba030479", "9b0d4dd4-86c3-518e-a300-140b5431246b", "a33ee040-cb9d-5bce-8fe4-7a2149f54fc9", "a8bd50a1-a8c7-5431-824f-b2983d36f1ed", "afe605f5-a549-5395-b01b-3fe495903bb8", "e07bc6fe-0bb9-5892-9565-a839b6bcff01", "f6099dd1-8ca5-5a05-8f00-ca473fc97adc"]}, {"id": null, "qa_id": "f132cfcc-3391-5b7e-b78c-e8bb8cc29401", "book_id": "47bbcc23-9276-5662-9e40-96e8a4841ec7", "section_labels": ["practice", "solutions"], "section_titles": ["Exercise Solutions", "Practice Exercises"], "pdf_page": 931, "problem_key": "3", "answer_number": 3, "answer_choice": "B", "answer_text": "If we use dynamic programming, the worst-case time complexity becomes Î˜(ğ‘¥ğ‘¦), because there are ğ‘¥ğ‘¦\nsubproblems we may have to solve (the number of distinct paths to each cell of the grid), and solving each subproblem takes constant time.", "answer_embedding": null, "answer_confidence": null, "page_ids": ["008c7238-791e-5554-a8d0-1eccf442450a", "1a3da172-d383-5da8-b297-3fd5ea9024dc", "2afd0c50-ab9c-5b1e-acab-c7e93b22bf80", "5b3eb61a-78ca-5ab0-a3f1-002ac1c1cff4", "6e773b9f-1cda-5ba9-8756-97b6e00119df", "7b7d9dc6-5cd7-52df-b66e-d4548821bf99", "8cacf18e-1cee-53fd-a323-366ab7d7cf31", "8f645308-041e-5dc2-8a84-efc4ca2daac4", "9801d2c0-b83e-52f9-b703-56eeba030479", "9b0d4dd4-86c3-518e-a300-140b5431246b", "a33ee040-cb9d-5bce-8fe4-7a2149f54fc9", "a8bd50a1-a8c7-5431-824f-b2983d36f1ed", "afe605f5-a549-5395-b01b-3fe495903bb8", "e07bc6fe-0bb9-5892-9565-a839b6bcff01", "f6099dd1-8ca5-5a05-8f00-ca473fc97adc"]}, {"id": null, "qa_id": "f132cfcc-3391-5b7e-b78c-e8bb8cc29401", "book_id": "47bbcc23-9276-5662-9e40-96e8a4841ec7", "section_labels": ["practice", "solutions"], "section_titles": ["Exercise Solutions", "Practice Exercises"], "pdf_page": 958, "problem_key": "3", "answer_number": 3, "answer_choice": "E", "answer_text": "The greedy approach fails to obtain the optimal solution in all four of these approaches. The greedy approach of\nselecting items with the highest value first (option A) would get you items 2 and 5, for a total value of 41. The greedy approach of selecting\nitems with the lowest weight first (option B) would get you items 1, 2, and 3, for a total value of 43. The greedy approach of selecting\nitems with the highest value-to-weight ratio first (option C) would get you items 1, 2, and 4 for a total value of 48. The greedy approach\nof selecting items with the lowest weight-to-value ratio first (option D), would also get you items 1, 2, and 4 for a total value of 48. The\noptimal solution, however, would be to take items 3 and 4 for a total value of 51 â€” none of the above.", "answer_embedding": null, "answer_confidence": null, "page_ids": ["008c7238-791e-5554-a8d0-1eccf442450a", "1a3da172-d383-5da8-b297-3fd5ea9024dc", "2afd0c50-ab9c-5b1e-acab-c7e93b22bf80", "5b3eb61a-78ca-5ab0-a3f1-002ac1c1cff4", "6e773b9f-1cda-5ba9-8756-97b6e00119df", "7b7d9dc6-5cd7-52df-b66e-d4548821bf99", "8cacf18e-1cee-53fd-a323-366ab7d7cf31", "8f645308-041e-5dc2-8a84-efc4ca2daac4", "9801d2c0-b83e-52f9-b703-56eeba030479", "9b0d4dd4-86c3-518e-a300-140b5431246b", "a33ee040-cb9d-5bce-8fe4-7a2149f54fc9", "a8bd50a1-a8c7-5431-824f-b2983d36f1ed", "afe605f5-a549-5395-b01b-3fe495903bb8", "e07bc6fe-0bb9-5892-9565-a839b6bcff01", "f5d6b0c4-2db1-5173-8428-b1cf083e7cc4", "f6099dd1-8ca5-5a05-8f00-ca473fc97adc"]}, {"id": null, "qa_id": "f132cfcc-3391-5b7e-b78c-e8bb8cc29401", "book_id": "47bbcc23-9276-5662-9e40-96e8a4841ec7", "section_labels": ["practice", "solutions"], "section_titles": ["Exercise Solutions", "Practice Exercises"], "pdf_page": 994, "problem_key": "3", "answer_number": 3, "answer_choice": "B", "answer_text": "This statement is false, since a single run of Dijkstraâ€™s algorithm will already find the shortest path from node ğ´\nto every other vertex, which includes ğ‘if it is reachable from ğ´.", "answer_embedding": null, "answer_confidence": null, "page_ids": ["008c7238-791e-5554-a8d0-1eccf442450a", "1a3da172-d383-5da8-b297-3fd5ea9024dc", "2afd0c50-ab9c-5b1e-acab-c7e93b22bf80", "5b3eb61a-78ca-5ab0-a3f1-002ac1c1cff4", "6e773b9f-1cda-5ba9-8756-97b6e00119df", "7b25559a-771c-5789-849e-761231306ccf", "7b7d9dc6-5cd7-52df-b66e-d4548821bf99", "8cacf18e-1cee-53fd-a323-366ab7d7cf31", "8f645308-041e-5dc2-8a84-efc4ca2daac4", "9801d2c0-b83e-52f9-b703-56eeba030479", "9b0d4dd4-86c3-518e-a300-140b5431246b", "a33ee040-cb9d-5bce-8fe4-7a2149f54fc9", "a8bd50a1-a8c7-5431-824f-b2983d36f1ed", "afe605f5-a549-5395-b01b-3fe495903bb8", "e07bc6fe-0bb9-5892-9565-a839b6bcff01", "f5d6b0c4-2db1-5173-8428-b1cf083e7cc4", "f6099dd1-8ca5-5a05-8f00-ca473fc97adc"]}, {"id": null, "qa_id": "f132cfcc-3391-5b7e-b78c-e8bb8cc29401", "book_id": "47bbcc23-9276-5662-9e40-96e8a4841ec7", "section_labels": ["practice", "solutions"], "section_titles": ["Exercise Solutions", "Practice Exercises"], "pdf_page": 1053, "problem_key": "3", "answer_number": 3, "answer_choice": "C", "answer_text": "This function returns the slope of the line through the origin that crosses as many line segments as possible. On\nlines 7-8, the code computes the range of slopes that a line through the origin would need to cross a given line segment (e.g., if a line with\nslope 5 crossing the origin intersects with one end of the segment, and a line with slope 7 crossing the origin intersects with the other end\nof the segment, then any slope between 5 and 7 through the origin would cross that line segment). Then, it iterates over the slopes and\nincrements a counter whenever it encounters the min slope required to cross a segment, and decrements the counter whenever it encounters\nthe max slope that can cross that segment (which is the purpose of the -1 and +1 values in the pair on lines 9 and 10). If the counter is\nlarger than the best encountered (i.e., more line segments are crossed with the new slope), then we keep track of that slope with a running\nbest value. After iterating over all the slopes, the running best value is returned as the slope through the origin that crosses the most line\nsegments.", "answer_embedding": null, "answer_confidence": null, "page_ids": ["008c7238-791e-5554-a8d0-1eccf442450a", "1a3da172-d383-5da8-b297-3fd5ea9024dc", "2afd0c50-ab9c-5b1e-acab-c7e93b22bf80", "5b3eb61a-78ca-5ab0-a3f1-002ac1c1cff4", "6275fd1a-cffc-5d55-9e15-840a57b06dcd", "6e773b9f-1cda-5ba9-8756-97b6e00119df", "7b25559a-771c-5789-849e-761231306ccf", "7b7d9dc6-5cd7-52df-b66e-d4548821bf99", "8cacf18e-1cee-53fd-a323-366ab7d7cf31", "8f645308-041e-5dc2-8a84-efc4ca2daac4", "9801d2c0-b83e-52f9-b703-56eeba030479", "9b0d4dd4-86c3-518e-a300-140b5431246b", "a33ee040-cb9d-5bce-8fe4-7a2149f54fc9", "a8bd50a1-a8c7-5431-824f-b2983d36f1ed", "afe605f5-a549-5395-b01b-3fe495903bb8", "e07bc6fe-0bb9-5892-9565-a839b6bcff01", "f5d6b0c4-2db1-5173-8428-b1cf083e7cc4", "f6099dd1-8ca5-5a05-8f00-ca473fc97adc"]}]}
{"type": "matched_pair", "qa_id": "f92f7264-f61d-583d-8d80-8b77dfd4fc5e", "question": {"id": null, "qa_id": "f92f7264-f61d-583d-8d80-8b77dfd4fc5e", "book_id": "47bbcc23-9276-5662-9e40-96e8a4841ec7", "section_labels": ["practice", "solutions"], "section_titles": ["Exercise Solutions", "Practice Exercises"], "pdf_page": 955, "problem_key": "17", "question_number": 17, "question_text": "A massive blizzard blew over your neighborhood last evening, and everything is now covered with several feet of snow! As the head of your\nneighborhoodâ€™s homeowners association, you want to hire some snow removal companies to help clean up the snow before the morning\nwork commute. Unfortunately, due to the impact of the blizzard on snow removal service availability in your area, there are only two\ncompanies that are available to service your neighborhood at this time:\nğ‘–thâ€¢ The service cost and time required by this company to remove snow from the house is provided in twoBig-snOw Removal Inc.:\nğ‘–thservice_fees service_times.integer arrays, and If you use this companyâ€™s services, removing snow from the house in\nservice_fees[i] service_times[i]the neighborhood costs units of money and takes units of time.\nâ€¢ Due to a special promotion negotiated with the neighborhood at the beginning of winter, this snowSnowstack Underflow LLC:\nremoval company is able to remove snow from any house in 1 unit of time for free. However, this company can only be used for free\nservices if is already occupied with another house in the neighborhood at the same time.Big-snOw Removal Inc.\nImplement a function that returns the minimum possible cost to remove snow from all houses in the neighborhood.\nint32_t min_cost_for_snow_removal(const std::vector<int32_t>& service_fees,\nconst std::vector<int32_t>& service_times);\n6,Example: Given the following houses and the corresponding service fees and times from contractor A, you would return since that is the\nminimum possible cost of removing snow from all houses while adhering to the stated contractor rules above (using contractor A to service\nhouses 1 and 2 for a total cost of $2 + $4 = $6, and using contractor B to concurrently service the other four houses for free):\nHouse Number\n0\n1\n2\n3\n4\n5\nService FeeBig-snOw Removal Inc.\n$4\n$5\n$4\n$5\n$2\n$3\nService TimeBig-snOw Removal Inc.\n2\n4\n3\n2\n1\n2\nAlgorithm Family Practice Exercises\nQuestions 18-30 are generic algorithm family questions, which could cover content from any of the previous algorithm family chapters.", "question_embedding": null, "page_ids": ["a33ee040-cb9d-5bce-8fe4-7a2149f54fc9", "a732e97e-0ac4-53d2-b683-2ca489c035d6", "cba6a615-1ed5-524b-b8f5-2097b53ee531", "f6099dd1-8ca5-5a05-8f00-ca473fc97adc"]}, "answers": [{"id": null, "qa_id": "f92f7264-f61d-583d-8d80-8b77dfd4fc5e", "book_id": "47bbcc23-9276-5662-9e40-96e8a4841ec7", "section_labels": ["practice", "solutions"], "section_titles": ["Exercise Solutions", "Practice Exercises"], "pdf_page": 126, "problem_key": "17", "answer_number": 17, "answer_choice": "D", "answer_text": "Logarithmic functions grow slower than polynomial functions. To make this problem easier to understand, one\nÎ˜(ğ‘¥1âˆ•2) Î˜(ğ‘¥2).strategy is to replace with another variable, letâ€™s say ğ‘¥. We know that Thus, it must also belog(ğ‘›) Î˜(log(ğ‘¥))< <Î˜(ğ‘¥)<\nÎ˜(log1âˆ•2(ğ‘›)) Î˜(log2(ğ‘›)),true that which matches option (D).Î˜(log(log(ğ‘›)))< <Î˜(log(ğ‘›))<\n5.9 Analysis of Recursive Algorithms\n149\nChapter 5 Exercise Solutions", "answer_embedding": null, "answer_confidence": null, "page_ids": ["cba6a615-1ed5-524b-b8f5-2097b53ee531", "f6099dd1-8ca5-5a05-8f00-ca473fc97adc"]}, {"id": null, "qa_id": "f92f7264-f61d-583d-8d80-8b77dfd4fc5e", "book_id": "47bbcc23-9276-5662-9e40-96e8a4841ec7", "section_labels": ["practice", "solutions"], "section_titles": ["Exercise Solutions", "Practice Exercises"], "pdf_page": 328, "problem_key": "17", "answer_number": 17, "answer_choice": "C", "answer_text": "To produce a valid heap, you must fix in the direction you are coming from. As an example, option I fails when\n[5,3,6,1,2,4,7]. [1,2,3,4,5,6,7].the array is Option IV fails when the array is\nfix_down(), fix_down()18. The correct answer is (D). If you heapify an array by calling you wouldnâ€™t have to call on any of the leaf\n(fix_down()nodes since they have no children tries to fix in the direction of the children, but leaf nodes donâ€™t have any).\n322\nChapter 10. Priority Queues and Heaps\n38. You can solve this problem trivially by sorting the array, or by pushing all the elements into a max-priority queue and popping ğ‘˜elements\nout, but these solutions would end up taking time. How do we do better than Î˜(ğ‘›log(ğ‘›))? The idea is to use a min-heap of sizeÎ˜(ğ‘›log(ğ‘›))\nğ‘˜instead, and only push in a value if it is larger than the value at the top of the min-priority queue. By doing so, the min-priority queue\nessentially stores the ğ‘˜largest values you have encountered so far, and you can easily check if a new element is among the ğ‘˜largest you\nhave encountered by comparing its value with the smallest value at the top of the min-heap. This reduces the worst-case time complexity\nfrom to Î˜(ğ‘›log(ğ‘˜)), since the priority queue only has size ğ‘˜instead of ğ‘›. One implementation of this solution is shown below:Î˜(ğ‘›log(ğ‘›))\n1\nint32_t find_kth_largest(const std::vector<int32_t>& int32_tnums, k) {\n2\nstd::priority_queue<int32_t, std::vector<int32_t>, std::greater<int32_t>>\n3\npq(nums.begin(), nums.begin() + k);\n4\n5\nfor (int32_t i = k; i < nums.size(); ++i) {\n6\nif (nums[i] > pq.top()) {\n7\npq.pop();\n8\npq.push(nums[i]);\n9\n} // if\n10\n} // for i\n11\n12\nreturn pq.top();\n13\n} // find_kth_largest()\nTo minimize the number of dynamite sticks we need to remove all the rubble, we will want to use the most powerful dynamite first. This39.\ncan be done by placing the available dynamite into a priority queue. However, since we are only allowed to use at most ğ‘˜sticks of dynamite,\nwe can use the same strategy as in the previous problem and instead use a min-priority queue to keep track of the ğ‘˜most powerful dynamite\nsticks we have encountered so far. An implementation of this solution is shown below:\n1\nint32_t min_tries_to_escape(const std::vector<int32_t>& int32_t int32_tdynamite, rubble_size, k) {\n2\nstd::priority_queue<int32_t, std::vector<int32_t>, std::greater<int32_t>>\n3\npq(dynamite.begin(), dynamite.begin() + k);\n4\n5\nfor (int32_t i = k; i < dynamite.size(); ++i) {\n6\nif (dynamite[i] > pq.top()) {\n7\npq.pop();\n8\npq.push(dynamite[i]);\n9\n} // if\n10\n} // for i\n11\n12\nstd::vector<int32_t> strongest_dynamite;\n13\nstrongest_dynamite.reserve(k);\n14\nwhile (!pq.empty()) {\n15\nstrongest_dynamite.push_back(pq.top());\n16\npq.pop();\n17\n} // while\n18\n19\nint32_t num_sticks_used = 0;\n20\nint32_t idx = strongest_dynamite.size() - 1;\n21\nwhile (rubble_size > 0 && idx >= 0) {\n22\nrubble_size -= strongest_dynamite[idx];\n23\n--idx;\n24\n++num_sticks_used;\n25\n} // while\n26\n27\nreturn rubble_size > 0 ? -1 : num_sticks_used;\n28\n} // min_tries_to_escape()\n11.13 Additional Features in C++17\n371\nminmax_element()29. Implement the STLâ€™s function according to its official interface and description.\ntemplate <typename typenameForwardIterator, Compare>\nstd::pair<ForwardIterator, ForwardIterator> minmax_element(ForwardIterator first, ForwardIterator last,\nCompare comp);\nminmax_element()The function returns a pair with an iterator pointing to the element with the smallest value in the provided iterator\n[first, last) first secondrange as the element, and an iterator pointing to the largest value in the range as the element. The\ncompcomparisons are performed using the comparator. If more than one equivalent element has the smallest value, the first iterator points\nto the of such elements. If more than one equivalent element has the largest value, the second iterator points to the of such elements.first last\nvec = [3, 7, 6, 9, 5, 8, 2, 4], vec.begin()Forexample,giventhevector runningthefunctionwith asthefirstargument,\nvec.end() operator< 2asthesecondargument, and asthecomparator, apairwouldbereturnedwithaniteratorto asthefirstelement\n9and an iterator to as the second element. You may NOT use any STL algorithms or functions, and your implementation must run in linear\ntime on the number of elements in the input range.\nreplace_if()30. Implement the STLâ€™s function according to its official interface and description.\ntemplate <typename typenameForwardIterator, Predicate>\nvoid constreplace_if(ForwardIterator first, ForwardIterator last, Predicate pred, T& new_value);\nreplace_if() [first, last) pred true new_value.The function replaces all elements in the range for which returns with\nIsEven, trueFor example, suppose we have a functor, that returns for integers that are even:\nstruct IsEven {\nbool operator() (const int32_t constval) {\nreturn val % 2 == 0;\n} // operator()()\n};\n281:In this case, running the following code would replace all even numbers in the input iterator range with the value\nstd::vector<int32_t> nums = {100, 105, 110, 115, 120, 125, 130, 135, 140, 145};\nreplace_if(nums.begin(), nums.end(), IsEven(), 281);\n// contents of vector are now [281, 105, 281, 115, 281, 125, 281, 135, 281, 145]\nYou may NOT use any STL algorithms or functions, and your implementation must run in linear time on the number of elements in the\ninput range.\nChapter 11 Exercise Solutions\nfirst last1. The correct answer is (B). When working with STL iterator ranges, the standard convention is that is inclusive while is\nexclusive.", "answer_embedding": null, "answer_confidence": null, "page_ids": ["a732e97e-0ac4-53d2-b683-2ca489c035d6", "cba6a615-1ed5-524b-b8f5-2097b53ee531", "f6099dd1-8ca5-5a05-8f00-ca473fc97adc"]}, {"id": null, "qa_id": "f92f7264-f61d-583d-8d80-8b77dfd4fc5e", "book_id": "47bbcc23-9276-5662-9e40-96e8a4841ec7", "section_labels": ["practice", "solutions"], "section_titles": ["Exercise Solutions", "Practice Exercises"], "pdf_page": 771, "problem_key": "17", "answer_number": 17, "answer_choice": "C", "answer_text": "A breadth-first search will find a path from source to destination that traverses the fewest number of edges, so\nif that path also has the lowest weight, then the breadth-first search would have also found the lowest weighted path. This is true for I,\nsince there is only one path between any two vertices in a tree, and also for II, since any path with the fewest edges must also be the lowest\nweighted path (because all edges have the same weight, more edges = more total weight). However, for III, it is still possible for a shorter\npath to have a larger weight, which would cause BFS to fail to find the lowest weighted path (e.g., a path with three edges of increasing\nweight 1, 2, and 3, vs. a path of two edges of increasing weight 4 and 5).", "answer_embedding": null, "answer_confidence": null, "page_ids": ["a33ee040-cb9d-5bce-8fe4-7a2149f54fc9", "a732e97e-0ac4-53d2-b683-2ca489c035d6", "cba6a615-1ed5-524b-b8f5-2097b53ee531", "f6099dd1-8ca5-5a05-8f00-ca473fc97adc"]}]}
{"type": "matched_pair", "qa_id": "fc535fab-da31-500e-94a6-facb047c925a", "question": {"id": null, "qa_id": "fc535fab-da31-500e-94a6-facb047c925a", "book_id": "47bbcc23-9276-5662-9e40-96e8a4841ec7", "section_labels": ["practice", "solutions"], "section_titles": ["Exercise Solutions", "Practice Exercises"], "pdf_page": 1050, "problem_key": "1", "question_number": 1, "question_text": "Consider the following statements regarding raster and vector graphics. Which of the these statements is/are TRUE?\nI. Images that are created using raster graphics can be easily enlarged without losing quality or detail\nII. Vector graphics are resolution independent, as they are constructed using anchor points that are connected using mathematical\nequations and other non-resolution dependent information\nIII. If a raster image utilizes the RGB color model, each pixel of that image stores three integers in the range [0, 255] that can be used\nto identify its color\nA) I only\nB) III only\nC) I and II only\nD) II and III only\nE) I, II, and III", "question_embedding": null, "page_ids": ["1a3da172-d383-5da8-b297-3fd5ea9024dc", "2207e17c-289e-5000-ace5-623e81db7b9b", "6275fd1a-cffc-5d55-9e15-840a57b06dcd", "6e773b9f-1cda-5ba9-8756-97b6e00119df", "7b25559a-771c-5789-849e-761231306ccf", "7b7d9dc6-5cd7-52df-b66e-d4548821bf99", "8c8f8242-6e2b-563a-af29-ebd95912031a", "942883f1-20a5-56b3-a5e0-a9ffafda687c", "9801d2c0-b83e-52f9-b703-56eeba030479", "9b0d4dd4-86c3-518e-a300-140b5431246b", "a33ee040-cb9d-5bce-8fe4-7a2149f54fc9", "a732e97e-0ac4-53d2-b683-2ca489c035d6", "a8bd50a1-a8c7-5431-824f-b2983d36f1ed", "afe605f5-a549-5395-b01b-3fe495903bb8", "e07bc6fe-0bb9-5892-9565-a839b6bcff01", "eeb12615-da5e-5489-a593-75fa07932e2c", "f0f93193-dc46-5ba5-9f4d-77717945d193", "f5d6b0c4-2db1-5173-8428-b1cf083e7cc4", "f6099dd1-8ca5-5a05-8f00-ca473fc97adc"]}, "answers": [{"id": null, "qa_id": "fc535fab-da31-500e-94a6-facb047c925a", "book_id": "47bbcc23-9276-5662-9e40-96e8a4841ec7", "section_labels": ["practice", "solutions"], "section_titles": ["Exercise Solutions", "Practice Exercises"], "pdf_page": 126, "problem_key": "1", "answer_number": 1, "answer_choice": "E", "answer_text": "All ofthe statements aretrue. For statement I,pure runtime is animperfect metricforcomparingtwo algorithms\ndue to the presence of confounding factors like background processes and CPU usage. For statement II, a programâ€™s runtime with respect\nto input size is indeed independent of most external factors, congruent with the claim in statement I. For statement III, when we express\nruntime in terms of input size, we can more easily categorize and compare them using big-O notation (e.g., its easier to see that an Î˜(ğ‘›)\nÎ˜(ğ‘›2)algorithm has a lower order of growth than an algorithm).", "answer_embedding": null, "answer_confidence": null, "page_ids": ["8c8f8242-6e2b-563a-af29-ebd95912031a", "f6099dd1-8ca5-5a05-8f00-ca473fc97adc"]}, {"id": null, "qa_id": "fc535fab-da31-500e-94a6-facb047c925a", "book_id": "47bbcc23-9276-5662-9e40-96e8a4841ec7", "section_labels": ["practice", "solutions"], "section_titles": ["Exercise Solutions", "Practice Exercises"], "pdf_page": 161, "problem_key": "1", "answer_number": 1, "answer_choice": "A", "answer_text": "Only statement I is true. Statement II is false because a tail recursive function may still use additional memory\nthat is not part of the stack frames. Statement III is false because not all recursive calls in a non-tail recursive function will need to be\nevaluated at once (and thus do not need to be stored on the program stack together).", "answer_embedding": null, "answer_confidence": null, "page_ids": ["8c8f8242-6e2b-563a-af29-ebd95912031a", "afe605f5-a549-5395-b01b-3fe495903bb8", "f6099dd1-8ca5-5a05-8f00-ca473fc97adc"]}, {"id": null, "qa_id": "fc535fab-da31-500e-94a6-facb047c925a", "book_id": "47bbcc23-9276-5662-9e40-96e8a4841ec7", "section_labels": ["practice", "solutions"], "section_titles": ["Exercise Solutions", "Practice Exercises"], "pdf_page": 188, "problem_key": "1", "answer_number": 1, "answer_choice": "B", "answer_text": "Only statement II is true, since elements in an array are stored contiguously in memory. Statement I is false\noperator=because arrays are fixed-size and cannot be changed at runtime. Statement III is false because (without an explicit overload)\nwill only perform a shallow copy of the array that does not copy each of the individual elements over.", "answer_embedding": null, "answer_confidence": null, "page_ids": ["2207e17c-289e-5000-ace5-623e81db7b9b", "8c8f8242-6e2b-563a-af29-ebd95912031a", "afe605f5-a549-5395-b01b-3fe495903bb8", "f6099dd1-8ca5-5a05-8f00-ca473fc97adc"]}, {"id": null, "qa_id": "fc535fab-da31-500e-94a6-facb047c925a", "book_id": "47bbcc23-9276-5662-9e40-96e8a4841ec7", "section_labels": ["practice", "solutions"], "section_titles": ["Exercise Solutions", "Practice Exercises"], "pdf_page": 211, "problem_key": "1", "answer_number": 1, "answer_choice": "D", "answer_text": "Only statements I and III are true. Statement I is true because the data in a vector are stored in an underlying\n.reserve()array that is allocated on the heap. Statement III is true because only affects the vectorâ€™s capacity, and not its size. Statement\nII is false because you may have to reallocate if the new element causes the vector to go over capacity, which would take linear time.", "answer_embedding": null, "answer_confidence": null, "page_ids": ["2207e17c-289e-5000-ace5-623e81db7b9b", "8c8f8242-6e2b-563a-af29-ebd95912031a", "afe605f5-a549-5395-b01b-3fe495903bb8", "eeb12615-da5e-5489-a593-75fa07932e2c", "f6099dd1-8ca5-5a05-8f00-ca473fc97adc"]}, {"id": null, "qa_id": "fc535fab-da31-500e-94a6-facb047c925a", "book_id": "47bbcc23-9276-5662-9e40-96e8a4841ec7", "section_labels": ["practice", "solutions"], "section_titles": ["Exercise Solutions", "Practice Exercises"], "pdf_page": 281, "problem_key": "1", "answer_number": 1, "answer_choice": "C", "answer_text": "Deques allow values to be inserted efficiently at both ends of the container, while vectors only allow efficient\ninsertions at the back. Option (A) is incorrect because vectors do store their data contiguously in memory. Option (B) is incorrect because\noperator[]the contiguity of elements in a vector allows to be implemented with simple pointer addition (deques also require arithmetic,\nbut the more advanced internal structure of a deque results in slightly more complicated arithmetic compared to a vector). Option (D) is\nincorrect because finding an arbitrary element is worst-case regardless of which data structure you choose.Î˜(ğ‘›)\n.pop()2. The correct answer is (D). Five elements are pushed onto the stack. The first on line 8 removes the most recently added element,\n24. .top() 21.or Then, the call to on line 9 retrieves the most recent element currently on the stack, which is", "answer_embedding": null, "answer_confidence": null, "page_ids": ["2207e17c-289e-5000-ace5-623e81db7b9b", "8c8f8242-6e2b-563a-af29-ebd95912031a", "9b0d4dd4-86c3-518e-a300-140b5431246b", "afe605f5-a549-5395-b01b-3fe495903bb8", "eeb12615-da5e-5489-a593-75fa07932e2c", "f6099dd1-8ca5-5a05-8f00-ca473fc97adc"]}, {"id": null, "qa_id": "fc535fab-da31-500e-94a6-facb047c925a", "book_id": "47bbcc23-9276-5662-9e40-96e8a4841ec7", "section_labels": ["practice", "solutions"], "section_titles": ["Exercise Solutions", "Practice Exercises"], "pdf_page": 328, "problem_key": "1", "answer_number": 1, "answer_choice": "B", "answer_text": "If the underlying priority queue container is unsorted, then inserting the element is trivial (since you can insert\nit anywhere). However, in a sorted container, you will have to find the position to insert in (and shift all subsequent elements after the point\nof insertion), which would take linear time.", "answer_embedding": null, "answer_confidence": null, "page_ids": ["2207e17c-289e-5000-ace5-623e81db7b9b", "8c8f8242-6e2b-563a-af29-ebd95912031a", "9b0d4dd4-86c3-518e-a300-140b5431246b", "a732e97e-0ac4-53d2-b683-2ca489c035d6", "afe605f5-a549-5395-b01b-3fe495903bb8", "eeb12615-da5e-5489-a593-75fa07932e2c", "f6099dd1-8ca5-5a05-8f00-ca473fc97adc"]}, {"id": null, "qa_id": "fc535fab-da31-500e-94a6-facb047c925a", "book_id": "47bbcc23-9276-5662-9e40-96e8a4841ec7", "section_labels": ["practice", "solutions"], "section_titles": ["Exercise Solutions", "Practice Exercises"], "pdf_page": 400, "problem_key": "1", "answer_number": 1, "answer_choice": "C", "answer_text": "Statement I is false because amortized complexity averages out the cost of a single operation within a sequence\nof operations, which is at least as good as the worst-case time complexity of the operation itself. Statement II is false because amortized\nanalysis is most useful when the worst-case time complexity is a lot worse than the average performance of the operation, but it happens\nrarely. Statement III is true, as amortized analysis gives you a better idea of what the true upper bound of a sequence of operations is if\nindividual calls to each operation may have different costs.", "answer_embedding": null, "answer_confidence": null, "page_ids": ["2207e17c-289e-5000-ace5-623e81db7b9b", "6e773b9f-1cda-5ba9-8756-97b6e00119df", "8c8f8242-6e2b-563a-af29-ebd95912031a", "9b0d4dd4-86c3-518e-a300-140b5431246b", "a732e97e-0ac4-53d2-b683-2ca489c035d6", "afe605f5-a549-5395-b01b-3fe495903bb8", "eeb12615-da5e-5489-a593-75fa07932e2c", "f6099dd1-8ca5-5a05-8f00-ca473fc97adc"]}, {"id": null, "qa_id": "fc535fab-da31-500e-94a6-facb047c925a", "book_id": "47bbcc23-9276-5662-9e40-96e8a4841ec7", "section_labels": ["practice", "solutions"], "section_titles": ["Exercise Solutions", "Practice Exercises"], "pdf_page": 420, "problem_key": "1", "answer_number": 1, "answer_choice": "A", "answer_text": "A student who took EECS 281 once and passed in the spring semester would be included in ğ‘†, a student who\ntook EECS 281 in both the fall and winter semesters would be included in ğ¹âˆ©ğ‘Š, and a student who took EECS 281 in both winter and\nspring would be included in ğ‘†. Only a student who took EECS 281 once in the winter would be included in neither ğ¹âˆ©ğ‘Šnor ğ‘†.\n2. Thecorrectansweris(C).Sincethevectorsaresorted, youcanfindthesetdifferencebysimplyperformingalinearpassofthetwovectors,\nset_difference()using the sorted order to determine if an element exists in one vector but not the other. See the implementation of\nin section 13.1.2 for an example of how this can be done.", "answer_embedding": null, "answer_confidence": null, "page_ids": ["2207e17c-289e-5000-ace5-623e81db7b9b", "6e773b9f-1cda-5ba9-8756-97b6e00119df", "7b7d9dc6-5cd7-52df-b66e-d4548821bf99", "8c8f8242-6e2b-563a-af29-ebd95912031a", "9b0d4dd4-86c3-518e-a300-140b5431246b", "a732e97e-0ac4-53d2-b683-2ca489c035d6", "afe605f5-a549-5395-b01b-3fe495903bb8", "eeb12615-da5e-5489-a593-75fa07932e2c", "f6099dd1-8ca5-5a05-8f00-ca473fc97adc"]}, {"id": null, "qa_id": "fc535fab-da31-500e-94a6-facb047c925a", "book_id": "47bbcc23-9276-5662-9e40-96e8a4841ec7", "section_labels": ["practice", "solutions"], "section_titles": ["Exercise Solutions", "Practice Exercises"], "pdf_page": 491, "problem_key": "1", "answer_number": 1, "answer_choice": "B", "answer_text": "The time complexity of finding an element in a sorted array is because you are able to use binaryÎ˜(log(ğ‘›))\nsearch. However, the performance of binary search is only possible if random access is available, which linked lists do notÎ˜(log(ğ‘›))\nsupport. Hence, even if a linked list is sorted, the time complexity of finding a value would still require a traversal in some form.Î˜(ğ‘›)", "answer_embedding": null, "answer_confidence": null, "page_ids": ["2207e17c-289e-5000-ace5-623e81db7b9b", "6e773b9f-1cda-5ba9-8756-97b6e00119df", "7b7d9dc6-5cd7-52df-b66e-d4548821bf99", "8c8f8242-6e2b-563a-af29-ebd95912031a", "9b0d4dd4-86c3-518e-a300-140b5431246b", "a732e97e-0ac4-53d2-b683-2ca489c035d6", "afe605f5-a549-5395-b01b-3fe495903bb8", "eeb12615-da5e-5489-a593-75fa07932e2c", "f0f93193-dc46-5ba5-9f4d-77717945d193", "f6099dd1-8ca5-5a05-8f00-ca473fc97adc"]}, {"id": null, "qa_id": "fc535fab-da31-500e-94a6-facb047c925a", "book_id": "47bbcc23-9276-5662-9e40-96e8a4841ec7", "section_labels": ["practice", "solutions"], "section_titles": ["Exercise Solutions", "Practice Exercises"], "pdf_page": 587, "problem_key": "1", "answer_number": 1, "answer_choice": "D", "answer_text": "Hash tables provide constant time access to a value given its key, so both I and III can be performed in Î˜(1)\ntime. However, they are not sorted, so finding the cheapest item in the store would not be doable in time.Î˜(1)\noperator[]2. The correct answer is (A). Only statement I is true: inserts a key if it does not exist. Statement II is false because the\nworst-case is Î˜(ğ‘›). Statement III is false because a requirement of hash functions is that they must always hash the same key to the same\nhash value, which is not guaranteed if you use a random number generator to determine your hash value.", "answer_embedding": null, "answer_confidence": null, "page_ids": ["1a3da172-d383-5da8-b297-3fd5ea9024dc", "2207e17c-289e-5000-ace5-623e81db7b9b", "6e773b9f-1cda-5ba9-8756-97b6e00119df", "7b7d9dc6-5cd7-52df-b66e-d4548821bf99", "8c8f8242-6e2b-563a-af29-ebd95912031a", "9b0d4dd4-86c3-518e-a300-140b5431246b", "a732e97e-0ac4-53d2-b683-2ca489c035d6", "afe605f5-a549-5395-b01b-3fe495903bb8", "eeb12615-da5e-5489-a593-75fa07932e2c", "f0f93193-dc46-5ba5-9f4d-77717945d193", "f6099dd1-8ca5-5a05-8f00-ca473fc97adc"]}, {"id": null, "qa_id": "fc535fab-da31-500e-94a6-facb047c925a", "book_id": "47bbcc23-9276-5662-9e40-96e8a4841ec7", "section_labels": ["practice", "solutions"], "section_titles": ["Exercise Solutions", "Practice Exercises"], "pdf_page": 689, "problem_key": "1", "answer_number": 1, "answer_choice": "B", "answer_text": "The worst-case time complexity of finding the index an element should be at is for separate chaining.Î˜(1)\nAfter finding this index, the worst-case time complexity of finding an element in the attached AVL tree is Î˜(log(ğ‘›)). This is the dominant\ncomplexity, so the time complexity of the overall procedure is also Î˜(log(ğ‘›)).", "answer_embedding": null, "answer_confidence": null, "page_ids": ["1a3da172-d383-5da8-b297-3fd5ea9024dc", "2207e17c-289e-5000-ace5-623e81db7b9b", "6e773b9f-1cda-5ba9-8756-97b6e00119df", "7b7d9dc6-5cd7-52df-b66e-d4548821bf99", "8c8f8242-6e2b-563a-af29-ebd95912031a", "942883f1-20a5-56b3-a5e0-a9ffafda687c", "9b0d4dd4-86c3-518e-a300-140b5431246b", "a732e97e-0ac4-53d2-b683-2ca489c035d6", "afe605f5-a549-5395-b01b-3fe495903bb8", "eeb12615-da5e-5489-a593-75fa07932e2c", "f0f93193-dc46-5ba5-9f4d-77717945d193", "f6099dd1-8ca5-5a05-8f00-ca473fc97adc"]}, {"id": null, "qa_id": "fc535fab-da31-500e-94a6-facb047c925a", "book_id": "47bbcc23-9276-5662-9e40-96e8a4841ec7", "section_labels": ["practice", "solutions"], "section_titles": ["Exercise Solutions", "Practice Exercises"], "pdf_page": 771, "problem_key": "1", "answer_number": 1, "answer_choice": "C", "answer_text": "The number of edges can be calculated using the following equation:\nğ‘‰(ğ‘‰âˆ’1)ğ¸=\n2\n10Ã—9=\n2\n=45", "answer_embedding": null, "answer_confidence": null, "page_ids": ["1a3da172-d383-5da8-b297-3fd5ea9024dc", "2207e17c-289e-5000-ace5-623e81db7b9b", "6e773b9f-1cda-5ba9-8756-97b6e00119df", "7b7d9dc6-5cd7-52df-b66e-d4548821bf99", "8c8f8242-6e2b-563a-af29-ebd95912031a", "942883f1-20a5-56b3-a5e0-a9ffafda687c", "9b0d4dd4-86c3-518e-a300-140b5431246b", "a33ee040-cb9d-5bce-8fe4-7a2149f54fc9", "a732e97e-0ac4-53d2-b683-2ca489c035d6", "afe605f5-a549-5395-b01b-3fe495903bb8", "eeb12615-da5e-5489-a593-75fa07932e2c", "f0f93193-dc46-5ba5-9f4d-77717945d193", "f6099dd1-8ca5-5a05-8f00-ca473fc97adc"]}, {"id": null, "qa_id": "fc535fab-da31-500e-94a6-facb047c925a", "book_id": "47bbcc23-9276-5662-9e40-96e8a4841ec7", "section_labels": ["practice", "solutions"], "section_titles": ["Exercise Solutions", "Practice Exercises"], "pdf_page": 793, "problem_key": "1", "answer_number": 1, "answer_choice": "A", "answer_text": "By definition, minimum spanning trees are acyclic, so statement I is true. Statement II is false because a MST\n|ğ‘‰|âˆ’1 |ğ‘‰|has edges, not edges. Statement III is false because it is possible for the largest weighted edge in the graph to connect a vertex\nthat cannot be reached from anywhere else, which necessitates it to be in the MST (also if every edge has the same weight). One example\nthat disproves statement III is shown below (the edge from ğ·to ğ¹of weight 8 must be in the MST):\nA\nB\nE\nC\nD\nF\n3\n5\n4\n2\n8\n6\n7\nÎ˜(|ğ¸|log(|ğ‘‰|)2. The correct answer is (B). The time complexity of Primâ€™s algorithm using a min-binary heap on an adjacency list is (see\nthe section on Primâ€™s algorithm for a detailed explanation).", "answer_embedding": null, "answer_confidence": null, "page_ids": ["1a3da172-d383-5da8-b297-3fd5ea9024dc", "2207e17c-289e-5000-ace5-623e81db7b9b", "6e773b9f-1cda-5ba9-8756-97b6e00119df", "7b7d9dc6-5cd7-52df-b66e-d4548821bf99", "8c8f8242-6e2b-563a-af29-ebd95912031a", "942883f1-20a5-56b3-a5e0-a9ffafda687c", "9801d2c0-b83e-52f9-b703-56eeba030479", "9b0d4dd4-86c3-518e-a300-140b5431246b", "a33ee040-cb9d-5bce-8fe4-7a2149f54fc9", "a732e97e-0ac4-53d2-b683-2ca489c035d6", "afe605f5-a549-5395-b01b-3fe495903bb8", "eeb12615-da5e-5489-a593-75fa07932e2c", "f0f93193-dc46-5ba5-9f4d-77717945d193", "f6099dd1-8ca5-5a05-8f00-ca473fc97adc"]}, {"id": null, "qa_id": "fc535fab-da31-500e-94a6-facb047c925a", "book_id": "47bbcc23-9276-5662-9e40-96e8a4841ec7", "section_labels": ["practice", "solutions"], "section_titles": ["Exercise Solutions", "Practice Exercises"], "pdf_page": 826, "problem_key": "1", "answer_number": 1, "answer_choice": "C", "answer_text": "A brute force algorithm, when implemented correctly, would check all possible solutions before deciding on the\nsolution that solves the problem. This means that a brute force approach can ensure that the optimal solution is found, so statement I is false.\n2ğ‘›,Statement II is not guaranteed to be true either depending on the problem to be solved â€” if the number of possible solutions exceeds\nÎ˜(2ğ‘›)then the time complexity of brute force can exceed (one example is the Traveling Salesperson Problem (TSP), which has a brute\nforce time complexity of Î˜(ğ‘›!), which we will discuss in more detail in the following chapter). Statement III is true: since brute force needs\nto check the entire solution space, it is computationally intensive and may take significant time to run (and if a machine is not powerful\nenough, a brute force algorithm may end up taking an infeasible amount of time to complete).", "answer_embedding": null, "answer_confidence": null, "page_ids": ["1a3da172-d383-5da8-b297-3fd5ea9024dc", "2207e17c-289e-5000-ace5-623e81db7b9b", "6e773b9f-1cda-5ba9-8756-97b6e00119df", "7b7d9dc6-5cd7-52df-b66e-d4548821bf99", "8c8f8242-6e2b-563a-af29-ebd95912031a", "942883f1-20a5-56b3-a5e0-a9ffafda687c", "9801d2c0-b83e-52f9-b703-56eeba030479", "9b0d4dd4-86c3-518e-a300-140b5431246b", "a33ee040-cb9d-5bce-8fe4-7a2149f54fc9", "a732e97e-0ac4-53d2-b683-2ca489c035d6", "a8bd50a1-a8c7-5431-824f-b2983d36f1ed", "afe605f5-a549-5395-b01b-3fe495903bb8", "eeb12615-da5e-5489-a593-75fa07932e2c", "f0f93193-dc46-5ba5-9f4d-77717945d193", "f6099dd1-8ca5-5a05-8f00-ca473fc97adc"]}, {"id": null, "qa_id": "fc535fab-da31-500e-94a6-facb047c925a", "book_id": "47bbcc23-9276-5662-9e40-96e8a4841ec7", "section_labels": ["practice", "solutions"], "section_titles": ["Exercise Solutions", "Practice Exercises"], "pdf_page": 873, "problem_key": "1", "answer_number": 1, "answer_choice": "D", "answer_text": "For constraint satisfaction, you just want to know if a solution exists, not what the best solution is. This only\napplies to answer choice (D). In choice (A), you want to find the distance to New York City; in choice (B), you want to find theminimum\nspanning tree; and in choice (C), you want to find the path of the maze.minimum shortest", "answer_embedding": null, "answer_confidence": null, "page_ids": ["1a3da172-d383-5da8-b297-3fd5ea9024dc", "2207e17c-289e-5000-ace5-623e81db7b9b", "6e773b9f-1cda-5ba9-8756-97b6e00119df", "7b7d9dc6-5cd7-52df-b66e-d4548821bf99", "8c8f8242-6e2b-563a-af29-ebd95912031a", "942883f1-20a5-56b3-a5e0-a9ffafda687c", "9801d2c0-b83e-52f9-b703-56eeba030479", "9b0d4dd4-86c3-518e-a300-140b5431246b", "a33ee040-cb9d-5bce-8fe4-7a2149f54fc9", "a732e97e-0ac4-53d2-b683-2ca489c035d6", "a8bd50a1-a8c7-5431-824f-b2983d36f1ed", "afe605f5-a549-5395-b01b-3fe495903bb8", "e07bc6fe-0bb9-5892-9565-a839b6bcff01", "eeb12615-da5e-5489-a593-75fa07932e2c", "f0f93193-dc46-5ba5-9f4d-77717945d193", "f6099dd1-8ca5-5a05-8f00-ca473fc97adc"]}, {"id": null, "qa_id": "fc535fab-da31-500e-94a6-facb047c925a", "book_id": "47bbcc23-9276-5662-9e40-96e8a4841ec7", "section_labels": ["practice", "solutions"], "section_titles": ["Exercise Solutions", "Practice Exercises"], "pdf_page": 958, "problem_key": "1", "answer_number": 1, "answer_choice": "C", "answer_text": "The greedy approach does not guarantee an optimal solution for the 0-1 knapsack problem (see section 24.2.2\nfor an explanation why). The other three algorithm families do guarantee an optimal solution (brute force because it tries everything; branch\nand bound because it is a smarter brute force that only explores promising search paths, which include the optimal solution; dynamic\nprogramming because the knapsack problem has an optimal substructure with overlapping subproblems).", "answer_embedding": null, "answer_confidence": null, "page_ids": ["1a3da172-d383-5da8-b297-3fd5ea9024dc", "2207e17c-289e-5000-ace5-623e81db7b9b", "6e773b9f-1cda-5ba9-8756-97b6e00119df", "7b7d9dc6-5cd7-52df-b66e-d4548821bf99", "8c8f8242-6e2b-563a-af29-ebd95912031a", "942883f1-20a5-56b3-a5e0-a9ffafda687c", "9801d2c0-b83e-52f9-b703-56eeba030479", "9b0d4dd4-86c3-518e-a300-140b5431246b", "a33ee040-cb9d-5bce-8fe4-7a2149f54fc9", "a732e97e-0ac4-53d2-b683-2ca489c035d6", "a8bd50a1-a8c7-5431-824f-b2983d36f1ed", "afe605f5-a549-5395-b01b-3fe495903bb8", "e07bc6fe-0bb9-5892-9565-a839b6bcff01", "eeb12615-da5e-5489-a593-75fa07932e2c", "f0f93193-dc46-5ba5-9f4d-77717945d193", "f5d6b0c4-2db1-5173-8428-b1cf083e7cc4", "f6099dd1-8ca5-5a05-8f00-ca473fc97adc"]}, {"id": null, "qa_id": "fc535fab-da31-500e-94a6-facb047c925a", "book_id": "47bbcc23-9276-5662-9e40-96e8a4841ec7", "section_labels": ["practice", "solutions"], "section_titles": ["Exercise Solutions", "Practice Exercises"], "pdf_page": 994, "problem_key": "1", "answer_number": 1, "answer_choice": "B", "answer_text": "A single run of Dijkstraâ€™s algorithm can be used to discover the shortest distance from the source vertex to every\nother reachable vertex in a given graph. This is because Dijkstraâ€™s algorithm explores outward from the source vertex, greedily identifying\neach vertexâ€™s shortest path to the source and using that information to determine the shortest path of vertices encountered later during the\nsearch. At the end of the run, every vertex reachable from the source would have been discovered and its shortest path known.", "answer_embedding": null, "answer_confidence": null, "page_ids": ["1a3da172-d383-5da8-b297-3fd5ea9024dc", "2207e17c-289e-5000-ace5-623e81db7b9b", "6e773b9f-1cda-5ba9-8756-97b6e00119df", "7b25559a-771c-5789-849e-761231306ccf", "7b7d9dc6-5cd7-52df-b66e-d4548821bf99", "8c8f8242-6e2b-563a-af29-ebd95912031a", "942883f1-20a5-56b3-a5e0-a9ffafda687c", "9801d2c0-b83e-52f9-b703-56eeba030479", "9b0d4dd4-86c3-518e-a300-140b5431246b", "a33ee040-cb9d-5bce-8fe4-7a2149f54fc9", "a732e97e-0ac4-53d2-b683-2ca489c035d6", "a8bd50a1-a8c7-5431-824f-b2983d36f1ed", "afe605f5-a549-5395-b01b-3fe495903bb8", "e07bc6fe-0bb9-5892-9565-a839b6bcff01", "eeb12615-da5e-5489-a593-75fa07932e2c", "f0f93193-dc46-5ba5-9f4d-77717945d193", "f5d6b0c4-2db1-5173-8428-b1cf083e7cc4", "f6099dd1-8ca5-5a05-8f00-ca473fc97adc"]}, {"id": null, "qa_id": "fc535fab-da31-500e-94a6-facb047c925a", "book_id": "47bbcc23-9276-5662-9e40-96e8a4841ec7", "section_labels": ["practice", "solutions"], "section_titles": ["Exercise Solutions", "Practice Exercises"], "pdf_page": 1053, "problem_key": "1", "answer_number": 1, "answer_choice": "D", "answer_text": "Statement I is false because that quality exists for vector images and not raster images; instead, raster images\ndeal with pixels and thus may lose quality when the original size is changed. Statement II is true, since vector graphics do not deal with\npixels and instead generate an underlying image using points connected using mathematical formulas and other non-resolution dependent\ninformation. Statement III is true since the RGB color model uses a number between 0 and 255 to determine the mix of red, green, and blue\nthat is used to generate a specific color.", "answer_embedding": null, "answer_confidence": null, "page_ids": ["1a3da172-d383-5da8-b297-3fd5ea9024dc", "2207e17c-289e-5000-ace5-623e81db7b9b", "6275fd1a-cffc-5d55-9e15-840a57b06dcd", "6e773b9f-1cda-5ba9-8756-97b6e00119df", "7b25559a-771c-5789-849e-761231306ccf", "7b7d9dc6-5cd7-52df-b66e-d4548821bf99", "8c8f8242-6e2b-563a-af29-ebd95912031a", "942883f1-20a5-56b3-a5e0-a9ffafda687c", "9801d2c0-b83e-52f9-b703-56eeba030479", "9b0d4dd4-86c3-518e-a300-140b5431246b", "a33ee040-cb9d-5bce-8fe4-7a2149f54fc9", "a732e97e-0ac4-53d2-b683-2ca489c035d6", "a8bd50a1-a8c7-5431-824f-b2983d36f1ed", "afe605f5-a549-5395-b01b-3fe495903bb8", "e07bc6fe-0bb9-5892-9565-a839b6bcff01", "eeb12615-da5e-5489-a593-75fa07932e2c", "f0f93193-dc46-5ba5-9f4d-77717945d193", "f5d6b0c4-2db1-5173-8428-b1cf083e7cc4", "f6099dd1-8ca5-5a05-8f00-ca473fc97adc"]}]}
{"type": "unmatched_answer", "record": {"id": null, "qa_id": null, "book_id": "47bbcc23-9276-5662-9e40-96e8a4841ec7", "section_labels": ["solutions"], "section_titles": ["Exercise Solutions"], "pdf_page": 126, "problem_key": "8", "answer_number": 8, "answer_choice": "C", "answer_text": "The program ran better than expected, so it could not have exposed worst-case behavior if all else went to plan.", "answer_embedding": null, "answer_confidence": null, "page_ids": ["f6099dd1-8ca5-5a05-8f00-ca473fc97adc"]}}
{"type": "unmatched_answer", "record": {"id": null, "qa_id": null, "book_id": "47bbcc23-9276-5662-9e40-96e8a4841ec7", "section_labels": ["solutions"], "section_titles": ["Exercise Solutions"], "pdf_page": 126, "problem_key": "9", "answer_number": 9, "answer_choice": "A", "answer_text": "None of the statements are true. The best way to disprove these statements is to use trigonometric functions,\nwhich do not adhere to many of the rules that are associated with traditional functions. Statement I is false when and cos(ğ‘¥).ğ‘“=sin(ğ‘¥) ğ‘”=\nStatement II is false when sin(ğ‘¥), cos(ğ‘¥), and cos(ğ‘¥). Statement III is false when sin(ğ‘¥), cos(ğ‘¥), andğ‘“= ğ‘”= â„= sin(ğ‘¥) ğ‘“= ğ‘”=+\nğ‘¥2sin(ğ‘¥)cos(ğ‘¥). Statement IV is false when and 1âˆ•ğ‘¥.â„= ğ‘“= ğ‘”=\nlog(ğ‘›39ğ‘›) log(ğ‘›3)+log(9ğ‘›).10. The correct answer is (A). Using log rules, can be rewritten as We can move the exponents in front of the log\nto get 3log(ğ‘›)+ğ‘›log(9). Both 3 and are constants, so they can be ignored, leaving us with log(ğ‘›)+ğ‘›. The lower order term of log(ğ‘›)log(9)\nÎ˜(9ğ‘›). log(ğ‘›543ğ‘›)can also be dropped, so the final complexity is Î˜(ğ‘›), not (A) is false. The other options are true. For (B), can be rewritten\nlog(ğ‘›5)+log(43ğ‘›)as Î˜(ğ‘›). For (C), is (see example 4.15). For (D), the base of a log does not5log(ğ‘›)+3ğ‘›log(4) log(ğ‘›!) Î˜(ğ‘›log(ğ‘›))= =\nlog(ğ‘›2)matter when working with big-O notation, so is Î˜(log2(ğ‘›)). For (E), is using log rules, which is Î˜(log(ğ‘›)).log3(ğ‘›) 2log(ğ‘›)", "answer_embedding": null, "answer_confidence": null, "page_ids": ["f6099dd1-8ca5-5a05-8f00-ca473fc97adc"]}}
{"type": "unmatched_answer", "record": {"id": null, "qa_id": null, "book_id": "47bbcc23-9276-5662-9e40-96e8a4841ec7", "section_labels": ["solutions"], "section_titles": ["Exercise Solutions"], "pdf_page": 126, "problem_key": "11", "answer_number": 11, "answer_choice": "E", "answer_text": "Asymptotic runtime deals with how an algorithmâ€™s runtime scales with respect to input size; the rate of growth\nof an algorithm is not impacted by the input size, machine performance, or compiler flags.\nÎ˜(ğ‘›2 Î˜(ğ‘›2),foo() helper_a()12. The correct answer is (A). The overall time complexity of is where the runtime of+ğ‘›+ğ‘›log(ğ‘›))=\nhelper_b() helper_c()contributes to the highest order term. Therefore, only improving or does not change the overall time\nfoo().complexity of This eliminates options (C) and (D). For option (B), the coefficient does not matter, so the time complexity of\nÎ˜(ğ‘›2). Î˜(ğ‘›2)foo() foo()would still be Only option (A) improves the overall time complexity of the function from to Î˜(ğ‘›log(ğ‘›)).", "answer_embedding": null, "answer_confidence": null, "page_ids": ["f6099dd1-8ca5-5a05-8f00-ca473fc97adc"]}}
{"type": "unmatched_answer", "record": {"id": null, "qa_id": null, "book_id": "47bbcc23-9276-5662-9e40-96e8a4841ec7", "section_labels": ["solutions"], "section_titles": ["Exercise Solutions"], "pdf_page": 126, "problem_key": "13", "answer_number": 13, "answer_choice": "E", "answer_text": "All of statements can be true in the equal case, where ğ´(ğ‘›), and have the same order of growth. Noteğµ(ğ‘›) ğ¶(ğ‘›)\nthat big-ğ‘‚, Î˜, and can also apply to a tight bound.Î©", "answer_embedding": null, "answer_confidence": null, "page_ids": ["f6099dd1-8ca5-5a05-8f00-ca473fc97adc"]}}
{"type": "unmatched_answer", "record": {"id": null, "qa_id": null, "book_id": "47bbcc23-9276-5662-9e40-96e8a4841ec7", "section_labels": ["solutions"], "section_titles": ["Exercise Solutions"], "pdf_page": 126, "problem_key": "14", "answer_number": 14, "answer_choice": "E", "answer_text": "This is not a good experiment for determining which algorithm is the most efficient due to the presence of\nconfounding factors, especially since each algorithm is only timed once. Plus, the conditions of the experiment are not well defined enough\nto come to a reasonable conclusion (e.g., what input size are you running on, compilation flags used, etc.).", "answer_embedding": null, "answer_confidence": null, "page_ids": ["f6099dd1-8ca5-5a05-8f00-ca473fc97adc"]}}
{"type": "unmatched_answer", "record": {"id": null, "qa_id": null, "book_id": "47bbcc23-9276-5662-9e40-96e8a4841ec7", "section_labels": ["solutions"], "section_titles": ["Exercise Solutions"], "pdf_page": 126, "problem_key": "15", "answer_number": 15, "answer_choice": "A", "answer_text": "This graph represents a logarithmic relationship between input size and runtime. None of options (B) through\n(E) are correct since they all grow at least as fast as linear, which is not true for the relationship in the provided graph.", "answer_embedding": null, "answer_confidence": null, "page_ids": ["f6099dd1-8ca5-5a05-8f00-ca473fc97adc"]}}
{"type": "unmatched_answer", "record": {"id": null, "qa_id": null, "book_id": "47bbcc23-9276-5662-9e40-96e8a4841ec7", "section_labels": ["solutions"], "section_titles": ["Exercise Solutions"], "pdf_page": 161, "problem_key": "8", "answer_number": 8, "answer_choice": "D", "answer_text": "For option (A), we can use the Master Theorem for 2, 4, and to conclude that the recurrence has ağ‘= ğ‘= ğ‘=5\nÎ˜(ğ‘›5).closed form that is For option (B), we can use the Master Theorem for 1, 2, and to conclude that the recurrence has ağ‘= ğ‘= ğ‘=1\nclosed form that is Î˜(ğ‘›). For option (C), we can use the Master Theorem for 2, 4, and to conclude that the recurrence has ağ‘= ğ‘= ğ‘=1âˆ•2\nclosed form that is Î˜(\nâˆš\nÎ˜(ğ‘›2)ğ‘›log(ğ‘›)). This leaves choice (D), which we can prove is using iterative substitution:\nğ‘‡(ğ‘›) ğ‘‡(ğ‘›âˆ’1)+ğ‘›+4 [ğ‘‡(ğ‘›âˆ’2)+(ğ‘›âˆ’1)+4]+ğ‘›+4 [[ğ‘‡(ğ‘›âˆ’3)+(ğ‘›âˆ’2)+4]+(ğ‘›âˆ’1)+4]+ğ‘›+4= = =\n=â€¦\nğ‘‡(ğ‘›âˆ’ğ‘˜)+ğ‘˜ğ‘›+4ğ‘˜âˆ’=\nğ‘˜âˆ’1\nâˆ‘\nğ‘–=0\nğ‘–\nThe base case happens when 1, so we can set to solve for the overall time complexity of the recurrence:ğ‘›âˆ’ğ‘˜= ğ‘˜=ğ‘›âˆ’1\nğ‘‡(ğ‘›) ğ‘‡(1)+(ğ‘›âˆ’1)ğ‘›+4(ğ‘›âˆ’1)âˆ’=\nğ‘›âˆ’2\nâˆ‘\nğ‘–=0\nâˆ’ğ‘›+4ğ‘›âˆ’4âˆ’(ğ‘›âˆ’1)(ğ‘›âˆ’2)1+ğ‘›2ğ‘–=\n2\n1=\n32ğ‘›2+\nÎ˜(ğ‘›2)2ğ‘›âˆ’2=", "answer_embedding": null, "answer_confidence": null, "page_ids": ["afe605f5-a549-5395-b01b-3fe495903bb8"]}}
{"type": "unmatched_answer", "record": {"id": null, "qa_id": null, "book_id": "47bbcc23-9276-5662-9e40-96e8a4841ec7", "section_labels": ["solutions"], "section_titles": ["Exercise Solutions"], "pdf_page": 161, "problem_key": "9", "answer_number": 9, "answer_choice": "B", "answer_text": "We can solve this recurrence using substitution:\nğ‘‡(ğ‘›) ğ‘‡(ğ‘›âˆ’1)+2 ğ‘‡(ğ‘›âˆ’2)+2+2 ğ‘‡(ğ‘›âˆ’3)+2+2+2= = =\n=â€¦\nğ‘‡(ğ‘›âˆ’ğ‘˜)+2ğ‘˜=\nThe base case happens when 0, so we can set ğ‘›to solve the overall recurrence:ğ‘›âˆ’ğ‘˜= ğ‘˜=\nğ‘‡(ğ‘›) ğ‘‡(0)+2ğ‘›=2ğ‘›+1=", "answer_embedding": null, "answer_confidence": null, "page_ids": ["afe605f5-a549-5395-b01b-3fe495903bb8"]}}
{"type": "unmatched_answer", "record": {"id": null, "qa_id": null, "book_id": "47bbcc23-9276-5662-9e40-96e8a4841ec7", "section_labels": ["solutions"], "section_titles": ["Exercise Solutions"], "pdf_page": 161, "problem_key": "10", "answer_number": 10, "answer_choice": "E", "answer_text": "We can solve this recurrence using iterative substitution:\n32ğ‘‡(ğ‘›âˆ’2)+3+1 32[3ğ‘‡(ğ‘›âˆ’3)+1]+3+1 33ğ‘‡(ğ‘›âˆ’3)+9+3+1ğ‘‡(ğ‘›) 3ğ‘‡(ğ‘›âˆ’1)+1 3[3ğ‘‡(ğ‘›âˆ’2)+1]+1= = = = =\n=â€¦\n3ğ‘˜ğ‘‡(ğ‘›âˆ’ğ‘˜)+=\nğ‘˜âˆ’1\nâˆ‘\nğ‘–=0\n3ğ‘–\nThe base case happens when 0, so we can set ğ‘›to solve for the overall time complexity of the recurrence:ğ‘›âˆ’ğ‘˜= ğ‘˜=\n3ğ‘›ğ‘‡(0)+ğ‘‡(ğ‘›)=\nğ‘›âˆ’1\nâˆ‘\nğ‘–=0\n3ğ‘–=Î˜(3ğ‘›)\n6.9 Lvalues, Rvalues, and Move Semantics\n167\nCould we plan further in advance by tripling or quadrupling the array capacity with every new allocation? We could, but this would be wasteful\nwhen it comes to memory. Although tripling or quadrupling capacity could reduce the number of copies we have to make, there is no guarantee\nthat all this memory will be used, and the improvement in performance is asymptotically insignificant.\nArrayWe have gotten quite far with our custom-implemented class in this section, implementing a container that abstracts away the work\nof memory allocation from the user and supports several features that are not present with just a standard C-style array. However, there is still\nmore we can do. For instance, we can implement a member function that can delete elements from our container, or a member function that can\ndatamanually change the capacity of the underlying array.\nArrayHowever, we will not be implementing any more member functions in our custom class. First, several of these features can get\nquite complicated. Insertion and deletion, for instance, both require elements in the array to be shifted. More importantly, however, doing so\nwould not be necessary â€” most of the work has already been done for us, so we do not need to spend time reinventing the wheel! C++ already\nprovides us with an array-based container that manages dynamic memory and performs all of the functionalities we have implemented in this\nstd::vector<>,section (and much more!). This container is known as the which we will cover in the next chapter.\n6.9\nLvalues, Rvalues, and Move Semantics (âœ½)\nIn this section, we will be briefly discussing the concept of move semantics, which allows resources to be transferred between objects instead\nof copied. Move semantics can be used to optimize the performance of your code, as it allows you to avoid making unnecessary copies of\ntemporary objects that you know are not going to exist for much longer.\nRemark: The material in this section is beyond the scope of this class, and you will need to know it for projects or exams. That beingnot\nsaid, you are still allowed to take advantage of move semantics in your projects or lab assignments if you know how they work. If you donâ€™t\nknow how move semantics work and donâ€™t have the time or commitment to read this section, thatâ€™s perfectly fine as well! The runtime\nbenchmarks that you are required to meet for coding assignments in this class are based off of instructor solutions that do not take advantage\nof these optimizations.\nÂ¸ 6.9.1\n(âœ½)Lvalues and Rvalues\nTo begin, we must first introduce the concepts of lvalues and rvalues. Lvalues, historically known as \"left-hand\" values since they can go on the\nleft-hand side of an assignment, are named objects with an identifiable location in memory (because of this, lvalues are also known as locator\nvalues). Rvalues, historically known as \"right-hand\" values since they can only go on the right-hand side of an assignment, are temporary,\nunnamed objects that cannot be assigned to (i.e., they cannot go on the left-hand side of an assignment). For example, consider the following:\nint32_t x = 281;\nx,There are two components to this assignment. On the left-hand side, we have the integer variable which is named and has an identifiable\nx 281,address in memory. Thus, the variable is an lvalue. On the right-hand side, we have the number which is a temporary numeric value that\n281has no identifiable location in memory until it is assigned. Thus, is an rvalue.\nLvalues can be assigned from rvalues or other lvalues, but rvalues cannot be assigned to at all. For instance, the following is okay since both\nx yand are lvalues, and thus can be assigned to:\nint32_t x = 281;\nint32_t y = x;\n// OK, x and y are both lvalues\n281However, the following is not okay, since is an rvalue, and thus cannot be assigned to:\nint32_t x = 281;\n281 = x;\n// NOT OK, 281 is an rvalue\nIf you return a value from a function that returns by value (instead of by reference), then that value will be returned as an rvalue. In the following\nget_favorite_class() x:code, returns an rvalue, which is then assigned to the lvalue\n1\nint32_t get_favorite_class() {\n2\nstatic int32_t fav_class = 281;\n3\nreturn fav_class;\n4\n} // get_favorite_class()\n5\n6\nint main() {\n7\nint32_t x = get_favorite_class();\n// x is lvalue, get_favorite_class() is rvalue\n8\n} // main()\nget_favorite_class()Because is an rvalue here, the following would not work:\nget_favorite_class() = 370;\n// not OK, get_favorite_class() is an rvalue\nget_favorite_class()However, this would work if the returned by reference instead of by value. If a function returns by reference, it\nwould return an lvalue reference, which can be assigned to:\n1\nint32_t& get_favorite_class() {\n2\nstatic int32_t fav_class = 281;\n3\nreturn fav_class;\n4\n} // get_favorite_class()\n5\n6\nint32_t main() {\n7\nget_favorite_class() = 370;\n// OK, get_favorite_class() is an lvalue reference\n8\n} // get_favorite_class()\n176\nChapter 6. Fixed-Size Arrays and Array-Based Containers\nChapter 6 Exercise Solutions", "answer_embedding": null, "answer_confidence": null, "page_ids": ["afe605f5-a549-5395-b01b-3fe495903bb8"]}}
{"type": "unmatched_answer", "record": {"id": null, "qa_id": null, "book_id": "47bbcc23-9276-5662-9e40-96e8a4841ec7", "section_labels": ["solutions"], "section_titles": ["Exercise Solutions"], "pdf_page": 188, "problem_key": "8", "answer_number": 8, "answer_choice": "A", "answer_text": "Assuming no reallocation is necessary, the time complexity of inserting an element to the back of an array is\nconstant (since it can be placed at the very back of the array without having to touch any of the other elements).", "answer_embedding": null, "answer_confidence": null, "page_ids": ["2207e17c-289e-5000-ace5-623e81db7b9b"]}}
{"type": "unmatched_answer", "record": {"id": null, "qa_id": null, "book_id": "47bbcc23-9276-5662-9e40-96e8a4841ec7", "section_labels": ["solutions"], "section_titles": ["Exercise Solutions"], "pdf_page": 188, "problem_key": "9", "answer_number": 9, "answer_choice": "C", "answer_text": "Assuming no reallocation is necessary, the time complexity of inserting an element to the front of an array is\nlinear, since you would have to shift all existing elements over by one to open up a spot at the beginning for the new element.", "answer_embedding": null, "answer_confidence": null, "page_ids": ["2207e17c-289e-5000-ace5-623e81db7b9b"]}}
{"type": "unmatched_answer", "record": {"id": null, "qa_id": null, "book_id": "47bbcc23-9276-5662-9e40-96e8a4841ec7", "section_labels": ["solutions"], "section_titles": ["Exercise Solutions"], "pdf_page": 188, "problem_key": "10", "answer_number": 10, "answer_choice": "E", "answer_text": "All of the statements are true. Statement I provides the definition of sequential vs. random access. Statement II\nis true because certain containers (such as lists) do not support random access at all. Statement III is true because these two conditions\nallow arrays to identify the memory position of any of its elements using simple pointer arithmetic.", "answer_embedding": null, "answer_confidence": null, "page_ids": ["2207e17c-289e-5000-ace5-623e81db7b9b"]}}
{"type": "unmatched_answer", "record": {"id": null, "qa_id": null, "book_id": "47bbcc23-9276-5662-9e40-96e8a4841ec7", "section_labels": ["solutions"], "section_titles": ["Exercise Solutions"], "pdf_page": 188, "problem_key": "11", "answer_number": 11, "answer_choice": "A", "answer_text": "To return an element from a container that should not be modified, it is best to return a const reference. The\nconst specified indicates the return value should not be modified, and the reference avoids making a copy of elements you want to return in\nthe container.\nconst operator[] const.12. The correct answer is (C). The version of is run if the container it is called on is specified as Even if\noperator[] non-const operator[]a call to does not modify a value in the container, the version of would still be called if the\nconst.container itself is not\nconst operator[] Array const.13. The correct answer is (A). The version of is called if the it is invoked on is This happens in the\noperator<< operator[]overloaded method, which calls on the array 3 times. Since the overloaded operator is invoked 3 times on\nstd::min(a[0], a[a.length - 1]) const operator[]line 37 (since is 3), the version of is called a total of 3 3 = 9 times.Ã—", "answer_embedding": null, "answer_confidence": null, "page_ids": ["2207e17c-289e-5000-ace5-623e81db7b9b"]}}
{"type": "unmatched_answer", "record": {"id": null, "qa_id": null, "book_id": "47bbcc23-9276-5662-9e40-96e8a4841ec7", "section_labels": ["solutions"], "section_titles": ["Exercise Solutions"], "pdf_page": 188, "problem_key": "14", "answer_number": 14, "answer_choice": "B", "answer_text": "The issue here is that the parameter of the copy constructor is passed in by value instead of by reference (i.e.,\nArray Array&).instead of Passing the array by value involves making a copy, which invokes the copy constructor we are trying to\nimplement, causing an error.\n7.6 Summary of Vector Complexities\n199\nChapter 7 Exercise Solutions", "answer_embedding": null, "answer_confidence": null, "page_ids": ["2207e17c-289e-5000-ace5-623e81db7b9b"]}}
{"type": "unmatched_answer", "record": {"id": null, "qa_id": null, "book_id": "47bbcc23-9276-5662-9e40-96e8a4841ec7", "section_labels": ["solutions"], "section_titles": ["Exercise Solutions"], "pdf_page": 211, "problem_key": "9", "answer_number": 9, "answer_choice": "D", "answer_text": "On line 10, the vector only has a size of 9 (from the resize on line 8). Since vectors are zero-indexed, there is no\noperator[]value at index 9, so the use of on line 10 results in undefined behavior.\nptr10. The correct answer is (E). It is impossible to determine what line 7 prints, since is invalidated when the vectorâ€™s underlying array is\nforced to reallocate on line 6 (since a 7th element is added when the capacity is 6).", "answer_embedding": null, "answer_confidence": null, "page_ids": ["eeb12615-da5e-5489-a593-75fa07932e2c"]}}
{"type": "unmatched_answer", "record": {"id": null, "qa_id": null, "book_id": "47bbcc23-9276-5662-9e40-96e8a4841ec7", "section_labels": ["solutions"], "section_titles": ["Exercise Solutions"], "pdf_page": 211, "problem_key": "11", "answer_number": 11, "answer_choice": "D", "answer_text": "The loop on line 4 pushes back all numbers from 281 to 381 (exclusive), incrementing by 10 each time. After\nv1the loop runs to completion, the contents of are:\nv1\n281 291 301 311 321 331 341 351 361 371\nv1 v2 v1On lines 7 and 8, both and are resized to a size of 6. This removes all but the first six elements in and initializes six elements in\nv2 with a default value of zero.\nv1\n281 291 301 311 321 331\nv2\n0\n0\n0\n0\n0\n0\n8.5 Techniques for Solving Linked List Problems\n219\nhead nullptr,The value of is now so we have successfully completed our traversal of the original list. The two smaller lists are then\nbefore_head->next = after_head)combined (i.e., to obtain our solution list. An implementation of this solution is provided below:\n1\nint32_tNode* partition_list(Node* head, p) {\n2\n// this creates a dummy node at the beginning of the\n3\n// before_head and after_head sublists to make implementation easier\n4\n// (also why before_head.next and after_head.next are used for return value)\n5\nNode before_head{0}, *before_ptr = &before_head;\n6\nNode after_head{0}, *after_ptr = &after_head;\n7\nwhile nullptr)(head != {\n8\nif (head->val < p) {\n9\nbefore_ptr->next = head;\n10\nbefore_ptr = before_ptr->next;\n11\n} // if\n12\nelse {\n13\nafter_ptr->next = head;\n14\nafter_ptr = after_ptr->next;\n15\n} // else\n16\nhead = head->next;\n17\n} // while\n18\n19\n// combine the two lists at before_head and after_head\n20\nnullptr;after_ptr->next =\n21\nbefore_ptr->next = after_head.next;\n22\nreturn before_head.next;\n23\n} // partition_list()\nThe time complexity of this solution is Î˜(ğ‘›), where ğ‘›is the number of nodes in the original list. This is because our implementation iterates\nover all the nodes of this list. The auxiliary space is because we only reorganized the nodes in the original list instead of duplicating them;Î˜(1)\nthus, the additional memory allocated by this solution is a constant that does not depend on the size of the original list.\nExample 8.7 head1 head2.You are given the head of two singly-linked lists, and Write a function that returns the node at which these\nnullptr.two lists intersect. If the two lists do not intersect at all, return You may assume that there are no cycles in the list structure you\nare given. A node is defined as follows:\n1\nstruct Node {\n2\nint32_t data;\n3\nNode* next;\n4\nNode(int32_t next{nullptr}x) : data{x}, {}\n5\n};\n3:For example, given the following head pointers, you would return the node with the value\nhead1\n1\n8\n3\n7\n6\n1\n8\n2\nhead2\nFor this problem, we will go over two solutions: a relatively straightforward solution, and one that requires a bit more ingenuity. To start, letâ€™s\nconsider the case where both lists have the same number of nodes before the point of intersection, as shown:\nhead1\nhead2\nhead1 head2.To find the node of intersection here, we can simply initialize two pointers, one that points to and one that points to We then\nincrement each pointer in tandem; if the two pointers ever end up pointing to the same node, then that node must be the point of intersection.\nâ€Increment\nâIncrement\nâ‚Increment\nâƒIntersection\nThis approach does work if the two lists have a different number of nodes before the point of intersection, as with our initial example.not\nHowever, we can use this idea to come up with a solution; instead of incrementing both pointers immediately, we first allow the pointer in the\nlonger chain to catch up with the pointer in the shorter chain. Then, we begin incrementing the two pointers in tandem, similar to before.\nâ€Only increment pointer #2\nâCaught up, increment both\nâ‚Increment\nâƒIntersection\n234\nChapter 8. Linked Lists\nğ‘˜th25. You are given the head of a singly-linked list and an integer ğ‘˜. Implement a function that swaps the value of the node with the value of\nğ‘˜ththe node end, and then returns the head of this modified list. For this problem, the list is 1-indexed. For example, if you arefrom the\ngiven the following list with 2:ğ‘˜=\n183\n203\n280\n281\n370\nhead\nnullptr\nyou would swap the 2nd value in the list (203) with the 2nd to last value in the list (281), as shown:\n183\n281\n280\n203\n370\nhead\nnullptr\nThe function header is provided below:\nstruct Node {\nint32_t val;\nNode* next;\nNode(int32_t next{nullptr}val_in) : val{val_in}, {}\n};\nuint32_tNode* swap_nodes(Node* head, k);\nYou should implement your solution in worst-case time and auxiliary space, where ğ‘›is the size of the list.Î˜(ğ‘›) Î˜(1)\n26. You are given the head of a singly-linked list, which contains a series of integers that separated by zeros. The first and last value in this list\nare guaranteed to be zero. Implement a function that, for every two consecutive zeros in the list, merges all the nodes in between the zeros\ninto a single node whose value is the sum of the merged nodes. This new list is then returned. The modified list should not include any\nzeros; you may assume that the original list will not have two consecutive zeros. For example, given the following list:\n0\n5\n3\n9\n0\n4\n6\n0\nhead\nnullptr\nyou would return the following list (where the first node has a value of 5 + 3 + 9 = 17, and the second node has a value of 4 + 6 = 10):\n17\n10\nhead\nnullptr\nThe function header is provided below:\nstruct Node {\nint32_t val;\nNode* next;\nNode(int32_t next{nullptr}val_in) : val{val_in}, {}\n};\nNode* sum_nodes_between_zeros(Node* head);\nYou should implement your solution in worst-case time and auxiliary space, where ğ‘›is the size of the list. The solution listÎ˜(ğ‘›) Î˜(ğ‘›)\nshould be returned as a brand new list, so the original list passed into the input should not be modified.\nChapter 8 Exercise Solutions\nint32_t1. The correct answer is (B). An has a size of 4 bytes. For a linked list of 47 integers, you have to store the Fibonacci number\nitself (with size 4 bytes) along with 2 pointers (8 bytes each). Hence, the total storage of 47 integers in a linked list is 47 (8 + 8 + 4), orÃ—\n940 bytes. For an array, you only have to store the number and not the pointers, so an array of 47 numbers would take up 47Ã—4, or 188\nbytes. The difference is thus 940 - 177 = 752 bytes. You can also think of this in terms of the additional storage needed to store a value in a\ndoubly-linked list compared to an array: in the linked list, each value would have to use 16 additional bytes of memory to store 2 pointers,\nso the extra memory required for the linked list of 47 values is bytes.47Ã—16", "answer_embedding": null, "answer_confidence": null, "page_ids": ["eeb12615-da5e-5489-a593-75fa07932e2c"]}}
{"type": "unmatched_answer", "record": {"id": null, "qa_id": null, "book_id": "47bbcc23-9276-5662-9e40-96e8a4841ec7", "section_labels": ["solutions"], "section_titles": ["Exercise Solutions"], "pdf_page": 281, "problem_key": "8", "answer_number": 8, "answer_choice": "B", "answer_text": "When 203, 370, and 281 are pushed into the container, 281 is the first to be retrieved. When 280, 376, and 183\nare added to the container, 183 is the first to be retrieved. After 183 is popped off, 376 is the next to be retrieved. Notice that the top value\nis always the most recent element inserted into the container; thus, of the options provided, the container must be a stack. Notice that a\n.push() .pop()deque would not work here, since they do not support and methods without specifying the end you want to push or pop\nMYSTERY_CONTAINER std::deque.from, so the code would not compile if were a", "answer_embedding": null, "answer_confidence": null, "page_ids": ["9b0d4dd4-86c3-518e-a300-140b5431246b"]}}
{"type": "unmatched_answer", "record": {"id": null, "qa_id": null, "book_id": "47bbcc23-9276-5662-9e40-96e8a4841ec7", "section_labels": ["solutions"], "section_titles": ["Exercise Solutions"], "pdf_page": 281, "problem_key": "9", "answer_number": 9, "answer_choice": "A", "answer_text": "Since Darget needs to insert inventory from one end of a container and remove it from the other, it should use a\nqueue, which can be used to efficiently support FIFO behavior. On the other hand, Paolmart needs to insert and remove inventory from the\nsame end of a container (since the newest element is removed first), which can be efficiently done using a stack or a vector.", "answer_embedding": null, "answer_confidence": null, "page_ids": ["9b0d4dd4-86c3-518e-a300-140b5431246b"]}}
{"type": "unmatched_answer", "record": {"id": null, "qa_id": null, "book_id": "47bbcc23-9276-5662-9e40-96e8a4841ec7", "section_labels": ["solutions"], "section_titles": ["Exercise Solutions"], "pdf_page": 281, "problem_key": "10", "answer_number": 10, "answer_choice": "A", "answer_text": "Queues need to support efficient insertion and removal from both ends of its underlying container, since\nstd::list<>the side in which you insert an element is not the side you should pop elements out of. This can be done with a or a\nstd::deque<>, std::vector<>,whichcansupport insertionandremovalfrombothendsofthecontainer, butnotwitha whichÎ˜(1)\nonly supports insertion and removal from the back.Î˜(1)", "answer_embedding": null, "answer_confidence": null, "page_ids": ["9b0d4dd4-86c3-518e-a300-140b5431246b"]}}
{"type": "unmatched_answer", "record": {"id": null, "qa_id": null, "book_id": "47bbcc23-9276-5662-9e40-96e8a4841ec7", "section_labels": ["solutions"], "section_titles": ["Exercise Solutions"], "pdf_page": 281, "problem_key": "11", "answer_number": 11, "answer_choice": "A", "answer_text": "Only option (A) is a true statement, since it describes the functionality of a container adaptor. Option (B)\nis false because stacks and queues are not the only container adaptors on the STL (priority queues are another one). Option (C) is false\nbecause random access is not a prerequisite for an underlying container: for containers like stacks and queues where random access is not\nstd::list<>necessary and you only need efficient access at the ends of the container, you can use a as the underlying container. Option\n(D) is false, since container adaptors may restrict or modify the functionality of its underlying container to support the desired behavior.", "answer_embedding": null, "answer_confidence": null, "page_ids": ["9b0d4dd4-86c3-518e-a300-140b5431246b"]}}
{"type": "unmatched_answer", "record": {"id": null, "qa_id": null, "book_id": "47bbcc23-9276-5662-9e40-96e8a4841ec7", "section_labels": ["solutions"], "section_titles": ["Exercise Solutions"], "pdf_page": 281, "problem_key": "12", "answer_number": 12, "answer_choice": "C", "answer_text": "If you want to emulate the behavior of a queue using a deque, then you should insert and remove elements from\nopposite ends of the deque.", "answer_embedding": null, "answer_confidence": null, "page_ids": ["9b0d4dd4-86c3-518e-a300-140b5431246b"]}}
{"type": "unmatched_answer", "record": {"id": null, "qa_id": null, "book_id": "47bbcc23-9276-5662-9e40-96e8a4841ec7", "section_labels": ["solutions"], "section_titles": ["Exercise Solutions"], "pdf_page": 281, "problem_key": "13", "answer_number": 13, "answer_choice": "B", "answer_text": "Deques support insertions and removals from the ends of the container, but not the middle. Inserting anÎ˜(1)\nelement into the middle of the deque may require elements to be shifted in memory, which could take time.Î˜(ğ‘›)", "answer_embedding": null, "answer_confidence": null, "page_ids": ["9b0d4dd4-86c3-518e-a300-140b5431246b"]}}
{"type": "unmatched_answer", "record": {"id": null, "qa_id": null, "book_id": "47bbcc23-9276-5662-9e40-96e8a4841ec7", "section_labels": ["solutions"], "section_titles": ["Exercise Solutions"], "pdf_page": 281, "problem_key": "14", "answer_number": 14, "answer_choice": "B", "answer_text": "Without a tail pointer, a linked list (regardless of whether it is doubly- or singly-linked) cannot support Î˜(1)\ninsertion or removal from the back. To implement the queue, you would need a way to insert and remove elements in from both endsÎ˜(1)\nof the container, which is not supported with a linked list deque with no tail pointer.", "answer_embedding": null, "answer_confidence": null, "page_ids": ["9b0d4dd4-86c3-518e-a300-140b5431246b"]}}
{"type": "unmatched_answer", "record": {"id": null, "qa_id": null, "book_id": "47bbcc23-9276-5662-9e40-96e8a4841ec7", "section_labels": ["solutions"], "section_titles": ["Exercise Solutions"], "pdf_page": 281, "problem_key": "15", "answer_number": 15, "answer_choice": "A", "answer_text": "The order in which elements are inserted into a queue is the same order in which they are removed.\nThe correct answer is (D). Queues are often used to allocate scarce resources among different running processes by providing them in16.\nfirst in, first out order for different processes (e.g., if two processes need a shared resource, and one gets there before the other, then the\nfirst process would get the resource first). The other three applications are better suited for a stack, which supports efficient insertions and\nremovals from the same end.\nstd::stack<>17. The correct answer is (D). Since you are only allowed to use public methods provided in the interface, you would not\nbe able to access the fifth oldest element without popping out all but five of the elements in the stack. Since the order of elements in the\nstack cannot be changed either, you would need to store the values you popped as well, in an external data structure. Because of this, the\nworst-case time and auxiliary space complexities of finding the fifth oldest element in a stack are both Î˜(ğ‘›).", "answer_embedding": null, "answer_confidence": null, "page_ids": ["9b0d4dd4-86c3-518e-a300-140b5431246b"]}}
{"type": "unmatched_answer", "record": {"id": null, "qa_id": null, "book_id": "47bbcc23-9276-5662-9e40-96e8a4841ec7", "section_labels": ["solutions"], "section_titles": ["Exercise Solutions"], "pdf_page": 328, "problem_key": "10", "answer_number": 10, "answer_choice": "D", "answer_text": "Because priority queues can have more than two children, inserting an element can be done in constant time by\njust melding the lower priority root as a child of the higher priority one.", "answer_embedding": null, "answer_confidence": null, "page_ids": ["a732e97e-0ac4-53d2-b683-2ca489c035d6"]}}
{"type": "unmatched_answer", "record": {"id": null, "qa_id": null, "book_id": "47bbcc23-9276-5662-9e40-96e8a4841ec7", "section_labels": ["solutions"], "section_titles": ["Exercise Solutions"], "pdf_page": 328, "problem_key": "11", "answer_number": 11, "answer_choice": "A", "answer_text": "Option (A) is not necessarily true because a key at each node may be identical to one of its children due to the\npossibility of ties. It does not always have to be larger.", "answer_embedding": null, "answer_confidence": null, "page_ids": ["a732e97e-0ac4-53d2-b683-2ca489c035d6"]}}
{"type": "unmatched_answer", "record": {"id": null, "qa_id": null, "book_id": "47bbcc23-9276-5662-9e40-96e8a4841ec7", "section_labels": ["solutions"], "section_titles": ["Exercise Solutions"], "pdf_page": 328, "problem_key": "12", "answer_number": 12, "answer_choice": "B", "answer_text": "Option (A) is not a valid binary heap because 12 is larger than 11. Option (C) is not a valid binary heap because\nit is not complete (28 has one child but 44 has two). Option (D) is not a valid binary heap because 44â€™s parent and child both include 43.", "answer_embedding": null, "answer_confidence": null, "page_ids": ["a732e97e-0ac4-53d2-b683-2ca489c035d6"]}}
{"type": "unmatched_answer", "record": {"id": null, "qa_id": null, "book_id": "47bbcc23-9276-5662-9e40-96e8a4841ec7", "section_labels": ["solutions"], "section_titles": ["Exercise Solutions"], "pdf_page": 328, "problem_key": "13", "answer_number": 13, "answer_choice": "A", "answer_text": "A min-heap is valid if the children of each element (located at indices 2ğ‘–and using 1-indexing) are not2ğ‘–+1\nsmaller than it. Option (B) is not a valid binary min-heap because the children of 47, 9 and 12, are smaller than 47. Option (C) is not a valid\nbinary min-heap because the child of 12 (11) is smaller than 12. Option (D) is not a valid binary min-heap because a child of 59 (58) is\nsmaller than 59. Option (A) is valid: 13 and 8 are not smaller than 2, 16 and 13 are not smaller than 13, 10 and 40 are not smaller than 8,\nand 25 and 17 are not smaller than 16.", "answer_embedding": null, "answer_confidence": null, "page_ids": ["a732e97e-0ac4-53d2-b683-2ca489c035d6"]}}
{"type": "unmatched_answer", "record": {"id": null, "qa_id": null, "book_id": "47bbcc23-9276-5662-9e40-96e8a4841ec7", "section_labels": ["solutions"], "section_titles": ["Exercise Solutions"], "pdf_page": 328, "problem_key": "14", "answer_number": 14, "answer_choice": "C", "answer_text": "A max-heap is valid if the children of each element (located at indices 2ğ‘–and using 1-indexing) are not2ğ‘–+1\nlarger than it. Option (A) is not a valid binary max-heap because the children of 14 (25 and 27) are not larger than 14. Option (B) is not a\nvalid max-heap because a child of 9 (10) is larger than 9. Option (D) is not a valid binary max-heap because a child of 54 (56) is larger than\n54. Option (C) is valid: 24 and 24 are not larger than 33, 7 and 9 are not larger than 24, 24 and 18 are not larger than 24, 7 and 5 are not\nlarger than 7, and 9 and 8 are not larger than 9.", "answer_embedding": null, "answer_confidence": null, "page_ids": ["a732e97e-0ac4-53d2-b683-2ca489c035d6"]}}
{"type": "unmatched_answer", "record": {"id": null, "qa_id": null, "book_id": "47bbcc23-9276-5662-9e40-96e8a4841ec7", "section_labels": ["solutions"], "section_titles": ["Exercise Solutions"], "pdf_page": 328, "problem_key": "15", "answer_number": 15, "answer_choice": "B", "answer_text": "After an element in a max-heap is modified, it only needs to move at most levels to return to a validÎ˜(log(ğ‘›))\nlocation (since there are levels in a heap with ğ‘›elements).Î˜(log(ğ‘›))\nfix_up() fix_down().16. The correct answer is (A). You can perform a heapify in place, using the given array of elements and either or", "answer_embedding": null, "answer_confidence": null, "page_ids": ["a732e97e-0ac4-53d2-b683-2ca489c035d6"]}}
{"type": "unmatched_answer", "record": {"id": null, "qa_id": null, "book_id": "47bbcc23-9276-5662-9e40-96e8a4841ec7", "section_labels": ["solutions"], "section_titles": ["Exercise Solutions"], "pdf_page": 420, "problem_key": "10", "answer_number": 10, "answer_choice": "B", "answer_text": "Since there are two disjoint sets, only one union operation is needed to bring the total number of disjoint sets\ndown to one (by calling union on two elements in different sets). In general, if there are ğ‘›disjoint sets, at least calls to union areğ‘›âˆ’1\nneeded to merge everything into a single set.\nfind_set()11. The correct answer is (D). Using the path-compression approach, if we were to call on an element ğ‘—, we would traverse\nall elements on the way to its ultimate representative ğ‘˜and change all these elements to have a representative of ğ‘˜. Since we called\nfind_set() on element 0, we follow the chain all the way to 0â€™s ultimate representative of 8:\nâ†’8.â†’5â†’3â†’2â†’7â†’90\nHere, all of these elements would have their representatives changed to 8.\nfind_set()12. The correct answer is (D). Calling on an element would not change its representative if there are no intermediaries between\nsuch an element and its ultimate representative. This is only true for element 1, as 1â€™s representative is 6, which is its own representative.\nCalling find on element 7 would change its representative fo 8, calling find on element 4 would change its representative to 6, and calling\nfind on element 3 would change its representative to 8 (as well as others down the chain to 8).", "answer_embedding": null, "answer_confidence": null, "page_ids": ["7b7d9dc6-5cd7-52df-b66e-d4548821bf99"]}}
{"type": "unmatched_answer", "record": {"id": null, "qa_id": null, "book_id": "47bbcc23-9276-5662-9e40-96e8a4841ec7", "section_labels": ["solutions"], "section_titles": ["Exercise Solutions"], "pdf_page": 420, "problem_key": "13", "answer_number": 13, "answer_choice": "C", "answer_text": "If there are 281 elements in the container, and 203 have themselves as their ultimate representative, then there\nmust be 203 disjoint sets. If 202 of these sets have only one element, then there are 281 - 202 = 79 elements remaining to form the last\ndisjoint set. The size cannot be larger than 79, or it would be impossible for there to be 203 disjoint sets in total.\n14. Thecorrectansweris(A).Sincepathcompressionissupported,thelargestpossiblenumberofelementsthatcouldhavetheirrepresentatives\nupdated is equal to the size of the largest disjoint set, minus 1 (since the ultimate representative of the set does not get updated), which could\nfind_set()happen if you have a representative chain in the form of a stick, and you call on the ultimate representative and farthest\nelement along the stick. The largest disjoint set can have a total of 370 - 279 = 91 elements, so the most number of representatives that\ncould potentially be updated is 90.", "answer_embedding": null, "answer_confidence": null, "page_ids": ["7b7d9dc6-5cd7-52df-b66e-d4548821bf99"]}}
{"type": "unmatched_answer", "record": {"id": null, "qa_id": null, "book_id": "47bbcc23-9276-5662-9e40-96e8a4841ec7", "section_labels": ["solutions"], "section_titles": ["Exercise Solutions"], "pdf_page": 420, "problem_key": "15", "answer_number": 15, "answer_choice": "E", "answer_text": "Option (A) is false because, from the existing representatives, there were only two disjoint sets before the union:\n{A, B, C, E} and {D}. This also means (B) and (C) are false as well. Of the remaining options, (E) is correct because the disjoint set\ncontaining {A, B, C, E} would not have an ultimate representative otherwise, as none of A, B, or C have its representative equal to itself.\n14.11 Index Sorting\n441\n35. You are given two snapshots of an array during the execution of a sorting algorithm, where the first snapshot was taken before the second:\n[13, 11, 12, 14, 17, 21, 15, 18, 22, 16, 19, 20]Snapshot 1:\n[11, 12, 13, 14, 17, 21, 15, 18, 22, 16, 19, 20]Snapshot 2:\nWhich of the following sorts could have possibly been run on this array? Note: for quicksort, do not restrict yourselfSelect all that apply.\nto the implementation where the last element is always chosen as the pivot; you may consider an implementation where any value could\nhave been chosen as the pivot, and the selected pivot could have been swapped to either the front or back of the array before partitioning.\nA) Bubble sort\nB) Insertion sort\nC) Selection sort\nD) Quicksort\nE) Mergesort\nChapter 14 Exercise Solutions\nÎ˜(ğ‘›2),The correct answer is (B). The worst-case time complexity of quicksort on an array of size ğ‘›is and not Î˜(ğ‘›log(ğ‘›)). This happens1.\nif you get unlucky with your pivot choice and end up with the smallest or largest elements as your pivot at every step, which causes the\nÎ˜(ğ‘›2).quicksort recurrence to become ğ‘‡(ğ‘›âˆ’1)+ğ‘›, which evaluates toğ‘‡(ğ‘›)=", "answer_embedding": null, "answer_confidence": null, "page_ids": ["7b7d9dc6-5cd7-52df-b66e-d4548821bf99"]}}
{"type": "unmatched_answer", "record": {"id": null, "qa_id": null, "book_id": "47bbcc23-9276-5662-9e40-96e8a4841ec7", "section_labels": ["solutions"], "section_titles": ["Exercise Solutions"], "pdf_page": 453, "problem_key": "8", "answer_number": 8, "answer_choice": "C", "answer_text": "Mergesort is the only one of the provided sorts that is stable. In addition, selection sort and quicksort have a\nÎ˜(ğ‘›2),worst-case time complexity of and heapsortâ€™s time complexity relies on random access, which linked lists do not support.Î˜(ğ‘›log(ğ‘›))", "answer_embedding": null, "answer_confidence": null, "page_ids": ["5b3eb61a-78ca-5ab0-a3f1-002ac1c1cff4"]}}
{"type": "unmatched_answer", "record": {"id": null, "qa_id": null, "book_id": "47bbcc23-9276-5662-9e40-96e8a4841ec7", "section_labels": ["solutions"], "section_titles": ["Exercise Solutions"], "pdf_page": 453, "problem_key": "9", "answer_number": 9, "answer_choice": "C", "answer_text": "Statements I and II are true. Mergesort does require an auxiliary array of the same size when sorting the\noriginal array, and the fastest possible comparison sort has a worst-case time complexity no better than (see section 14.8.2 forÎ˜(ğ‘›log(ğ‘›))\nan explanation why). Statement III is false because quicksortâ€™s better time complexity does not mean that it will always sort faster, but\nÎ˜(ğ‘›2),rather that its performance degrades slower as input size grows (also, the worst-case time complexity of quicksort is still which\nmatches bubble sort).", "answer_embedding": null, "answer_confidence": null, "page_ids": ["5b3eb61a-78ca-5ab0-a3f1-002ac1c1cff4"]}}
{"type": "unmatched_answer", "record": {"id": null, "qa_id": null, "book_id": "47bbcc23-9276-5662-9e40-96e8a4841ec7", "section_labels": ["solutions"], "section_titles": ["Exercise Solutions"], "pdf_page": 453, "problem_key": "10", "answer_number": 10, "answer_choice": "A", "answer_text": "The best choice for the pivot is the median, which lets you partition the input into two evenly sized subarrays.\nIn this case, the median value is 43.\nThe correct answer is (B). The recurrence relation for mergesort is 2ğ‘‡(ğ‘›âˆ•2)+Î˜(ğ‘›), since it recursively calls itself twice with half11. ğ‘‡(ğ‘›)=\nmerge(),the input size, then calls which takes linear time. However, since your friend incorrectly implemented the algorithm so that the\nÎ˜(ğ‘›2) 2ğ‘‡(ğ‘›âˆ•2)+Î˜(ğ‘›2).merging step takes time, the recurrence relation now becomes Using the Master Theorem where 2,ğ‘‡(ğ‘›) ğ‘==\nğ‘ğ‘, Î˜(ğ‘›ğ‘) Î˜(ğ‘›2).2, and 2, we see that which implies that the time complexity of this recurrence isğ‘= ğ‘= ğ‘< =", "answer_embedding": null, "answer_confidence": null, "page_ids": ["5b3eb61a-78ca-5ab0-a3f1-002ac1c1cff4"]}}
{"type": "unmatched_answer", "record": {"id": null, "qa_id": null, "book_id": "47bbcc23-9276-5662-9e40-96e8a4841ec7", "section_labels": ["solutions"], "section_titles": ["Exercise Solutions"], "pdf_page": 453, "problem_key": "12", "answer_number": 12, "answer_choice": "E", "answer_text": "Quicksort A is the standard version of quicksort that was discussed in this chapter, with an average-case time\nÎ˜(ğ‘›2).complexity of and a worst-case time complexity of Quicksort B always chooses the worst-case pivot, so the performanceÎ˜(ğ‘›log(ğ‘›))\nÎ˜(ğ‘›2).of quicksort B will always be the worst-case of Thus, the average-case time complexity of quicksort A is better than that of quicksort\nB, but their worst-case time complexities are the same.\n15.2 Binary Search\n447\nExample 15.1 Is the underlying data vector used to implement a binary heap sorted? Is it ordered? If not, provide an example.\nThe underlying data vector used to implement a binary heap is neither sorted nor ordered. This may seem counterintuitive, since a binary heap\ncertainly seems like a container that is sorted by priority. However, if you recall the definition of a binary heap, the relationship between nodes\nof the heap only requires no parent to have a lower priority than any of its descendants. Because of this, there are multiple ways to represent the\nsame elements in the underlying container of a binary heap.\n1\n3\n6\n2\n5\n4\n1\n2\n3\n4\n5\n6\n1\n2\n4\n3\n5\n6\n1\n3\n2\n6\n5\n4\nBoth of these variations are valid structures for a min-binary heap, and we can clearly see that the data in the underlying container does not need\nto be in a specific, predefined order. Thus, the underlying vector used to implement a binary heap is not a sorted container.\nThe underlying vector in a binary heap is also not an ordered container. To illustrate why this is the case, consider the following array\nrepresentation of a max-binary heap:\n8\n4\n2\n8\n2\n4\nSuppose we insert 9 into this binary heap. 9 would get inserted to the back of the heap, and then fixed up to its correct position.\n8\n4\n2\n9\n8\n2\n4\n9\n8\n4\n9\n2\n8\n9\n4\n2\n9\n4\n8\n2\n9\n8\n4\n2\nNotice that the addition of 9 to this binary heap changed the relative ordering of 2 and 4! Prior to insertion, 2 was before 4 in the underlying\nvector; however, after 9 was added, 2 is after 4. This shows that the binary heapâ€™s underlying data vector is not an ordered container.\n15.2\nBinary Search\nAs mentioned earlier, searching in a sorted container is much more efficient if the container is able to support binary search. Binary search is a\nsearching algorithm that can be used to find a value in logarithmic time if the underlying data is sorted. During the binary search process, we\nfirst look at the middle element and compare it with the value we are trying to find. If the middle element is larger than the element we want to\nfind, then we know that the our target element must be to the left of the middle value. On the other hand, if the middle element is smaller than\nthe element we want to find, then we know that our target element must be to the right of the middle value. We are then able to repeat this\nprocess until we find (or fail to find) our target value, eliminating half the search space every time. For example, suppose we wanted to search\nfor 21 in the following sorted vector:\n2\n3\n5\n7\n13\n21\n25\n31\n42\n0\n1\n2\n3\n4\n5\n6\n7\n8\nWe will first look at the element in the middle, 13. Since 21 is greater than 13, we know that 21 (if it exists), must be to the right of 13. As a\nresult, we can eliminate all the elements to the left of 13 as possible solutions.\n2\n3\n5\n7\n13\n21\n25\n31\n42\n0\n1\n2\n3\n4\n5\n6\n7\n8\nNext, we would look at the middle value of the remaining elements, or 25 (integer division chooses the value on the left if there are two middle\nvalues). Since 21 is less than 25, it must be to the left of 25 (if it exists). Thus, we can eliminate all the elements to the right of 25.\n2\n3\n5\n7\n13\n21\n25\n31\n42\n0\n1\n2\n3\n4\n5\n6\n7\n8\nWe then look at the remaining element to the left of 25. It is equal to our target of 21, so the value has been found.\n2\n3\n5\n7\n13\n21\n25\n31\n42\n0\n1\n2\n3\n4\n5\n6\n7\n8\n456\nChapter 15. Binary Search and Additional Algorithms\nExample 15.6 You are given an array of ğ‘›non-negative integers that represent the height of vertical bars on a map. For example, the array\n[1, 4, 9, 5, 8, 10, 7, 6, 3] represents the following map:\n10\n8\n6\n4\n2\n0\n1\n2\n3\n4\n5\n6\n7\n8\n9\nEach bar is a distance of 1 away from adjacent bars. Implement a function that returns the maximum amount of water that can be held by the\nbars on the map. The most water that can be held in the example above is 30:\n10\n8\n6\n4\n2\n0\n1\n2\n3\n4\n5\n6\n7\n8\n9\nLike with the previous example, a naÃ¯ve solution would be to check every possible pair of bars to determine the maximum amount of water that\ncan be held. However, we can use the two pointer approach to reduce the complexity of this problem to linear time. To do so, we first start by\nconsidering both the leftmost and rightmost bars, as shown below. Here, the amount of water we can hold is 8.1Ã—(9âˆ’1)=\n10\n8\n6\n4\n2\n0\n1\n2\n3\n4\n5\n6\n7\n8\n9\nNext, we will move the two pointers (or indices) toward each other in order to discover potentially better solutions. Which one do we move first?\nSince we are trying to maximize the amount of water we can hold, we should move the pointer referencing the shorter bar. In fact, we should\ncontinue moving this pointer until we encounter a bar that is taller than the ones we have encountered before, as only a taller bar can potentially\nyield a better solution. In this case, we will increment the left pointer to the right by one.\n10\n8\n6\n4\n2\n0\n1\n2\n3\n4\n5\n6\n7\n8\n9\n458\nChapter 15. Binary Search and Additional Algorithms\nAn implementation of this solution is shown below. This solution uses indices, but you can also use iterators to traverse the bars instead.\n1\nint32_t max_water(const std::vector<int32_t>& bars) {\n2\nsize_t left = 0, right = bars.size() - 1;\n3\nint32_t best = 0;\n4\nwhile (left < right) {\n5\nint32_t min_height = std::min(bars[left], bars[right]);\n6\nbest = std::max(best, min_height (right - left));*\n7\nwhile (bars[left] <= min_height && left < right) {\n8\n++left;\n9\n} // while\n10\nwhile (bars[right] <= min_height && left < right) {\n11\n--right;\n12\n} // while\n13\n} // while\n14\nreturn best;\n15\n} // max_water()\nSimilar to the previous problem, we only complete a single pass of the input vector, so the time complexity of this solution is Î˜(ğ‘›). The memory\nallocated by this solution does not depend on input size, so the auxiliary space usage is Î˜(1).\n15.6\nSliding Window Technique (âœ½)\nThe sliding window technique is another technique that can be used to solve different programming problems. The sliding window technique\nconsiders individual subsets of data and expands or shrinks that subset based on the conditions of the problem, giving it the effect of \"sliding\" a\nwindow through the data. In many cases, the sliding window technique is a useful tool for solving problems where you are given an ordered and\niterable container (like a vector or a string) and asked for information on a subrange of that container (such as the longest or shortest subrange\ncondition).1that satisfies a given We will look at a few problems that can be solved using a sliding window approach below.\nExample 15.7 str,Given a string find the length of the longest substring without any repeating characters. You may assume that the\nstring you are given only contains the letters a-z, all in lowercase.\n\"eecsiseecs\", 4, (\"ecsi\")Example: Given the string return since the longest substring without any repeating letters has length 4.\nThe simplest solution would be to generate all possible substrings of the given string, and among the substrings that have no duplicate letters,\nidentify the one with the largest length. However, such an approach is clearly inefficient. Instead, since the problem deals with a contiguous\nsubrange that needs to satisfy a given condition, we will approach it using the sliding window technique.\nIt turns out that the sliding window approach can indeed be used to solve this problem efficiently. In this solution, we start at the left\nedge of the string, increasing the size of our window one character at a time. Along the way, we keep track of which letters appear in our\nwindow, allowing us to immediately detect the presence of a duplicate letter. We also keep track of the length of the longest viable string we\nhave encountered so far. If the right boundary of our window ever encounters a duplicate letter, we must increment the left boundary until the\nduplicate is gone. This process is illustrated in the example below.\ne\ne\nc\ns\ni\ns\ne\ne\nc\ns\nBest window size encountered: 0\nLetters currently in window:\neFirst, we add to our sliding window. The best window size encountered becomes 1.\ne\ne\nc\ns\ni\ns\ne\ne\nc\ns\n1Best window size encountered:\neLetters currently in window:\nslide\ne e eNext, we add the second to our sliding window. However, already exists in our window, so the addition of this new would make our\newindow contain a duplicate letter. To fix this, we would continuously increment the left boundary of our window until there is only one\nremaining. In this case, the left boundary only needs to move forward by one position. Our new window is shown below:\ne\ne\nc\ns\ni\ns\ne\ne\nc\ns\nBest window size encountered: 1\nLetters currently in window: e\nslide\nc.We then slide the right boundary of the window forward, adding in This is still a valid window without any duplicate letters, so we update the\ncbest window size encountered to 2 and add to the collection of letters currently in our window.\ne\ne\nc\ns\ni\ns\ne\ne\nc\ns\n2Best window size encountered:\ne, cLetters currently in window:\nslide\n1Thisisjustaruleofthumb,andthereisnoguaranteethataslidingwindowcanbeusedtosolveallproblemsthatfollowthisstructure. Forcertainproblems,a\nmoreadvancedalgorithmictechniquemaybenecessary,suchasdynamicprogrammingordivide-and-conquer(bothofwhichwillbecoveredlater). However,\nthisisstillagoodpatterntohaveinyouralgorithmtoolbox,asitcanhelpyoucomeupwithsolutionstoproblemsthatcanbesolvedusingthistechnique.\n15.8 Median Finding Algorithms\n479\n15. You are given a vector of integers and a target value ğ‘˜. Implement a function that returns the pair of elements whose sum is closest to ğ‘˜.\nThe smaller element should go first in the pair that is returned.\n[29, 30, 40, 10, 28, 22] [22, 30].Example: Given the input vector and a target of 54, you would return the pairğ‘˜=\nstd::pair<int32_t, int32_t> closest_sum_to_k(const std::vector<int32_t>& int32_tvec, k);\nYour solution should be implemented in time and with auxiliary space, where ğ‘›is the length of the vector.ğ‘‚(ğ‘›log(ğ‘›)) ğ‘‚(log(ğ‘›))\nvec target.16. You are given an array of positive integers and a positive integer Implement a function that returns the length of the smallest\ntarget. std::numeric_limits<int32_t>::max()subarraywhosesumisgreaterthanorequalto Ifthereisnosuchsubarray,return\n(INT_MAX). [2, 3, 4] [1, 2, 3, 4, 5]).A subarray is a contiguous section of an array (e.g., is a subarray of\n[4, 2, 9, 1, 2, 8, 5, 3] target 12, 2,Example: Given the input vector and a value of you would return since the smallest\n[8, 5],subarray that sums to a value of at least 12, has a length of 2.\nint32_t min_subarray_length(const std::vector<int32_t>& int32_tvec, target);\nYour solution should be implemented in time and with auxiliary space, where ğ‘›is the length of the vector.ğ‘‚(ğ‘›) ğ‘‚(1)\nChapter 15 Exercise Solutions", "answer_embedding": null, "answer_confidence": null, "page_ids": ["5b3eb61a-78ca-5ab0-a3f1-002ac1c1cff4"]}}
{"type": "unmatched_answer", "record": {"id": null, "qa_id": null, "book_id": "47bbcc23-9276-5662-9e40-96e8a4841ec7", "section_labels": ["solutions"], "section_titles": ["Exercise Solutions"], "pdf_page": 587, "problem_key": "9", "answer_number": 9, "answer_choice": "C", "answer_text": "The type of an element in an unordered map is a key-value pair.\nposts[\"memes\"] \"memes\",10. The correct answer is (D). The expression is a reference for the value associated with the key or the\nposts[\"memes\"]vector of post IDs associated with this key. As a result, you can treat as the type of the value (a vector) and simply\npush back the new ID.", "answer_embedding": null, "answer_confidence": null, "page_ids": ["1a3da172-d383-5da8-b297-3fd5ea9024dc"]}}
{"type": "unmatched_answer", "record": {"id": null, "qa_id": null, "book_id": "47bbcc23-9276-5662-9e40-96e8a4841ec7", "section_labels": ["solutions"], "section_titles": ["Exercise Solutions"], "pdf_page": 587, "problem_key": "11", "answer_number": 11, "answer_choice": "E", "answer_text": "An unordered map is, by definition, unordered. Thus, you cannot determine which key was encountered first\nwhile iterating over the map.\nfoods[\"cabbage\"] std::pair<std::string,12. The correct answer is (C). is the value type of the unordered map, which is a\nint32_t>. 1 \"cabbage\"), .secondThus, to get the integer value of this pair (which is for the key you would need to reference the\nmember of the pair.\n18.11 Tries\n677\n82. You are given a sorted array. Implement a function that builds a balanced binary search tree from the contents of this array and returns the\nroot node of the newly built tree.\narray_to_bst(const std::vector<int32_t>&Node* nums);\nYour solution should run in time and use auxiliary space, where ğ‘›is the size of the input array.ğ‘‚(ğ‘›) ğ‘‚(ğ‘›)\nStockPriceTrackerImplement the following class, which can be used to return the price of a known stock at any point in time. This83.\nclass supports two operations that you will need to implement:\nvoid update(const double int32_tstd::string& symbol, price, timestamp);â€¢\nsymbol price timestamp.â€“ This indicates that the price of the stock with symbol changed to a value of at timestamp\ndouble get_price(const int32_tstd::string& symbol, timestamp);â€¢\nsymbol timestamp. symbolâ€“ This returns the price of the stock with symbol at timestamp You may assume that the exists\ntimestamp.and has been updated before at a timestamp less than or equal to\nHere are some example operations that demonstrate this behavior:\n1\nStockPriceTracker spt;\n2\nspt.update(\"NVDA\", 739.00, 1);\n3\nspt.update(\"MSFT\", 409.49, 3);\n4\nspt.update(\"TSLA\", 188.71, 4);\n5\nspt.update(\"NVDA\", 739.07, 3);\n6\nspt.update(\"TSLA\", 188.65, 6);\n7\n8\n// The following prints out the prices of the three stocks at timestamp 5\n9\nstd::cout << spt.get_price(\"NVDA\", 5) << std::endl; // prints 739.07\n10\nstd::cout << spt.get_price(\"MSFT\", 5) << std::endl; // prints 409.49\n11\nstd::cout << spt.get_price(\"TSLA\", 5) << std::endl; // prints 188.71\nAn outline of this class is provided below:\n1\nclass StockPriceTracker {\n2\nprivate:\n3\n// TODO: Add any data structures here!\n4\npublic:\n5\nvoid update(const double int32_tstd::string& symbol, price, timestamp) {\n6\n// TODO: Implement this\n7\n} // update()\n8\n9\ndouble get_price(const int32_tstd::string& symbol, timestamp) {\n10\n// TODO: Implement this\n11\n} // get_price()\n12\n};\nChapter 18 Exercise Solutions", "answer_embedding": null, "answer_confidence": null, "page_ids": ["1a3da172-d383-5da8-b297-3fd5ea9024dc"]}}
{"type": "unmatched_answer", "record": {"id": null, "qa_id": null, "book_id": "47bbcc23-9276-5662-9e40-96e8a4841ec7", "section_labels": ["solutions"], "section_titles": ["Exercise Solutions"], "pdf_page": 771, "problem_key": "8", "answer_number": 8, "answer_choice": "E", "answer_text": "Since a depth-first search looks down each path individually (and does not look at every element in a level\nbefore moving down), you cannot conclude anything about where the element ğ‘˜may be.", "answer_embedding": null, "answer_confidence": null, "page_ids": ["a33ee040-cb9d-5bce-8fe4-7a2149f54fc9"]}}
{"type": "unmatched_answer", "record": {"id": null, "qa_id": null, "book_id": "47bbcc23-9276-5662-9e40-96e8a4841ec7", "section_labels": ["solutions"], "section_titles": ["Exercise Solutions"], "pdf_page": 771, "problem_key": "9", "answer_number": 9, "answer_choice": "A", "answer_text": "Since a breadth-first search explores every element at a level before moving down to the next level, and the\nsearch terminates immediately when the target element is discovered (without pushing it into the deque), if you reached a depth of 121, you\nknow that ğ‘˜must not have been found at a depth of 120: otherwise, the search would have terminated before reaching depth 121.", "answer_embedding": null, "answer_confidence": null, "page_ids": ["a33ee040-cb9d-5bce-8fe4-7a2149f54fc9"]}}
{"type": "unmatched_answer", "record": {"id": null, "qa_id": null, "book_id": "47bbcc23-9276-5662-9e40-96e8a4841ec7", "section_labels": ["solutions"], "section_titles": ["Exercise Solutions"], "pdf_page": 771, "problem_key": "10", "answer_number": 10, "answer_choice": "C", "answer_text": "The adjacency list tells us that (1) Chicago has a direct connection with Los Angeles, Ann Arbor, and New\nYork, and (2) Ann Arbor has a direct connection with New York and Seattle. Because Chicago has a direct connection to Ann Arbor, but\nAnn Arbor does not have a connection back to Chicago, we know that this graph is directed and that choice (A) is true. The only false\nstatement is choice (C): since New York does not have an adjacency list entry, there are no connections from New York to anywhere in this\ngraph, even though there are direct connections from Chicago and Ann Arbor to New York.", "answer_embedding": null, "answer_confidence": null, "page_ids": ["a33ee040-cb9d-5bce-8fe4-7a2149f54fc9"]}}
{"type": "unmatched_answer", "record": {"id": null, "qa_id": null, "book_id": "47bbcc23-9276-5662-9e40-96e8a4841ec7", "section_labels": ["solutions"], "section_titles": ["Exercise Solutions"], "pdf_page": 771, "problem_key": "11", "answer_number": 11, "answer_choice": "C", "answer_text": "Because the graph is simple and undirected, you know that the weight from A to B is equal to the weight from\nB to A. ğ‘¥is equal to the weight from A to F, which is the same as the weight from F to A (252). ğ‘¦is equal to the weight from D to B, which\nis equal to the weight from ğµto ğ·(611). Thus, 863.ğ‘¥+ğ‘¦=252+611=", "answer_embedding": null, "answer_confidence": null, "page_ids": ["a33ee040-cb9d-5bce-8fe4-7a2149f54fc9"]}}
{"type": "unmatched_answer", "record": {"id": null, "qa_id": null, "book_id": "47bbcc23-9276-5662-9e40-96e8a4841ec7", "section_labels": ["solutions"], "section_titles": ["Exercise Solutions"], "pdf_page": 771, "problem_key": "12", "answer_number": 12, "answer_choice": "D", "answer_text": "The average length of a linked list in an adjacency list is ğ¸âˆ•ğ‘‰, where ğ‘‰is the number of airports and ğ¸is the\ntotal number of connections that exist among these airports. In the average case, the total time complexity is the time required to access the\nvertex list (a operation) and all the elements in the list (a operation), which comes out to Î˜(1+ğ¸âˆ•ğ‘‰).Î˜(ğ¸âˆ•ğ‘‰)Î˜(1)", "answer_embedding": null, "answer_confidence": null, "page_ids": ["a33ee040-cb9d-5bce-8fe4-7a2149f54fc9"]}}
{"type": "unmatched_answer", "record": {"id": null, "qa_id": null, "book_id": "47bbcc23-9276-5662-9e40-96e8a4841ec7", "section_labels": ["solutions"], "section_titles": ["Exercise Solutions"], "pdf_page": 771, "problem_key": "13", "answer_number": 13, "answer_choice": "A", "answer_text": "To see if any flight departs from an airport, simply check if there is an element in the list corresponding to that\nairport. This only takes time.Î˜(1)", "answer_embedding": null, "answer_confidence": null, "page_ids": ["a33ee040-cb9d-5bce-8fe4-7a2149f54fc9"]}}
{"type": "unmatched_answer", "record": {"id": null, "qa_id": null, "book_id": "47bbcc23-9276-5662-9e40-96e8a4841ec7", "section_labels": ["solutions"], "section_titles": ["Exercise Solutions"], "pdf_page": 771, "problem_key": "14", "answer_number": 14, "answer_choice": "A", "answer_text": "The number of students that any one student has shared a class with at the university is a relatively small\nconstant in comparison with the total number of students at the university (e.g., itâ€™s infeasible for a single student to have shared a class with\nevery student at the university), so the graph is sparse, and an adjacency list should be used.", "answer_embedding": null, "answer_confidence": null, "page_ids": ["a33ee040-cb9d-5bce-8fe4-7a2149f54fc9"]}}
{"type": "unmatched_answer", "record": {"id": null, "qa_id": null, "book_id": "47bbcc23-9276-5662-9e40-96e8a4841ec7", "section_labels": ["solutions"], "section_titles": ["Exercise Solutions"], "pdf_page": 771, "problem_key": "15", "answer_number": 15, "answer_choice": "D", "answer_text": "Since every server has a direct connection with every other server in the network, the graph is complete and\ntherefore dense, and an adjacency matrix should be used.", "answer_embedding": null, "answer_confidence": null, "page_ids": ["a33ee040-cb9d-5bce-8fe4-7a2149f54fc9"]}}
{"type": "unmatched_answer", "record": {"id": null, "qa_id": null, "book_id": "47bbcc23-9276-5662-9e40-96e8a4841ec7", "section_labels": ["solutions"], "section_titles": ["Exercise Solutions"], "pdf_page": 826, "problem_key": "8", "answer_number": 8, "answer_choice": "A", "answer_text": "A brute force solution examines all possible solutions, so if returns 281 as the solution, then 281 must be the\noptimal solution (otherwise it would have discovered a solution better than 281).", "answer_embedding": null, "answer_confidence": null, "page_ids": ["a8bd50a1-a8c7-5431-824f-b2983d36f1ed"]}}
{"type": "unmatched_answer", "record": {"id": null, "qa_id": null, "book_id": "47bbcc23-9276-5662-9e40-96e8a4841ec7", "section_labels": ["solutions"], "section_titles": ["Exercise Solutions"], "pdf_page": 826, "problem_key": "9", "answer_number": 9, "answer_choice": "A", "answer_text": "The brute force approach examines all possible solutions, so it is guaranteed to return the best solution if\nimplemented correctly. Thus, it is not possible for a greedy approach to do better, so choice (A) is not possible.", "answer_embedding": null, "answer_confidence": null, "page_ids": ["a8bd50a1-a8c7-5431-824f-b2983d36f1ed"]}}
{"type": "unmatched_answer", "record": {"id": null, "qa_id": null, "book_id": "47bbcc23-9276-5662-9e40-96e8a4841ec7", "section_labels": ["solutions"], "section_titles": ["Exercise Solutions"], "pdf_page": 826, "problem_key": "10", "answer_number": 10, "answer_choice": "C", "answer_text": "Divide-and-conquer works best when a problem can be split into subproblems that are independent from each\nother, which allows the input to be broken up, solved individually, and combined together without having to worry about dependencies\nbetween subproblems. If there is a dependency between different subproblems, then another algorithmic approach my work better (e.g.,\ndynamic programming, which will be discussed in a later chapter).", "answer_embedding": null, "answer_confidence": null, "page_ids": ["a8bd50a1-a8c7-5431-824f-b2983d36f1ed"]}}
{"type": "unmatched_answer", "record": {"id": null, "qa_id": null, "book_id": "47bbcc23-9276-5662-9e40-96e8a4841ec7", "section_labels": ["solutions"], "section_titles": ["Exercise Solutions"], "pdf_page": 826, "problem_key": "11", "answer_number": 11, "answer_choice": "E", "answer_text": "All of the above can be solved using divide-and-conquer. Option (A) was demonstrated in section 21.4.4, option\n(B) can be solved using a divide-and-conquer sorting algorithm like mergesort or quicksort, option (C) was demonstrated in section 21.4.2,\nand option (D) was briefly mentioned at the end of the chapter (and will be covered in section 26.3).", "answer_embedding": null, "answer_confidence": null, "page_ids": ["a8bd50a1-a8c7-5431-824f-b2983d36f1ed"]}}
{"type": "unmatched_answer", "record": {"id": null, "qa_id": null, "book_id": "47bbcc23-9276-5662-9e40-96e8a4841ec7", "section_labels": ["solutions"], "section_titles": ["Exercise Solutions"], "pdf_page": 826, "problem_key": "12", "answer_number": 12, "answer_choice": "C", "answer_text": "Mergesort and quicksort are two divide-and-conquer sorting algorithms, since they break up the input into\nsmaller subproblems, solve those subproblems independently, and then combine the subproblems to obtain the final solution (i.e., a fully\nsorted array).\n21.4 Divide-and-Conquer\n815\n13. The greedy solution to this problem is to sort all the tasks in order from least to most time required, and then greedily select the tasks that\nrequire the least amount of time. The proof for this is pretty intuitive â€” if somehow the optimal solution does not include the task that\ntakes the least amount of time, we can obtain a solution that is no worse by swapping out a longer task with the one that takes the least\namount of time (a contradiction). One possible solution is implemented below:\n1\nint32_t max_tasks(const std::vector<int32_t>& int32_tduration, total_time) {\n2\nint32_t num_tasks = 0;\n3\nstd::vector<int32_t> sorted_durations(duration);\n4\nstd::sort(sorted_durations.begin(), sorted_durations.end());\n5\nfor (int32_t curr_duration : sorted_durations) {\n6\nif (curr_duration > total_time) {\n7\nbreak;\n8\n} // if\n9\ntotal_time -= curr_duration;\n10\n++num_tasks;\n11\n} // for i\n12\nreturn num_tasks;\n13\n} // max_tasks()\nThe greedy solution to this problem is to sort all the lectures in order of starting time, and then iterate over the lectures and assign them to14.\nan available classroom (or allocate a new one if all the existing classrooms are full). This is guaranteed to identify the maximum number of\nlectures in conflict at any given time, since a room will only be assigned under this approach if ğ‘‘other classrooms are occupied. Noteğ‘‘+1\nthat if the maximum number of lectures that conflict with each other at any given time is ğ‘‘, then all possible solutions to the problem must\nrequire at least ğ‘‘classrooms (since anything less than ğ‘‘would cause two lectures to overlap), which makes ğ‘‘the optimal solution. One\npossible implementation is shown below: here, we use a priority queue to keep track of the end times of all the lectures at any point in time.\nWhenever we want to add a new lecture, we remove any lectures that may have completed and add the new lecture in, keeping track of the\nlargest size the priority queue was able to reach.\n1\nstruct LectureCompare {\n2\nbool operator() (const constLecture& lhs, Lecture& rhs) {\n3\nreturn lhs.begin_time < rhs.begin_time;\n4\n} // operator()()\n5\n};\n6\n7\nint32_t min_classrooms_needed(const std::vector<Lecture>& lectures) {\n8\nstd::vector<Lecture> sorted_lectures(lectures);\n9\nLectureCompare comp;\n10\nstd::sort(sorted_lectures.begin(), sorted_lectures.end(), comp);\n11\n12\nint32_t min_classrooms = 0;\n13\nstd::priority_queue<int32_t, std::vector<int32_t>, std::greater<int32_t>> pq;\n14\nfor (const Lecture& lecture : sorted_lectures) {\n15\nwhile (!pq.empty() && pq.top() <= lecture.begin_time) {\n16\npq.pop();\n17\n} // while\n18\npq.push(lecture.end_time);\n19\nstatic_cast<int32_t>(pq.size()));min_classrooms = std::max(min_classrooms,\n20\n} // for\n21\n22\nreturn min_classrooms;\n23\n} // min_classrooms_needed()\nChapter 22\nBacktracking and Branch and Bound\n22.1\nBacktracking\nÂ¸ 22.1.1\nIntroduction to Backtracking\nBacktracking is an algorithm family that can be used to solve problems. Unlike optimization problems, which wereconstraint satisfaction\nintroduced in the previous chapter, constraint satisfaction problems are only concerned with whether there a solution that satisfies allexists\nconstraints, and not what the best solution is. The backtracking approach can often be applied to solve problems that ask you to either find a\nsingle solution or enumerate over all solutions that satisfy a given set of constraints.\nSimilar to the brute force approach, backtracking algorithms are designed to explore all possible solutions to determine if any of them\nsatisfy a given set of constraints. However, unlike brute force, backtracking stops checking a partial solution constraint.as soon as it violates any\nThis process of removing partial solutions that cannot lead to a valid solution is known as pruning.\nTo demonstrate how backtracking works, letâ€™s start with a simple example with no constraints. Suppose you have three marbles that you\nhave to place in a straight line: a red marble (ğ‘…), and blue marble (ğµ), and a yellow marble (ğ‘Œ). Your goal is to write a function that prints out\nall the different ways these marbles can be placed, assuming they can be placed in any order.\nThe simplest way to solve this problem is to consider all possible choices that can be made at each step. For the first marble, we can either\nchoose ğ‘…, ğµ, or ğ‘Œ. If we choose ğ‘…as our first marble, we can choose ğµor ğ‘Œas our second marble. If we choose ğµas our first marble, we can\nchoose ğ‘…or ğ‘Œas our second marble. If we choose ğ‘Œas our first marble, we can choose ğ‘…or ğµas our second marble (and so on). Since we are\nmaking a series of decisions that bring us toward a solution, we can represent the solution set to the problem in the form of a tree, where each\nbranch represents a choice that was made to reach a solution (this type of tree is known as a tree).state-space\n818\nChapter 22. Backtracking and Branch and Bound\nThe state-space tree for the marble problem is shown below:\nğ‘…\nğµ\nğ‘Œ\nğ‘…\nğµ\nğ‘…\nğ‘Œ\nğµ\nğ‘…\nğµ\nğ‘Œ\nğ‘Œ\nğ‘…\nğ‘Œ\nğµ\nğ‘…\nğµ\nğ‘Œ\nğ‘…\nğ‘Œ\nğµ\nğµ\nğ‘…\nğ‘Œ\nğµ\nğ‘Œ\nğ‘…\nğ‘Œ\nğ‘…\nğµ\nğ‘Œ\nğµ\nğ‘…\nSince we have no constraints on how the marbles can be placed, we can obtain all orderings of these three marbles by performing a depth-first\nsearch on this tree. Every time we hit a leaf node, we know that we have reached a valid outcome of our problem.\nRemark: Note that the state-space tree is not actually a physical tree that is stored in memory, but rather an abstract representation of the\nsolution space of our problem. The backtracking algorithm does not necessarily involve physical tree objects; rather, the state-space tree is\nonly used to demonstrate that the behavior of backtracking is similar to a depth-first search over a solution space, as if the solution space were\nrepresented as a tree where nodes represent partial input states and branches represent choices.\nNow, letâ€™s add a constraint to this problem. Consider the same scenario as before, but this time, suppose the red marble must be in thealways\nmiddle position. Notice how our tree changes when this constraint is added â€” certain branches no longer lead us to a valid solution! As a result,\nthere is no need to explore these branches during our depth-first search. This is the core difference between backtracking and brute force â€”\nbrute force would check every branch, even ones that do not work, while backtracking would stop checking a branch as soon as it realizes the\nbranch cannot lead to a viable solution.\nğ‘…\nğµ\nğ‘Œ\nğ‘…\nğµ\nğ‘…\nğ‘Œ\nğµ\nğ‘…\nğµ\nğ‘Œ\nğ‘Œ\nğ‘…\nğ‘Œ\nğµ\nğ‘…\nğµ\nğ‘Œ\nğ‘…\nğ‘Œ\nğµ\nğµ\nğ‘…\nğ‘Œ\nğµ\nğ‘Œ\nğ‘…\nğ‘Œ\nğ‘…\nğµ\nğ‘Œ\nğµ\nğ‘…\nThis idea forms the foundation of the backtracking approach, which performs a depth-first search on the solution space and branches thatprunes\ncannot lead to a valid solution. Backtracking algorithms essentially boil down to the following four steps:\n1. Make a choice that leads you toward a solution (which moves you down a level of the state-space tree).\n2. Check if the choice is promising (that is, if it can lead you to a valid solution that satisfies the constraints). If it is, fix the choice you just\nmade and recurse on the subproblem that remains â€” this allows you to explore further down the branch until you either obtain a valid\nsolution or discover that the path no longer satisfies the given constraints.\n3. Check if the current partial solution is a valid complete solution to the problem. If it is, you have a solution. If the problem only asks for\none solution, you are done. If you are asked for all solutions, keep track of the solution you obtained.\n4. Undo the choice you most recently made (i.e., backtrack) so that you can explore other branches.\nTo demonstrate this process, consider these steps when applied to the marble problem, under the constraint that the red marble must be in the\nmiddle. First, our algorithm will make a choice. It doesnâ€™t matter what choice we make as long as it brings us closer to a solution, so for the\nsake of simplicity, we will always choose a marble for the leftmost position available.\nğ‘…\nğµ\nğ‘Œ\nğ‘…\nğµ\nğ‘…\nğ‘Œ\nğµ\nğ‘…\nğµ\nğ‘Œ\nğ‘Œ\nğ‘…\nğ‘Œ\nğµ\nğ‘…\nğµ\nğ‘Œ\nğ‘…\nğ‘Œ\nğµ\nğµ\nğ‘…\nğ‘Œ\nğµ\nğ‘Œ\nğ‘…\nğ‘Œ\nğ‘…\nğµ\nğ‘Œ\nğµ\nğ‘…\nThere are three choices we can make here: we can either place the red marble, the blue marble, or the yellow marble in the first position. Each\nof these choices represents a branch of our state-space tree. For our example, we will choose the red marble first (you can choose any marble\nhere since all the branches will need to be explored eventually, but for consistency, we will go with the order ğ‘…, then ğµ, then ğ‘Œ):\nğ‘…\nğµ\nğ‘Œ\nğ‘…\nğµ\nğ‘…\nğ‘Œ\nğµ\nğ‘…\nğµ\nğ‘Œ\nğ‘Œ\nğ‘…\nğ‘Œ\nğµ\nğ‘…\nğµ\nğ‘Œ\nğ‘…\nğ‘Œ\nğµ\nğµ\nğ‘…\nğ‘Œ\nğµ\nğ‘Œ\nğ‘…\nğ‘Œ\nğ‘…\nğµ\nğ‘Œ\nğµ\nğ‘…\n22.1 Backtracking\n819\nAfter making a choice, we then check if the choice is promising. In this case, the choice is promising, as it violates the constraint that the rednot\nmarble must be in the middle. Thus, we can all the solutions down this path, since we know that none of them will yield a valid solution.prune\nğ‘…\nâœ•\nğµ\nğ‘Œ\nğ‘…\nğµ\nğ‘…\nğ‘Œ\nğµ\nğ‘…\nğµ\nğ‘Œ\nğ‘Œ\nğ‘…\nğ‘Œ\nğµ\nğ‘…\nğµ\nğ‘Œ\nğ‘…\nğ‘Œ\nğµ\nğµ\nğ‘…\nğ‘Œ\nğµ\nğ‘Œ\nğ‘…\nğ‘Œ\nğ‘…\nğµ\nğ‘Œ\nğµ\nğ‘…\nNow, we backtrack by undoing the choice we just made. This allows us to explore another branch by making a different choice.\nğ‘…\nâœ•\nğµ\nğ‘Œ\nğ‘…\nğµ\nğ‘…\nğ‘Œ\nğµ\nğ‘…\nğµ\nğ‘Œ\nğ‘Œ\nğ‘…\nğ‘Œ\nğµ\nğ‘…\nğµ\nğ‘Œ\nğ‘…\nğ‘Œ\nğµ\nğµ\nğ‘…\nğ‘Œ\nğµ\nğ‘Œ\nğ‘…\nğ‘Œ\nğ‘…\nğµ\nğ‘Œ\nğµ\nğ‘…\nWe then repeat this process until we have considered all viable branches of the tree. Since we have already considered the choice of the red\nmarble, we will now choose the blue marble for the leftmost position.\nğ‘…\nâœ•\nğµ\nğ‘Œ\nğ‘…\nğµ\nğ‘…\nğ‘Œ\nğµ\nğ‘…\nğµ\nğ‘Œ\nğ‘Œ\nğ‘…\nğ‘Œ\nğµ\nğ‘…\nğµ\nğ‘Œ\nğ‘…\nğ‘Œ\nğµ\nğµ\nğ‘…\nğ‘Œ\nğµ\nğ‘Œ\nğ‘…\nğ‘Œ\nğ‘…\nğµ\nğ‘Œ\nğµ\nğ‘…\nAgain, we will check if the choice is promising. Here, the choice is indeed promising, as it does not violate any constraints. Thus, we will\nrecurse down this branch by fixing the blue marble in place and making a choice for the marble in the middle. There are two choices we can\nmake: the red marble and the yellow marble. Here, we will first consider the red marble.\nğµ\nğ‘…\nğ‘…\nâœ•\nğµ\nğ‘Œ\nğ‘…\nğµ\nğ‘…\nğ‘Œ\nğµ\nğ‘Œ\nğ‘Œ\nğ‘…\nğ‘Œ\nğµ\nğ‘…\nğµ\nğ‘Œ\nğ‘…\nğ‘Œ\nğµ\nğµ\nğ‘…\nğ‘Œ\nğµ\nğ‘Œ\nğ‘…\nğ‘Œ\nğ‘…\nğµ\nğ‘Œ\nğµ\nğ‘…\nThis choice is promising, so we recurse down the branch by making a choice for the final marble. Only the yellow marble is left, so we will\nchoose the yellow marble for this position.\nğµ\nğ‘…\nğ‘…\nâœ•\nğµ\nğµ\nğ‘…\nğ‘Œ\nğ‘Œ\nğ‘…\nğµ\nğ‘…\nğ‘Œ\nğµ\nğ‘Œ\nğ‘Œ\nğ‘…\nğ‘Œ\nğµ\nğ‘…\nğµ\nğ‘Œ\nğ‘…\nğ‘Œ\nğµ\nğµ\nğ‘Œ\nğ‘…\nğ‘Œ\nğ‘…\nğµ\nğ‘Œ\nğµ\nğ‘…\nWe have made a choice for all the positions and thus have a full solution. This solution does not violate any constraints, so it is a valid solution\nfor our problem. If our goal was to simply discover if a solution exists, then we would be done! However, since we want to enumerate over all\nsolutions, we will continue searching. To do so, we keep track of this solution (usually in a container of solutions) and then undo the choice of\nthe final marble so that we can explore other branches.\nğµ\nğ‘…\nğ‘…\nâœ•\nğµ\nğµ\nğ‘…\nğ‘Œ\nğ‘Œ\nğ‘…\nğµ\nğ‘…\nğ‘Œ\nğµ\nğ‘Œ\nğ‘Œ\nğ‘…\nğ‘Œ\nğµ\nğ‘…\nğµ\nğ‘Œ\nğ‘…\nğ‘Œ\nğµ\nğµ\nğ‘Œ\nğ‘…\nğ‘Œ\nğ‘…\nğµ\nğ‘Œ\nğµ\nğ‘…\n820\nChapter 22. Backtracking and Branch and Bound\nWe have considered all possible choices for the third marble, so there are no more branches we have to consider for the case where ğµand ğ‘…take\nup the first two positions. We then undo the choice of the second marble to move up a level of the tree.\nğµ\nğ‘…\nğ‘…\nâœ•\nğµ\nğµ\nğ‘…\nğ‘Œ\nğ‘Œ\nğ‘…\nğµ\nğ‘…\nğ‘Œ\nğµ\nğ‘Œ\nğ‘Œ\nğ‘…\nğ‘Œ\nğµ\nğ‘…\nğµ\nğ‘Œ\nğ‘…\nğ‘Œ\nğµ\nğµ\nğ‘Œ\nğ‘…\nğ‘Œ\nğ‘…\nğµ\nğ‘Œ\nğµ\nğ‘…\nSince we have finished considering the red marble in the middle position, we will now consider the yellow marble.\nğµ\nğ‘…\nğ‘…\nâœ•\nğµ\nğµ\nğ‘Œ\nğµ\nğ‘…\nğ‘Œ\nğ‘Œ\nğ‘…\nğµ\nğ‘…\nğ‘Œ\nğ‘Œ\nğ‘…\nğ‘Œ\nğµ\nğ‘…\nğµ\nğ‘Œ\nğ‘…\nğ‘Œ\nğµ\nğµ\nğ‘Œ\nğ‘…\nğ‘Œ\nğ‘…\nğµ\nğ‘Œ\nğµ\nğ‘…\nHowever, this choice is promising, so we will prune off all solutions that begin with the blue and yellow marbles.not\nğµ\nğ‘…\nğ‘…\nâœ•\nğµ\nğµ\nğ‘Œ\nâœ•\nğµ\nğ‘…\nğ‘Œ\nğ‘Œ\nğ‘…\nğµ\nğ‘…\nğ‘Œ\nğ‘Œ\nğ‘…\nğ‘Œ\nğµ\nğ‘…\nğµ\nğ‘Œ\nğ‘…\nğ‘Œ\nğµ\nğµ\nğ‘Œ\nğ‘…\nğ‘Œ\nğ‘…\nğµ\nğ‘Œ\nğµ\nğ‘…\nWe then undo the choice and return back to the state where only the blue marble has been placed. At this point, we have considered all possible\nscenarios where the blue marble is in the first position, so we can undo that choice as well.\nğµ\nğ‘…\nğ‘…\nâœ•\nğµ\nğµ\nğ‘Œ\nâœ•\nğµ\nğ‘…\nğ‘Œ\nğ‘Œ\nğ‘…\nğµ\nğ‘…\nğ‘Œ\nğ‘Œ\nğ‘…\nğ‘Œ\nğµ\nğ‘…\nğµ\nğ‘Œ\nğ‘…\nğ‘Œ\nğµ\nğµ\nğ‘Œ\nğ‘…\nğ‘Œ\nğ‘…\nğµ\nğ‘Œ\nğµ\nğ‘…\nThe last marble we still need to consider for the first position is the yellow marble, so we will select it to explore our final branch.\nğ‘Œ\nğµ\nğ‘…\nğ‘…\nâœ•\nğµ\nğµ\nğ‘Œ\nâœ•\nğµ\nğ‘…\nğ‘Œ\nğ‘…\nğµ\nğ‘…\nğ‘Œ\nğ‘Œ\nğ‘…\nğ‘Œ\nğµ\nğ‘…\nğµ\nğ‘Œ\nğ‘…\nğ‘Œ\nğµ\nğµ\nğ‘Œ\nğ‘…\nğ‘Œ\nğ‘…\nğµ\nğ‘Œ\nğµ\nğ‘…\n22.1 Backtracking\n821\nThis choice does not break any constraints, so we will continue recursing down its branch. Using a similar approach as before, we will consider\nboth ğ‘…and ğµas the second marble. The branch with ğ‘…as the second marble leads to a valid solution, while the branch with ğµas the second\nmarble gets pruned since it breaks the given constraint.\nğ‘Œ\nğµ\nğ‘…\nğ‘…\nâœ•\nğµ\nğµ\nğ‘Œ\nâœ•\nğµ\nğ‘…\nğ‘Œ\nğ‘Œ\nğ‘…\nğ‘Œ\nğ‘…\nğµ\nğ‘Œ\nğµ\nâœ•\nğ‘…\nğµ\nğ‘…\nğ‘Œ\nğ‘…\nğµ\nğ‘Œ\nğ‘…\nğ‘Œ\nğµ\nğµ\nğ‘Œ\nğ‘…\nğ‘Œ\nğµ\nğ‘…\nThus, there are two valid solutions to the marble problem that satisfy the constraint that the red marble must be in the middle:\nğµ\nğ‘…\nğ‘Œ\nğ‘Œ\nğ‘…\nğµ\nÂ¸ 22.1.2\nBacktracking Structure\nThe good news about backtracking solutions is that they often share a similar structure, so the logic that is used to solve one backtracking\nproblem can often be applied to solve other backtracking problems. When writing a backtracking algorithm, you typically want to do the\nfollowing four things:\n1. Identify the choice you need to make at each step to bring you closer to a solution.\nIdentifying the allows you to conceptualize the state-space tree for a backtracking problem. This step is usually relatively straightforwardchoice\nand can be inferred from the type of problem you are given (such as adding a number to a running collection, or placing a piece down on a grid).\nA rule of thumb is to think about the choices you would need to make to solve the problem if you were brute forcing it by hand, and then apply\nthat choice in a backtracking approach.\n2. Devise a mechanism for checking whether a partial solution is a valid full solution.\nYou will need a way to determine whether a partial solution could potentially be a complete solution to the entire problem. For example, in the\nmarble example from before, you would know that a solution is complete once all three marbles have been placed. If any position is empty, then\nthe partial solution cannot be a full valid solution. This check is needed so that your algorithm knows when to store a solution or exit the search.\n3. Devise a mechanism for checking whether a partial solution is promising.\nYou will need a way to determine whether a partial solution is promising, so that you can prune branches that cannot lead to a valid solution.\nThis is often done by checking a partial solution against the given constraints. Implementing a promising check is not always trivial, and can\neven be the most complicated component of a backtracking algorithm. However, this process is also the most important, since a backtracking\nalgorithm without any promising checks essentially degenerates to brute force.\n4. Using the three features above, implement a function for exploring the solution space.\nFor backtracking problems, this is often done by writing a recursive function that performs the choices needed to extend a partial solution and\nthen checks that partial solution against the given constraints. If you have all of the things above, you can typically implement this function\ncheck_node()using one of the following two templates. Here, checks the current partial solution (the function is named that way because\neach partial solution is a node of a backtracking problemâ€™s state-space tree).\nTemplate 1 (Promising Check Before Recursive Call):\n1\nAlgorithm check_node(partial_solution):\n2\nif partial_solution is a valid full solution:\n3\nstore solution\n4\nelse:\n5\nif (promising(partial_solution)):\n6\nfor each choice that can be made to extend partial_solution:\n7\npartial_solution = partial_solution + choice\n8\ncheck_node(partial_solution)\n9\npartial_solution = partial_solution - choice\nTemplate 2 (Promising Check After Recursive Call):\n1\nAlgorithm check_node(partial_solution):\n2\nif partial_solution is not promising:\n3\nreturn\n4\nif partial_solution is a valid full solution:\n5\nstore solution\n6\nelse:\n7\nfor each choice that can be made to extend partial_solution:\n8\npartial_solution = partial_solution + choice\n9\ncheck_node(partial_solution)\n10\npartial_solution = partial_solution - choice\n822\nChapter 22. Backtracking and Branch and Bound\nBoth templates accomplish in the same thing; the only difference is that the first template checks if a partial solution is promising abefore\nrecursive call is made, while the second template checks if a partial solution is promising a recursive call is made. Either version can beafter\nused, but depending on the problem you are trying to solve, one may be easier to implement than the other. To demonstrate this strategy in\naction, we will look at a few examples of backtracking problems over the next few pages.\nÂ¸ 22.1.3\nSolving Problems Using Backtracking: Combinations\nExample 22.1 nums, target.You are given an vector of distinct positive integers, as well as a target integer Your goal is to write a\nnums targetfunction that returns a list of all combinations of numbers in that sum to (you can return the solutions in any order).unique\nnums = [2, 3, 5] target = 8, [2, 2, 2, 2], [2, 3, 3],For example, if you are given the array and you would return\n[3, 5], numsand since these are the unique combinations of numbers in that sum up to 8.\nSince this is a constraint satisfaction problem that asks you to enumerate over all solutions that satisfy a given set of constraints, backtracking\ncan be used to implement a solution. To implement a backtracking solution, we first want to think about the we should make at each stepchoice\nnumsto bring us closer to a solution. In this case, the choice is to add a number from to a running combination of numbers, and there are three\npossible choices that we can make at each step: we can either add a 2, a 3, or a 5 to our running total. To ensure that we arenâ€™t considering\n[2, 3] [3, 2]), numsduplicates (i.e., both and we will not add any values whose index position in is less than the index of any value\nalready in our running collection. The state-space tree for this problem is shown below:\n[]\n[5]\n[5,5]\n[5,5,5]\nâ‹®\n[3]\n[3,5]\n[3,5,5]\nâ‹®\n[3,3]\n[3,3,5]\nâ‹®\n[3,3,3]\nâ‹®\n[2]\n[2,5]\n[2,5,5]\nâ‹®\n[2,3]\n[2,3,5]\nâ‹®\n[2,3,3]\n[2,3,3,5]\nâ‹®\n[2,3,3,3]\nâ‹®\n[2,2]\n[2,2,5]\n[2,2,5,5]\nâ‹®\n[2,2,3]\n[2,2,3,5]\nâ‹®\n[2,2,3,3]\nâ‹®\n[2,2,2]\n[2,2,2,5]\nâ‹®\n[2,2,2,3]\nâ‹®\n[2,2,2,2]\nâ‹®\nIn addition to the choice, we also need a way to check if a partial solution is a valid complete solution, and if a partial solution is promising. To\ndetermine if a partial solution is complete, we just need to check if its sum is equal to our target value of 8. Similarly, because the values in\nnums are all positive, we can check if a choice is promising by looking at the sum of the new partial solution once the new value is added â€” a\nbranch can be pruned as soon as its sum exceeds the target value of 8.\n[]\n[5]\n[5,5]\nâœ•\n[3]\n[3,5]\n[3,5,5]\nâœ•\n[3,3]\n[3,3,5]\nâœ•\n[3,3,3]\nâœ•\n[2]\n[2,5]\n[2,5,5]\nâœ•\n[2,3]\n[2,3,5]\nâœ•\n[2,3,3]\n[2,3,3,5]\nâœ•\n[2,3,3,3]\nâœ•\n[2,2]\n[2,2,5]\n[2,2,5,5]\nâœ•\n[2,2,3]\n[2,2,3,5]\nâœ•\n[2,2,3,3]\nâœ•\n[2,2,2]\n[2,2,2,5]\nâœ•\n[2,2,2,3]\nâœ•\n[2,2,2,2]\nâ‹®\nNowthatweknowhowtocheckforwhetherapartialsolutioniscompleteorpromising, wealsoneedawaytoimplementthesechecksefficiently.\nA naÃ¯ve approach to implement our promising check would be to individually sum up every partial solution we encounter. However, this method\nis quite inefficient, since each summation takes linear time on the size of the partial solution, and we end up doing a summation for every partial\nsolution we encounter in the tree. To prevent our algorithm from performing a summation at every step, we can keep track of a separate integer\nremain that stores how much we can add to a partial solution before it becomes too large. For example, if we are currently considering the\n[2, 3], remainpartial solution then would have a value of 3, since this is the most we can add to this partial solution without going over our\nremaintarget of 8. This allows us to complete a promising check in constant time, since we only need to check if is non-negative. Similarly,\nremainthis additional variable allows us to easily check if a solution is complete, since a solution is complete only if is exactly 0.\n22.1 Backtracking\n823\nNow that we have identified the choice we need to make and the procedure for checking whether the current solution is promising or complete,\nwe can use the backtracking template to write a solution for the combination sum problem.\n1\nstd::vector<std::vector<int32_t>> combination_sum(const std::vector<int>& int32_tnums, target) {\n2\nstd::vector<std::vector<int32_t>> solutions;\n3\nstd::vector<int32_t> current_partial_solution;\n4\ncheck_sum(nums, target, solutions, current_partial_solution, 0);\n5\nreturn solutions;\n6\n} // combination_sum()\n7\n8\nvoid check_sum(const std::vector<int32_t>& int32_tnums, remain,\n9\nstd::vector<std::vector<int32_t>>& solutions,\n10\nstd::vector<int32_t>& size_tcurrent_partial_solution, start_idx) {\n11\nif (remain == 0) {\n12\nsolutions.push_back(current_partial_solution);\n13\n} // if\n14\nelse {\n15\nfor (size_t i = start_idx; i < nums.size(); ++i) {\n16\ncurrent_partial_solution.push_back(nums[i]);\n17\nif (nums[i] <= remain) {\n18\ncheck_sum(nums, remain - nums[i], solutions,\ncurrent_partial_solution, i);\n19\n} // if\n20\ncurrent_partial_solution.pop_back();\n21\n} // for i\n22\n} // else\n23\n} // check_sum()\nExample 22.2 nums,Given a vector of unique integers implement a function to return all possible subsets that can be constructed using\n[1, 2, 3],this vector of integers (i.e., the power set). For example, given the vector you would return\n[ [], [1], [2], [1, 2], [3], [1, 3], [2, 3], [1, 2, 3] ]\nThis problem is similar to the combination sum problem, where we add values to a running collection (using the same rules to ensure we do not\ncheck the same subset twice). However, in this case, we do not want to add values that have already been added, since a valid subset cannot\ncontain duplicate elements. The state-space tree for this problem is shown below:\n[ ]\n[3]\n[2]\n[2, 3]\n[1]\n[1, 3]\n[1, 2]\n[1, 2, 3]\nNotice that every node of the state-space tree is a subset of the original input array â€” thus, we will need to keep track of every partial solution\nin our final output container. Furthermore, there are no constraints that allow us to prune off any branches in the tree, so we will need to treat\nevery branch as promising. The solution is shown below:\n1\nstd::vector<std::vector<int32_t>> power_set(const std::vector<int32_t>& nums) {\n2\nstd::vector<std::vector<int32_t>> solutions;\n3\nstd::vector<int32_t> current_partial_solution;\n4\ncheck_node(nums, solutions, current_partial_solution, 0);\n5\nreturn solutions;\n6\n} // power_set()\n7\n8\nvoid check_node(const std::vector<int32_t>& std::vector<std::vector<int32_t>>nums, &solutions,\n9\nstd::vector<int32_t>& size_tcurrent_partial_solution, start_idx) {\n10\nsolutions.push_back(current_partial_solution);\n11\nfor (size_t i = start_idx; i < nums.size(); ++i) {\n12\ncurrent_partial_solution.push_back(nums[i]);\n13\ncheck_node(nums, solutions, current_partial_solution, i + 1);\n14\ncurrent_partial_solution.pop_back();\n15\n} // for i\n16\n} // check_node()\n824\nChapter 22. Backtracking and Branch and Bound\nExample 22.3 Given a positive integer ğ‘›, implement a function that returns all combinations of well-formed sequences that can be\nconstructed using ğ‘›pairs of parentheses. For example, given 3, you would returnğ‘›=\n[\"((()))\", \"(()())\", \"(())()\", \"()(())\", \"()()()\"]\nSince this is a constraint satisfaction problem, it can be solved using a backtracking approach. Here, each choice would be to add a parenthesis\n(either left or right, as long as we have one available) to a running sequence of parentheses. The state-space tree for is shown below:ğ‘›=3\n\"\"\n\")\"\n\"))\"\n\")))\"\n\")))(\"\n\")))((\"\n\")))(((\"\n\"))(\"\n\"))()\"\n\"))()(\"\n\"))()((\"\n\"))((\"\n\"))(()\"\n\"))(()(\"\n\"))(((\"\n\"))((()\"\n\")(\"\n\")()\"\n\")())\"\n\")())(\"\n\")())((\"\n\")()(\"\n\")()()\"\n\")()()(\"\n\")()((\"\n\")()(()\"\n\")((\"\n\")(()\"\n\")(())\"\n\")(())(\"\n\")(()(\"\n\")(()()\"\n\")(((\"\n\")((()\"\n\")((())\"\n\"(\"\n\"()\"\n\"())\"\n\"()))\"\n\"()))(\"\n\"()))((\"\n\"())(\"\n\"())()\"\n\"())()(\"\n\"())((\"\n\"())(()\"\n\"()(\"\n\"()()\"\n\"()())\"\n\"()())(\"\n\"()()(\"\n\"()()()\"\n\"()((\"\n\"()(()\"\n\"()(())\"\n\"((\"\n\"(()\"\n\"(())\"\n\"(()))\"\n\"(()))(\"\n\"(())(\"\n\"(())()\"\n\"(()(\"\n\"(()()\"\n\"(()())\"\n\"(((\"\n\"((()\"\n\"((())\"\n\"((()))\"\nJust by looking at the tree, it is easy to determine which branches are promising and which are not. However, when we actually implement this\nproblem, we do not want to individually calculate whether a sequence of parentheses is balanced for every partial solution we encounter! Is\nthere a faster way to determine whether a partial solution is promising, preferably in constant time?\nTo address this, notice that a sequence of parentheses is promising only if the number of left parentheses is greater than or equal to the\nnumber of right parentheses. In addition, the number of left parentheses in the sequence cannot exceed ğ‘›. Thus, to efficiently determine if a\npartial solution is promising, we just need to keep track of the number of left and right parentheses present in any partial solution. If the number\nof right parentheses exceeds the number of left parentheses, or if the number of left parentheses exceeds ğ‘›, we can prune the branch of the tree.\n\"\"\n\")\"\nâœ•\n\"(\"\n\"()\"\n\"())\"\nâœ•\n\"()(\"\n\"()()\"\n\"()())\"\nâœ•\n\"()()(\"\n\"()()()\"\n\"()((\"\n\"()(()\"\n\"()(())\"\n\"((\"\n\"(()\"\n\"(())\"\n\"(()))\"\nâœ•\n\"(())(\"\n\"(())()\"\n\"(()(\"\n\"(()()\"\n\"(()())\"\n\"(((\"\n\"((()\"\n\"((())\"\n\"((()))\"\nWe can also easily determine whether we have a potential full solution by looking at the number of parentheses in our current sequence. Since a\nvalid solution involves ğ‘›pairs of parentheses, the length of a valid sequence must have length 2ğ‘›. Using this information, we can construct the\nfollowing backtracking solution for this problem:\n1\ngenerate_parentheses(int32_tstd::vector<std::string> n) {\n2\nstd::vector<std::string> solutions;\n3\nstd::string current_partial_solution;\n4\ncheck_parentheses(n, solutions, current_partial_solution, 0, 0);\n5\nreturn solutions;\n6\n} // generate_parentheses()\n7\n8\nvoid check_parentheses(int32_t n, std::vector<std::string>& solutions,\n9\nint32_t int32_tstd::string current_partial_solution, left, right) {\n10\nif (current_partial_solution.length() == 2 n) {*\n11\nsolutions.push_back(current_partial_solution);\n12\n} // if\n13\nelse {\n14\nif (left < n) {\n15\ncheck_parentheses(n, solutions, current_partial_solution + \"(\", left + 1, right);\n16\n} // if\n17\nif (right < left) {\n18\ncheck_parentheses(n, solutions, current_partial_solution + \")\", left, right + 1);\n19\n} // if\n20\n} // else\n21\n} // check_parentheses()\n22.1 Backtracking\n825\nÂ¸ 22.1.4\nSolving Problems Using Backtracking: N-Queens\nExample 22.4 In the game of chess, the is a powerful piece that can move any number of squares vertically, horizontally, orqueen\ndiagonally. The movement capability of a queen is shown on the chessboard below:\n1\na\n2\nb\n3\nc\n4\nd\n5\ne\n6\nf\n7\ng\n8\nh\nq\nThe premise of the N-Queens problem is relatively straightforward: given a chessboard of size ğ‘Ã—ğ‘, is it possible to place ğ‘queens on\nthe chessboard without any of the queens directly threatening each other? In other words, is it possible to place ğ‘queens on a ğ‘Ã—ğ‘\nchessboard such that no queen is directly in the path of another queen? Implement a function that takes in a dimension ğ‘›of a ğ‘›Ã—ğ‘›board\nand returns all possible placements of ğ‘›queens such that no queen threatens any other queen on the board.\nSince this is a constraint satisfaction problem, we can solve it using backtracking. In this problem, we want to place queens on the chessboard\nunder the constraint that any queen we place cannot threaten any other queen already on the chessboard. Letâ€™s look at the backtracking algorithm\nin action on a 4 4 board:Ã—\n1\na\n2\nb\n3\nc\n4\nd\nA sensible first choice is to place a queen in the first position and start exploring partial solutions from there. This choice does not break any\nconstraints, since there are no other queens currently on the chessboard.\n1\na\n2\nb\n3\nc\n4\nd\nq\nWhat should our second choice be? We could consider every empty cell from left to right, then top to bottom. If we did this, we would put a\nqueen in the second cell of the chessboard, see that it is not promising, and undo the choice.\n1\na\n2\nb\n3\nc\n4\nd\nqq\n1\na\n2\nb\n3\nc\n4\nd\nqq\n1\na\n2\nb\n3\nc\n4\nd\nq\nHowever, this is not an efficient way to explore the search space, since we know that a queen placed in the same row as another queen will\nalways violate our constraint. To reduce our search space and make the backtracking process more efficient, we can instead make choices one\nat a time. That is, after we place a queen in one row, the next choice will place a queen in the row, which eliminates the need to checkrow next\nthe horizontal constraint on a regular basis. Note that queens can be placed one column at a time as well â€” the idea here is to not waste time\nmaking choices that you already know will not be promising without having to make the choice!\n22.1 Backtracking\n827\nSince placing the queen at position did not lead us to a solution, we will try placing the queen at position ğ‘4, the next position in the first row.ğ‘4\nThe next steps of the backtracking process are shown below:\n1\na\n2\nb\n3\nc\n4\nd\nq\nâœ•\nâœ•\nâœ•\n1\na\n2\nb\n3\nc\n4\nd\nq\nq\nâœ•\nâœ•\nâœ•\n1\na\n2\nb\n3\nc\n4\nd\nq\nq\nq\nâœ•\nâœ•\nâœ•\n1\na\n2\nb\n3\nc\n4\nd\nq\nq\nq\nq\nWe were able to place a queen in all four rows, so we have a solution to the problem that satisfies all constraints! To find additional solutions, we\nwould undo the queen placement in square and continue searching using the same approach as before.ğ‘1\nTo summarize, the components of the N-Queens problem are as follows:\nâ€¢ The we need to make is to place a queen in the next unconsidered square (from left to right) in the first row of the chessboard thatchoice\ndoes not yet have a queen.\nâ€¢ To determine if a partial solution is a solution, we check if we have successfully placed a queen in the final row of thevalid complete\nchessboard.\nâ€¢ To determine if a partial solution is promising, we check if the queen we place is threatened by any existing queens already on the\nchessboard.\nUsing this information, we can implement the following solution to the N-Queens problem:\n1\nusing std::vector<std::vector<bool>>;Board =\n2\n3\nn_queens(size_tstd::vector<Board> n) {\n4\nstd::vector<Board> solutions;\n5\nstd::vector<bool>(n, false));Board current_partial_solution(n,\n6\nplace_queen(solutions, current_partial_solution, 0, n);\n7\nreturn solutions;\n8\n} // n_queens()\n9\n10\nbool size_t size_t size_tpromising(Board& current_partial_solution, row, col, n) {\n11\n// check for queens in same column\n12\nfor (size_t r = 0; r < row; ++r) {\n13\nif true)(current_partial_solution[r][col] == {\n14\nreturn false;\n15\n} // if\n16\n} // for r\n17\n// check for queens in same 45 degree diagonal\n18\nfor (size_t r = row, c = col; r-- > 0 && c-- > 0; ) {\n19\nif true)(current_partial_solution[r][c] == {\n20\nreturn false;\n21\n} // if\n22\n} // for r, c\n23\n// check for queens in same 135 degree diagonal\n24\nfor (size_t r = row, c = col; r-- > 0 && c++ < n - 1; ) {\n25\nif true)(current_partial_solution[r][c] == {\n26\nreturn false;\n27\n} // if\n28\n} // for r, c\n29\nreturn true;\n30\n} // promising()\n31\n32\nvoid place_queen(std::vector<Board>& solutions, Board& current_partial_solution,\n33\nsize_t size_trow, n) {\n34\nif (row == n) {\n35\nsolutions.push_back(current_partial_solution);\n36\n} // if\n37\nelse {\n38\nfor (size_t col = 0; col < n; ++col) {\n39\nif (promising(current_partial_solution, row, col, n)) {\n40\ntrue;current_partial_solution[row][col] =\n41\nplace_queen(solutions, current_partial_solution, row + 1, n);\n42\nfalse;current_partial_solution[row][col] =\n43\n} // if\n44\n} // for col\n45\n} // else\n46\n} // place_queen()\n22.1 Backtracking\n829\nPutting this all together, we can implement the following solution to the N-Queens problem. Unlike before, we can now check if a column or\ndiagonal is available in time (by checking a Boolean stored in an array) without needing to conduct a linear traversal every time. Ourconstant\npromising() function still gets the job done, but much more efficiently!\n1\nusing std::vector<std::vector<bool>>;Board =\n2\n3\nclass NQueensSolver {\n4\nsize_t size;\n5\nstd::vector<size_t> position_in_row;\n6\nstd::vector<bool> column, left_diagonal, right_diagonal;\n7\nstd::vector<Board> solutions;\n8\nconst bool true;AVAILABLE =\n9\n10\npublic:\n11\nNQueensSolver(size_t n)\n12\ntrue),: size{n}, position_in_row(n, -1), column(n,\n13\ntrue), true)left_diagonal(2 n - 1, right_diagonal(2 n - 1, {}* *\n14\n15\nvoid place_queen(size_t row) {\n16\nif (row == size) {\n17\nstore_solution_board();\n18\nreturn;\n19\n} // place_queen()\n20\n21\nfor (size_t col = 0; col < size; ++col) {\n22\nif (promising(row, col)) {\n23\nposition_in_row[row] = col;\n24\ncolumn[col] = !AVAILABLE;\n25\nleft_diagonal[row + col] = !AVAILABLE;\n26\nright_diagonal[row - col + (size - 1)] = !AVAILABLE;\n27\nplace_queen(row + 1);\n28\n29\n// undo and backtrack\n30\ncolumn[col] = AVAILABLE;\n31\nleft_diagonal[row + col] = AVAILABLE;\n32\nright_diagonal[row - col + (size - 1)] = AVAILABLE;\n33\n} // if\n34\n} // for col\n35\n} // place_queen()\n36\n37\nbool promising(size_t size_trow, col) {\n38\nreturn column[col] == AVAILABLE &&\n39\nleft_diagonal[row + col] = AVAILABLE &&\n40\nright_diagonal[row - col + (size - 1)] = AVAILABLE;\n41\n} // promising()\n42\n43\nvoid store_solution_board() {\n44\nstd::vector<bool>(size, false));Board solution(size,\n45\nfor (size_t row; row < size; ++row) {\n46\nfor (size_t col; col < size; ++col) {\n47\nif (position_in_row[row] == col) {\n48\ntrue;solution[row][col] =\n49\n} // if\n50\n} // for col\n51\n} // for row\n52\nsolutions.push_back(solution);\n53\n} // store_solution_board()\n54\n55\nvoid solve() {\n56\nplace_queen(0);\n57\n} // solve()\n58\n59\nstd::vector<Board> get_solutions() {\n60\nreturn solutions;\n61\n} // get_solutions()\n62\n};\n63\n64\nn_queens(size_tstd::vector<Board> n) {\n65\nNQueensSolver nqs(n);\n66\nnqs.solve();\n67\nreturn nqs.get_solutions();\n68\n} // n_queens()\n22.1 Backtracking\n831\nAn implementation of this solution is shown below:\n1\nvoid solve_sudoku(std::vector<std::vector<char>> &board) {\n2\nif (!place_digit(board, 0, 0)) {\n3\nstd::cout << \"No solution\" << std::endl;\n4\n} // if\n5\n} // solve_sudoku()\n6\n7\nbool promising(std::vector<std::vector<char>>& size_t size_t charboard, row, col, digit) {\n8\nfor (size_t i = 0; i < 9; ++i) {\n9\n// check same row\n10\nif (board[row][i] == digit) {\n11\nreturn false;\n12\n} // if\n13\n// check same column\n14\nif (board[i][col] == digit) {\n15\nreturn false;\n16\n} // if\n17\n// check same subgrid\n18\nif (board[row - row % 3 + i / 3][col - col % 3 + i % 3] == digit) {\n19\nreturn false;\n20\n} // if\n21\n} // for i\n22\nreturn true;\n23\n} // promising()\n24\n25\nbool place_digit(std::vector<std::vector<char>>& size_t size_tboard, row, col) {\n26\nif (row == 9) {\n27\nreturn true;\n28\n} // if\n29\nif (col == 9) {\n30\nreturn place_digit(board, row + 1, 0);\n// check first empty cell in next row\n31\n} // if\n32\nif (board[row][col] != '.') {\n33\nreturn place_digit(board, row, col + 1);\n// ignore if cell already filled\n34\n} // if\n35\nfor (char c = '1'; c <= '9'; ++c) {\n36\nif (promising(board, row, col, c)) {\n37\nboard[row][col] = c;\n38\nif (place_digit(board, row, col + 1)) {\n39\nreturn true;\n40\n} // if\n41\nboard[row][col] = '.';\n42\n} // if\n43\n} // for c\n44\nreturn false;\n45\n} // place_digit()\nÂ¸ 22.1.6\nBacktracking Time Complexity\nWhat is the time complexity of a backtracking algorithm? Since backtracking is simply an extension of brute force that relies on pruning to\nreduce the solution space, the worst-case time complexity of backtracking is actually bounded by the time complexity of a brute force approach!\nWhy is this so? Consider the scenario where you are extremely unlucky and are unable to prune anything â€” if this happens, you are essentially\nchecking every possible solution. As a result, the worst-case time complexity of a backtracking algorithm is based on the total number of\nsolutions you would have to check if nothing is pruned. That being said, even though brute force serves as an upper bound on asymptotic\nruntime, the actual performance of backtracking is typically much faster (since the worst-case scenario rarely happens).\nExample 22.6 You are given a ğ‘›Ã—ğ‘›Sudoku board, where ğ‘›is a perfect square number. Assuming that the number of possibilities for\neach cell is ğ‘›(all numbers from 1 to ğ‘›), and the number of empty cells at the beginning is ğ‘š, what is the worst-case time complexity of a\nbacktracking solution for a Sudoku solver of this ğ‘›Ã—ğ‘›board?\nğ‘›ğ‘špossibleThere are a total of ğ‘šopen cells, and ğ‘›possibilities for each cell. Thus, by the fundamental counting principle, there are a total of\nğ‘‚(ğ‘›ğ‘š).boards that can be created. Thus, the worst-case time complexity of a backtracking solution to the Sudoku solver problem is bounded by\n832\nChapter 22. Backtracking and Branch and Bound\n22.2\nBranch and Bound\nÂ¸ 22.2.1\nBranch and Bound: Minimization Problems\nPreviously, we discussed the algorithm family of backtracking, which solves constraint satisfaction problems by performing a search over the\nsolution space and pruning partial solutions that cannot lead to a valid solution. This technique of pruning partial solutions can also be used to\nsolve problems. If we apply the concepts of backtracking to solve an optimization problem, we end up with a similar algorithmoptimization\npromising()family known as branch and bound. In branch and bound, the function now has two responsibilities:\n1. It must determine if a partial solution can ever lead to a complete solution that (similar to backtracking).satisfies all constraints\n2. It must also determine if the partial solution can ever lead to an solution.optimal\nThis second task can be completed by estimating a bound on the the best solution obtainable from continuing a partial solution. The bound\ngives you a reasonable estimate for the remaining work needed to complete a solution, without having to do the work itself. This allows the\nalgorithm to quickly identify whether it should continue looking down the branch it is currently exploring: if the bound of a partial solution\nis not better than the best complete solution known so far, then there is no reason to continue exploring that partial solution (this process of\nsystematically eliminating partial solutions from consideration is known as pruning).\nIt is important to note that bounds are simply estimates, and a bound does have to match the actual best solution of extending a partialnot\nsolution (which can often be expensive to compute). However, you still want your bounds to be as close to the actual solution as possible, since\na more accurate bound allows you to prune more efficiently.\nThere are also limits on what a valid bound can be: an estimated bound must be as the actual best solution attainableat least as optimistic\nfrom continuing a partial solution. Otherwise, your algorithm could potentially prune the optimal solution by mistakenly believing that its\nbranch is not promising (an issue known as overpruning)!\nThe precise calculation of bounds depends on whether you are trying to solve a minimization or a maximization problem. If you are working\nwith a problem, you would need to identify the following two bounds at every partial solution:minimization\nâ€¢ A lower bound, which is an of the best solution you could get from extending the current partial solution. The loweroptimistic estimate\nbound is calculated by taking the cost of the partial solution so far and adding it to an of the remaining cost required tounderestimate\ncomplete the partial solution (we will discuss why an underestimate is needed for minimization problems later in the section).\nAn upper bound, which is the cost of the best complete solution encountered so far. The upper bound, as its name suggests, serves as anâ€¢\nupper limit for the lower bound estimate. If the calculated lower bound of a partial solution is greater than or equal to the current upper\nbound, then the partial solution can be pruned.\nThe lower and upper bounds are compared to determine if a branch is promising. If the lower bound is less than the current upper bound, then it\nmay be possible to discover a better solution along that branch, and you should continue extending the current partial solution. Otherwise, there\nis no way to discover a solution that is better by extending the partial solution, and the branch should be pruned.\nLetâ€™s look at this process using an example. Suppose we are trying to solve a minimization problem, where the best complete solution we\nknow so far has a total cost of 281, and the current partial solution we are considering has a cost of 183. Our goal with branch and bound is to\ndiscover the optimal solution, so our algorithm needs to know whether the current partial solution can ever lead to a outcome that is better than\nour best-known solution of 281. If it cannot, then the partial solution cannot be optimal, and we can stop exploring it immediately.\n0\n183\n281\n(upper bound)\nworse than 281 (prune)\nbetter than 281 (promising)\n?\n?\nHowever, there isnâ€™t much we can infer about the branch just by looking at the current cost of the partial solution (which is 183). For instance, it\nis entirely possible that every solution down this branch leads to a solution that is worse than 281 (which indicates the branch should be pruned).\n0\n183\n281\n(upper bound)\n326\n323\n337\n360\n349\n834\nChapter 22. Backtracking and Branch and Bound\nIn general, you want the lower bound estimate to be to the actual best outcome of extending the branch. A lower bound thatas close as possible\nis too optimistic could cause you to waste time exploring solutions that arenâ€™t promising. For example, a lower bound of 240 for the following\nbranch is valid, but you would mistakenly believe that there is a better solution when there actually isnâ€™t. This would worsen the performance of\nyour branch and bound algorithm.\n0\n183\n281\n240\n(lower bound)\n326\n323\n337\n360\n349\n240 281<\npromising\n(but it isnâ€™t)\nHowever, the lower bound estimate cannot ever be than the actual best outcome of extending a branch! If your lower bound is tooworse\npessimistic, you could mistakenly believe a branch is not promising even if it includes the actual optimal solution. For example, consider the\nfollowing partial solution, where the best possible outcome of extending the partial solution is 270. However, if your lower bound is too high\n(e.g., 290), your algorithm would conclude that it is impossible to obtain a solution better than 290 by continuing the branch, and the partial\nsolution would be incorrectly pruned.\n0\n183\n281 290\n(lower bound)\n326\n323\n337\n360\n270\nâ‰¥281290\nnot promising\n(but it is)\nTo summarize, the steps of a branch and bound algorithm for a minimization problem are as follows:\n1. Start with an initial upper bound of infinity.\n2. Find the first complete solution and use its cost as an upper bound to prune branches during the rest of the search.\nExplore the solution space (similar to backtracking). For each partial solution encountered, calculate a lower bound estimate for the total3.\ncost required to complete the solution.\n4. Prune partial solutions whose lower bound is greater than or equal to the current upper bound. This is because the lower bound is an\noptimisticestimate of the best solution you could get from continuingthe partialsolution, and the upper boundis the best-known solution;\nif the optimistic estimate of continuing a branch is worse than the best-known solution, there is no reason to continue down that branch.\n5. If a branch is fully explored without being pruned, and the solution of this completed branch is than the existing upper bound,better\nupdate the upper bound to this new value (since the upper bound represents the best solution encountered so far).\n6. After the entire solution space is explored, the current upper bound is the optimal solution.\ncurrent_bestThe pseudocode for exploring the search space is shown below. At the end of the search, the value of (i.e., the upper bound)\nstores the optimal solution to the minimization problem.\n1\nAlgorithm check_node(partial_solution, current_best):\n2\nif partial_solution is a valid full solution:\n3\nif partial_solution < current_best:\n4\ncurrent_best = partial_solution\n5\nelse:\n6\nif (promising(partial_solution, current_best)):\n7\nfor each choice that can be made to extend partial_solution:\n8\npartial_solution = partial_solution + choice\n9\ncheck_node(partial_solution, current_best)\n10\npartial_solution = partial_solution - choice\n11\n12\nbool promising(partial_solution, current_best):\n13\nlower_bound = calculate_lower_bound()\n14\nif lower_bound < current_best:\n15\nreturn true\n16\nreturn false\n836\nChapter 22. Backtracking and Branch and Bound\n0\n183\n281\n240\n(upper bound)\n229\n232\n290\n225\n233\nâ‰¤281240\nnot promising\n(but it is)\nupper bound too pessimistic\nTo summarize, the steps of a branch and bound algorithm for a maximization problem are as follows:\n1. Start with an initial lower bound of zero (or negative infinity, if negatives are allowed).\n2. Find the first complete solution and use its cost as a lower bound to prune branches during the rest of the search.\n3. Explore the solution space. For each partial solution encountered, calculate an upper bound estimate for the total value attainable from\ncompleting the solution.\n4. Prune partial solutions whose upper bound is less than or equal to the current lower bound. This is because the upper bound is an\noptimistic estimate of the best solution you could get from continuing the partial solution, and the lower bound is the best-known solution;\nif the optimistic estimate of continuing a branch is worse than the best-known solution, there is no reason to continue down that branch.\n5. If a branch is fully explored without being pruned, and the solution of this completed branch is than the existing lower bound,better\nupdate the lower bound to this new value (since the lower bound represents the best solution encountered so far).\n6. After the entire solution space is explored, the current lower bound is the optimal solution.\ncurrent_bestThe pseudocode for this approach is shown below. At the end of the search, the value of (i.e., the lower bound) stores the\noptimal solution to the maximization problem:\n1\nAlgorithm check_node(partial_solution, current_best):\n2\nif partial_solution is a valid full solution:\n3\nif partial_solution > current_best:\n4\ncurrent_best = partial_solution\n5\nelse:\n6\nif (promising(partial_solution, current_best)):\n7\nfor each choice that can be made to extend partial_solution:\n8\npartial_solution = partial_solution + choice\n9\ncheck_node(partial_solution, current_best)\n10\npartial_solution = partial_solution - choice\n11\n12\nbool promising(partial_solution, current_best):\n13\nupper_bound = calculate_upper_bound()\n14\nif upper_bound > current_best:\n15\nreturn true\n16\nreturn false\nBranch and bound algorithms are not always easy to implement, even if they follow a common pattern! The most challenging component of any\nbranch and bound algorithm is the process of estimating the bounds, since this step can make or break the algorithm. There are also performance\ntradeoffs you must consider when identifying your bounds â€” better bounds can save you time by allowing you to prune more efficiently, but\nthey can also require a non-trivial amount of time to compute! In some cases, a quick bound estimation can get the job done. In other cases,\nÎ˜(ğ‘›2)spending more time perfecting your bounds can be worth the runtime improvements you get from pruning. For instance, an algorithm to\nestimate bounds may seem inefficient, but it is often preferable if the alternative involves exploring additional branches.Î˜(ğ‘›!)\nSimilar to backtracking, the worst-case time complexity of a branch and bound algorithm is bounded by the complexity of a brute force\napproach, which occurs in the case where nothing gets pruned. However, like before, this worst-case scenario rarely ever happens, so the\nperformance of branch and bound is typically superior to that of brute force.\nIn this class, we will focus on two important problems that can be solved using branch and bound. First, we will look at the traveling\nproblem, a minimization problem that can be solved using a branch and bound approach. Then, in chapter 24, we will look at thesalesperson\nproblem, a maximization problem that can also be solved using this algorithm family.knapsack\n22.3\nThe Traveling Salesperson Problem (TSP)\nÂ¸ 22.3.1\nEstimating Bounds for TSP\nInthissection,wewilldiscussthetravelingsalespersonproblem(TSP),oneofthemostextensivelystudiedoptimizationproblemsincomputer\nscience. In the traveling salesperson problem, you are given a collection of cities and distances between each pair of cities, and you want to find\nthe shortest route that visits every city once and returns back to the starting city (such a cycle that traverses every node of a graph once is known\nas a Hamiltonian cycle).\n22.3 The Traveling Salesperson Problem (TSP)\n837\nSuppose you are given the following ten cities, and you want to find the shortest Hamiltonian cycle that visits every city exactly once:\nA\nB\nC\nD\nE\nF\nG\nH\nI\nJ\nCity\nCoordinate\nğ´\n(2,3)\nğµ\n(3,5)\nğ¶\n(4,3)\nğ·\n(5,5)\nğ¸\n(5,2)\nğ¹\n(6,7)\nğº\n(7,5)\nğ»\n(9,7)\nğ¼\n(9,5)\nğ½\n(10,2)\nIf you were to use brute force to find a solution, you would have to check every Hamiltonian cycle possible to identify an optimal path. There are\n(ğ‘›âˆ’1)!a total of\n2\nsuch cycles, since from any starting vertex there are edges to choose from for the first vertex, edges to choose from forğ‘›âˆ’1 ğ‘›âˆ’2\nthe second vertex, edges to choose from for the third vertex, and so on (we divide the final result by two since half of these permutationsğ‘›âˆ’3\nare simply mirror images of each other, i.e., ğ´â†’ğµâ†’ğ¶â†’ğ´and ğ´â†’ğ¶â†’ğµâ†’ğ´). Because there exist possible Hamiltonian cyclesğ‘‚(ğ‘›!)\ngiven ğ‘›cities, a brute force approach to TSP would also take time, which is computationally infeasible for large input sizes.ğ‘‚(ğ‘›!)\nTo reduce the runtime of TSP, we can use a branch and bound approach to prune off paths we know cannot be optimal, therefore reducing\nthe size of our search space. To start off the branch and bound process, we will find the first complete solution and use its cost as an upper\nsearch.1bound to prune branches during the rest of the For our example, suppose the first complete solution we find is ğ´â†’ğµâ†’ğ¶â†’ğ·â†’\n33.095:2ğ¸â†’ğ¹â†’ğºâ†’ğ»â†’ğ¼â†’ğ½â†’ğ´, which has a total cost of\nA\nB\nC\nD\nE\nF\nG\nH\nI\nJ\nConnection\nDistance\nğ´â†’ğµ\n2.236\nğµâ†’ğ¶\n2.236\nğ¶â†’ğ·\n2.236\nğ·â†’ğ¸\n3.000\nğ¸â†’ğ¹\n5.099\nğ¹â†’ğº\n2.236\nğºâ†’ğ»\n2.828\nğ»â†’ğ¼\n2.000\nğ¼â†’ğ½\n3.162\nğ½â†’ğ´\n8.062\nTotal\n33.095\nNow we know that, whatever the optimal path is, it must have a weight less than or equal to 33.095. We will therefore set 33.095 as our initial\nupper bound. This allows us to prune future partial solutions that we know cannot lead us to a solution that is better than 33.095, the best\nsolution we have encountered so far.\nAfter identifying this upper bound, we will now need to implement a method to determine whether a partial solution is promising. Recall\nfrom the previous section that this step is done by estimating a for each partial solution, which serves as an optimistic estimate forlower bound\nthe best solution attainable from continuing the partial solution. For example, consider the following partial solution ğ´â†’ğµâ†’ğ¶â†’ğ¸:\nA\nB\nC\nD\nE\nF\nG\nH\nI\nJ\nConnection\nDistance\nğ´â†’ğµ\n2.236\nğµâ†’ğ¶\n2.236\nğ¶â†’ğ¸\n1.414\nâˆ’\nâˆ’\nâˆ’\nâˆ’\nâˆ’\nâˆ’\nâˆ’\nâˆ’\nâˆ’\nâˆ’\nâˆ’\nâˆ’\nâˆ’\nâˆ’\nTotal\n5.886\n1Thisisactuallynotthebestwaytosetaninitialupperbound,sincethefirstsolutionyoufindmaynotbeanidealbound. Instead,youshouldsettheinitialbound\ntotheresultofaTSPheuristic,whichwewilldiscussinalatersection.\n2Thedirectionofthearrowsherearearbitrarychosen,andcanbeflippedaroundtoproducetheexactsamepath. Thearrowsareincludedhere(andinfuture\nexamples)toeaseunderstandingofcertainTSPconcepts,sodonâ€™tworrytoomuchaboutwhythedirectionofthepathisthewayitis. Twosolutionswiththe\nsameedgesareconsideredtobeidentical,evenifthedirectionofthearrowsareflipped.\n840\nChapter 22. Backtracking and Branch and Bound\nTo estimate a lower bound for this partial solution, we first find the weight of the MST that connects the remaining points, which is 9.606:\nA\nB\nC\nD\nE\nF\nG\nH\nI\nJ\nWeight of MST: 9.606\nWeight of Partial Solution: 21.118\nConnection\nDistance\nğ¸â†’ğ¹\n5.099\nğ¹â†’ğ½\n6.403\nğ½â†’ğµ\n7.616\nğµâ†’ğ·\n2.000\nğ´â†’ğ¶\n2.000\nğ¶â†’ğº\n3.606\nğºâ†’ğ¼\n2.000\nğ»â†’ğ¼\n2.000\nâˆ’\nâˆ’\nâˆ’\nâˆ’\nTotal\n30.724\nThen, we calculate the cost of connecting the endpoints of our current partial solution (ğ¸and ğ·) with their closest points in the MST. The\nclosest point to ğ¸is ğ¶(for a cost of 1.414), and the closest point to ğ·is ğº(for a cost of 2).\nA\nB\nC\nD\nE\nF\nG\nH\nI\nJ\nWeight of MST: 9.606\nWeight of Partial Solution: 21.118\nWeight CE: 1.414\nWeight DG: 2\nConnection\nDistance\nğ¸â†’ğ¹\n5.099\nğ¹â†’ğ½\n6.403\nğ½â†’ğµ\n7.616\nğµâ†’ğ·\n2.000\nğ´â†’ğ¶\n2.000\nğ¶â†’ğº\n3.606\nğºâ†’ğ¼\n2.000\nğ»â†’ğ¼\n2.000\nğ¸â†’ğ¶\n1.414\nğ·â†’ğº\n2.000\nTotal\n34.138\nAdding everything up, we get a lower bound of 21.118 + 9.606 + 2 + 1.414 = 34.138. This means that the best solution we could get from\ncontinuing the partial solutionğ¸â†’ğ¹â†’ğ½â†’ğµâ†’ğ·cannot be better than 34.138. Since we already know that the cost of the complete solution\nğ´â†’ğµâ†’ğ¶â†’ğ·â†’ğ¸â†’ğ¹â†’ğºâ†’ğ»â†’ğ¼â†’ğ½â†’ğ´has a cost of 33.095, we know that our current partial solution is not promising. Thus,\nwe know that an optimal solution cannot possibly include ğ¸â†’ğ¹â†’ğ½â†’ğµâ†’ğ·, allowing us to prune this branch from our search space.\nÂ¸ 22.3.2\nGenerating Permutations\nWe now have a mechanism for determining whether a partial solution is promising. However, we still need a way to generate these partial\ngen_perms()solutions when exploring the solution space. In this class, we will use the following function to generate all partial solutions by\nperm_lengthpermuting over all possible paths where the first items of a path vector are fixed.\n1\ntemplate <typename T>\n2\nvoid size_tgen_perms(std::vector<T>& path, perm_length) {\n3\nif (perm_length == path.size()) {\n4\n// Base case, this gets hit if you fully explore a path without ever pruning it.\n5\n// This means the path currently stored in the vector may be an optimal solution,\n6\n// so compare it with the best solution known so far and update the upper bound if needed.\n7\nreturn;\n8\n} // if\n9\nif (!promising(path, perm_length)) {\n10\nreturn;\n11\n} // if\n12\nfor (size_t i = perm_length; i < path.size(); ++i) {\n13\nstd::swap(path[perm_length], path[i]);\n14\ngen_perms(path, perm_length + 1);\n15\nstd::swap(path[perm_length], path[i]);\n16\n} // for i\n17\n} // gen_perms()\n22.3 The Traveling Salesperson Problem (TSP)\n841\ngen_perms()Letâ€™s take a closer look at how works. Consider the traveling salesperson problem for 10 vertices, numbered from 0 to 9. To\ngen_perms(),use we will store all of these vertices in a vector that stores the current path:\npath\n0\n1\n2\n3\n4\n5\n6\n7\n8\n9\ngen_perms() path perm_lengthusesthis vectortoidentifythecurrentpartialsolutionat pointalongoursearch. Thisisdoneusingtheany\ngen_perms() perm_lengthvariable, which represents the current length of our partial solution. To start the search, is called with a of 1:\ngen_perms(1);\npath\n0\n1\n2\n3\n4\n5\n6\n7\n8\n9\nperm_length = 1\nThis indicates that the current partial solution has a length of 1 and only includes the vertex at the first position of the vector. We then check if\nthis partial solution is promising using the lower bound strategy explained previously â€” if it is, we extend the partial solution by adding another\nvertex to the back of our path. This is done by moving the vertex we want to add to the back of the partial solution, and then recursing on the\nperm_lengthvector with a value that is larger by one. This process is implemented using the loop on line 10 of the provided code.\npath iLetâ€™s look at this loop in action using the vector above. In the first iteration of the loop, is equal to 1, so index 1 is swapped with\nperm_lengthitself. We then make a recursive call with a of 2, which adds vertex 1 to our partial solution.\npath\n0\n1\n2\n3\n4\n5\n6\n7\n8\n9\nperm_length = 1\npath\n0\n1\n2\n3\n4\n5\n6\n7\n8\n9\nperm_length = 2\nperm_lengthWe then check if the partial solution is promising. If it is, we make a recursive call with a of 3, which adds vertex 2 toâ†’10\nthe partial solution.\npath\n0\n1\n2\n3\n4\n5\n6\n7\n8\n9\nperm_length = 3\npromising()However, letâ€™s suppose that our function determines that the partial solution isnâ€™t promising. In this case, we wouldâ†’10\nbe able to prune off this branch. The pruning step happens when the function returns on line 8, and we return to the stack frame where\nperm_length is 1. Notice that this tells our algorithm to ignore any permutation that starts with â†’1, since we will no longer make any0\nadditional recursive calls that begin with these two items!\npath\n0\n1\n2\n3\n4\n5\n6\n7\n8\n9\nperm_length = 2\npath\n0\n1\n2\n3\n4\n5\n6\n7\n8\n9\nperm_length = 1\nAfter the recursive call unrolls, we undo the swap we completed on line 11 (to ensure our loop explores the remaining branches correctly) and\nplace the next element we want to consider at the end of the partial solution. A new element is considered with each iteration of the loop â€” here,\ni perm_lengthis incremented to 2 on the next iteration, so we swap the vertex at index 2 to the back of the partial solution and recurse with a\nof 2. This allows us to explore all branches that start with â†’2.0\npath\n0\n2\n1\n3\n4\n5\n6\n7\n8\n9\nperm_length = 1\npath\n0\n2\n1\n3\n4\n5\n6\n7\n8\n9\nperm_length = 2\nThis process continues for the remainder of the search (we explore all paths that start with â†’3, then â†’4, and so on). At every step, we add0 0\na vertex to our path by swapping it into the next position of our partial solution and fixing it in place, and then recursively generate permutations\non the remaining vertices not in our path. We then check if each partial solution is promising by comparing its lower bound with the best\ncomplete solution known so far (i.e., the upper bound). If it is promising, we continue extending the branch. Otherwise, we swap out the element\nwe most recently added to our partial solution and try something else in its place.\nperm_lengthEventually, if every partial solution along a branch is promising, you will end up in a position where is equal to the size of\npaththe vector. When this happens, the entire path is fixed, and you have a complete solution that could potentially be better than the best\nknown solution so far. In this case, you should check to see if your current path is indeed better, and update your current best solution if it is.\npath\n0\n2\n1\n3\n4\n5\n6\n7\n8\n9\nperm_length = 9\nThere are two important details to note here. First, a path is always promising does guarantee an optimal solution. This is because we usenot\nan to determine if a branch is promising, and it is entirely possible for that estimate to be too optimstic. Because of this, you cannotestimate\nblindly update your best solution if you reach the base case â€” instead, you will need to compare the current path with the best solution youâ€™ve\ngen_perms()encountered to determine if it is actually better. Second, you cannot ensure that a solution is optimal until the initial call runs\nto completion. This is because you need to consider all possible solutions before you can safely conclude that one is better than the rest!\n842\nChapter 22. Backtracking and Branch and Bound\npromising()Remark: The function estimates the cost of continuing a partial solution, which allows you to prune branches that cannot\nlead to an optimal solution. However, there comes a point where the work required to estimate a lower bound is actually than the workgreater\nrequired to explore all the remaining branches. Suppose there are ğ‘˜vertices that remain unvisited in our current partial solution, where ğ‘˜=\npath.size() - perm_length. The cost of checking all remaining branches along this partial solution is ğ‘˜!, since we have to permute\nğ‘˜2 ğ‘˜2over the ğ‘˜vertices that have not yet been added to the path. On the other hand, the cost of estimating a lower bound is +2ğ‘˜, where the\nwork comes from building the MST, and the 2ğ‘˜work comes from connecting the two endpoints of the current tour with their closest points\nin the MST. If we look at the total work required for different values for ğ‘˜, we would get the following:\nk\nTSP (k!)\n(k2Estimate 2k)+\n1\n1\n3\n2\n2\n8\n3\n6\n15\n4\n24\n24\n5\n120\n35\n6\n720\n48\n7\n5040\n63\n8\n40320\n80\n9\n362880\n99\n10\n3628800\n120\nItâ€™s pretty clear that you would prefer to estimate if ğ‘˜is large. However, if there are fewer than five points remaining, then you arenâ€™t\ngetting much benefit from estimating a lower bound over simply brute forcing the remaining solutions. Thus, you can speed up your\npromising() truebranch-and-bound algorithm by having always return if the number of remaining points is less than 5.ğ‘˜=\n1\nbool size_tpromising(std::vector<T>& path, perm_length) {\n2\nif (path.size() - perm_length < 5) {\n3\nreturn true;\n4\n} // if\n5\n... // estimate lower bound and compare with upper bound\n6\n} // promising()\n22.4\nTSP Heuristics\nIn the previous section, we devised a reasonably efficient branch and bound algorithm for solving the traveling salesperson problem. However, if\nwe were to run our branch and bound algorithm on an input file containing several hundred points, we would see that it would take an incredibly\nlong time to run. Even though branch and bound is an improvement over brute force, there are still a lot of branches that we have to explore, and\nthe cost of estimating a lower bound is not negligible, especially as the number of vertices grows.\nAt the end of the day, TSP is still a computationally expensive problem, and an efficient branch and bound implementation can still struggle\non large input sizes. Because of this, we often rely on heuristics to approximate solutions for TSP problems where the input size is prohibitively\nlarge. Unlike brute force or branch and bound, heuristics do guarantee an optimal solution, but they have better time complexities and oftennot\nproduce approximations that are close to optimal. Heuristics can be classified into separate categories based on their behavior: constructive\napproximate an optimal solution by extending a partial solution step-by-step using a predefined set of rules, whileheuristics local search\nstart with a complete solution and attempt to improve it by applying a series of small changes. In this section, we will discuss a fewheuristics\nheuristics that can be used to efficiently approximate the optional solution of a traveling salesperson problem.\nÂ¸ 22.4.1\nNearest Neighbor and 2-Opt\nNearest neighbor and 2-opt are actually two different heuristics that can be combined to produce a close-to-optimal TSP solution in polynomial\ntime. Nearest neighbor is a relatively straightforward heuristic that relies on the greedy approach to identify an optimal path. The steps of the\nnearest neighbor heuristic are as follows:\n1. Start with an initial partial solution containing a single arbitrarily selected city.\n2. Identify the unvisited neighbor closest to the vertex most recently added to the partial solution, and add it to the path.\n3. After all points are added to the partial solution, connect the first and last vertices in the path to complete the solution.\nFor example, letâ€™s run the nearest neighbor heuristic on the following points, with ğ´as our initial starting vertex.\nA\nB\nC\nD\nE\nF\nG\nH\nI\nJ\n850\nChapter 22. Backtracking and Branch and Bound\nforWhat is the time complexity of this 2-opt implementation (reproduced below)? Letâ€™s first look at the nested loop spanning from lines 5-11.\nforHere, the body of the inner loop can take up to time, since we need to perform a reversal whenever a swap is made (and reversingÎ˜(ğ‘›)\nÎ˜(ğ‘›2)takes linear time). Since this work is the most expensive step and may be run up to times when looping over all pairs of non-adjacent\nÎ˜(ğ‘›2)Ã—Î˜(ğ‘›) Î˜(ğ‘›3).foredges (lines 5 and 6), the overall worst-case time complexity of the nested loop is =\n1\nbest_distance = calc_distance(current_path)\n// path after running nearest neighbor\n2\nhas_improvement = true\n// did you find a beneficial swap during the most recent iteration?\n3\nwhile has_improvement == true:\n4\nhas_improvement = false\n5\nfor i in range [0, num_cities - 2):\n6\nfor j in range [i + 2, num_cities):\n7\nchange = dist(i, j) + dist(i + 1, j + 1) - dist(i, i + 1) - dist(j, j + 1)\n8\nif change < 0:\n9\nreverse all vertices from index i + 1 to index j\n10\nbest_distance = best_distance + change\n11\nhas_improvement = true\nwhile forHowever, what about the outer loop that repeats as long as an improvement has been made? The nested loop on lines 5 and 6 may\nwhiletake polynomial time, but the overall performance of 2-opt also depends on how many times the outer loop on line 3 executes.\nwhileThis outer loop runs as long as there are pairs in our path that can be swapped to further improve the pathâ€™s total distance. Just\nhow many times can this happen? The answer to this problem is not trivial. van Leeuwen and Schoone (1980) proved that an algorithm which\nğ‘‚(ğ‘›3)removes intersections from a Hamiltonian path of ğ‘›vertices on an Euclidean plane will ultimately produce an intersection-free tour after\nremoved.5 ğ‘‚(ğ‘›3)removals, regardless of the order in which these intersections are However, this bound assumes the restriction that 2-opt can\nonly perform swaps to remove edges that intersect in the path. If we are allowed to perform a swap between any pair of non-adjacent edges that\nreduces total cost (regardless of whether the pair forms an intersection in the path), then the total number of swaps performed by 2-opt can\n(2014).6become exponential in the worst case, as proven by Englert, RÃ¶glin, and VÃ¶cking\nwhile forTo avoid this, one optimization is to disregard the outer loop entirely. Instead, the nested loop is run a constant number of\ntimes, regardless of the number of improvements that are made. By doing so, we sacrifice the accuracy of the algorithm for improved efficiency.\nforThe following pseudocode is similar to the one above, except that it only runs the nested loop once.\n1\nbest_distance = calc_distance(current_path)\n// path after running nearest neighbor\n2\nfor i in range [0, num_cities - 2):\n3\nfor j in range [i + 2, num_cities):\n4\nchange = dist(i, j) + dist(i + 1, j + 1) - dist(i, i + 1) - dist(j, j + 1)\n5\nif change < 0:\n6\nreverse all vertices from index i + 1 to index j\n7\nbest_distance = best_distance + change\nforA slightly more accurate (but less performant) implementation would still run the nested loop a constant number of times, but would\nforinstead the inner loop whenever an improvement is made (note that the loop is restarted and not the outer loop). This ensuresrestart inner\nthat you can still perform beneficial swaps that are unearthed by previous swaps within the same iteration of the inner loop without having to\nrestart the entire algorithm. This is shown below (again, this only runs the nested loops once, but you can tweak this based on your needs for\nperformance vs. accurary â€” if you run the algorithm more times, you will get a better approximation, but your performance will also be slower).\n1\nbest_distance = calc_distance(current_path)\n// path after running nearest neighbor\n2\nfor i in range [0, num_cities - 2):\n3\nfor j in range [i + 2, num_cities):\n4\nchange = dist(i, j) + dist(i + 1, j + 1) - dist(i, i + 1) - dist(j, j + 1)\n5\nif change < 0:\n6\nreverse all vertices from index i + 1 to index j\n7\nbest_distance = best_distance + change\n8\nrestart inner for loop from j = i + 2\nRemark: The 2-opt heuristic improves an existing solution by reconnecting of non-adjacent edges until no more pairs can be swappedpairs\nto further improve the solution. However, 2-opt is not the only heuristic that uses this strategy to optimize a tour. Another heuristic, 3-opt,\ndoes the same thing, but it instead reconnects edges in groups of three rather than two.\nHeuristics such as 2-opt and 3-opt are often defined as heuristics, which improve existing solutions by repeatedly reconnecting ğ‘˜edgesk-opt\nof a tour until no more changes can be made to improve the solution. A 3-opt approach often yields a better approximation of the optimal\nsolution than 2-opt, but it is also more computationally expensive (and therefore slower to run). For this class, you will not need to worry\nabout 3-opt (or any value of ğ‘˜above that) â€” 2-opt should be more than enough for any TSP problem you are required to solve.\n5\"UntanglingaTravelingSalesmanTourinthePlane\"byvanLeeuwenandSchoone(1980).\n6\"WorstCaseandProbabilisticAnalysisofthe2-OptAlgorithmfortheTSP\"byEnglert,RÃ¶glin,andVÃ¶cking(2014).\n22.4 TSP Heuristics\n857\nThis is the final result of the arbitrary insertion heuristic, with total weight 26.661. As you can see, all three of these insertion heurstics were\ntime.7Î˜(ğ‘›2)able to produce solutions that were close to optimal (25.049) in If you arenâ€™t concerned with finding the exact optimal solution for\na problem, a heuristic can provide a significant improvement over a branch-and-bound approach!\nRemark: The heuristics we have covered so far are not exhaustive, and many other heuristics exist for the traveling salesperson problem.\nFor instance, is another insertion heuristic that behaves similarly to nearest insertion, but instead of choosing to insertcheapest insertion\nthe vertex that is closest to any vertex the current partial tour, it chooses the vertex that, when added, results in the shortest possible tour.\nis a heuristic that uses advanced graph concepts to approximate a solution that is always within a factor of 3/2 ofChristofides algorithm\nthe optimal solution. The is an adaptive local-search heuristic that dynamically adjusts between different ğ‘˜-optLin-Kernighan heuristic\nheuristics to produce an estimate that is closer to optimal.\nMany of these more advanced heuristics may deliver better approximations, but similar the 3-opt approach discussed earlier, they are also a\nÎ˜(ğ‘›2)lot more expensive to compute. For the class, a heuristic such as nearest, farthest, or arbitrary insertion is enough for generating a\nreasonably close approximation for TSP in a short amount of time, which is why these additional heuristics are not covered in more detail.\nSo far, we have talked about how heuristics can be useful for approximating TSP in polynomial time. However, what if you absolutely needed to\nknow the exact optimal solution? Would heuristics be useless in such a scenario?\nAlthoughheuristicscannotguaranteeoptimality,theycanstillbeusefulinhelpingyoufindtheoptimalsolutionduringthebranch-and-bound\nprocess. Recall that the efficiency of branch-and-bound for TSP relies on an accurate bound, which is used to prune branches we canupper\nguaranteearesub-optimal. Currently, weinitiallysettheupperboundtothecostofthefirstcompletesolutionweencounter(whichwearbitrarily\ndecided as the path ğ´â†’ğµâ†’ğ¶â†’ğ·â†’ğ¸â†’ğ¹â†’ğºâ†’ğ»â†’ğ¼â†’ğ½â†’ğ´). Every branch that we explore later would then be compared to this\ninitial bound until a better solution is found.\nSince the upper bound is used as a threshold to decide whether a partial branch is promising, we want our upper bound to be as close as\npossible to the actual optimal solution to support efficient pruning. However, there is no guarantee that the first complete solution we find is\nclose to optimal! If our first solution is too costly, we would waste time exploring sub-optimal branches at the beginning of our algorithm.\nTo address this issue, we can instead set our initial upper bound to rather than the first solution we find during ourthe solution of a heuristic\nsearch. This ensures that our initial upper bound is close-to-optimal, allowing us to prune branches efficiently from the get-go. Even though a\nheuristic may take time to run, the cost savings of setting a tighter upper bound is often well worth this extra effort!\n7Donâ€™t judge the performance ofeach heuristicbased onthis example alone! Even thoughfarthestinsertionended up performingthe best,this dependson the\ninput. Givenanothersetofcities,itisentirelypossibleforadifferentheuristictoperformbetter.\n22.4 TSP Heuristics\n859\n6. Suppose you want to visit the computer science buildings of every major university in the United States, and you want to find the shortest\nroute that will allow you to visit each campus exactly once before returning to your starting location. What is the worst-case time complexity\nof using brute force to calculate this shortest path, assuming that you have ğ‘›campuses that you want to visit?\nÎ˜(2ğ‘›)A)\nÎ˜(ğ‘›2ğ‘›)B)\nÎ˜(ğ‘›2)C)\nÎ˜(ğ‘›ğ‘›)D)\nE) Î˜(ğ‘›!)\n7. Which of the following statements is/are TRUE?\nI. Running the branch and bound algorithm on the traveling salesperson problem is guaranteed to make the program run faster,\ncompared to a brute force solution.\nII. The worst-case time complexity of running the traveling salesperson problem using a branch and bound algorithm is better than\nthe worst-case time complexity of solving the traveling salesperson problem using brute force.\nIII. When solving the traveling salesperson problem using branch and bound, overestimating the cost of extending a partial solution\ncould cause you to fail to find the optimal solution.\nA) I only\nB) II only\nC) III only\nD) II and III only\nE) I, II, and III\n8. Which of the following statements is/are TRUE?\nI. When solving a minimization problem using branch and bound, a branch should be pruned if the upper bound is less than the\nlower bound.\nWhen solving a maximization problem using branch and bound, a branch should be pruned if the upper bound is greater than theII.\nlower bound.\nIII. When solving a maximization problem using branch and bound, the upper bound is calculated by taking the current partial\nsolution and adding it to an underestimate of the value obtainable from completing the partial solution.\nA) I only\nB) II only\nC) I and III only\nD) II and III only\nE) I, II, and III\n9. You are given two fully connected graphs, one with four vertices and the other with five vertices. How many more distinct Hamiltonian\ncycles exist in the graph with five vertices, compared to the one with four vertices? That is, if the graph with four vertices has distinctâ„4\nHamiltonian cycles and the graph with five vertices has distinct Hamiltonian cycles, what is the value of âˆ’â„4?â„5 â„5\nA) 24\nB) 48\nC) 72\nD) 96\nE) 120\n10. Which of the following problems can be solved using a backtracking algorithm?\nI. Finding the minimum spanning tree of a graph\nII. Determining if a graph can be colored with ğ‘›different colors without any adjacent vertices sharing the same color\nIII. Implementing a Sudoku solver\nA) I only\nB) II only\nC) III only\nD) II and III only\nE) I, II, and III\n11. Which of the following statements is true about branch and bound, but not necessarily true for backtracking?\nA) The algorithm can be used to solve problems involving constraints\nB) The algorithm will return an optimal solution\nC) The algorithm typically improves on the runtime performance of brute force\nD) The algorithm prunes partial solutions that cannot yield a valid solution\nE) None of the above\n22.4 TSP Heuristics\n861\nChapter 22 Exercise Solutions", "answer_embedding": null, "answer_confidence": null, "page_ids": ["a8bd50a1-a8c7-5431-824f-b2983d36f1ed"]}}
{"type": "unmatched_answer", "record": {"id": null, "qa_id": null, "book_id": "47bbcc23-9276-5662-9e40-96e8a4841ec7", "section_labels": ["solutions"], "section_titles": ["Exercise Solutions"], "pdf_page": 873, "problem_key": "8", "answer_number": 8, "answer_choice": "A", "answer_text": "Statement I is true: when solving a minimization problem using branch and bound, the upper bound is the\nbest solution encountered so far, so if the lower bound of extending the current branch is already worse than this upper bound, the branch\nshould be pruned. Statement II is false: when solving a maximization problem using branch and bound, the lower bound is the best solution\nencountered so far, so if the upper bound is greater than the lower bound, we could still find a better solution and the branch should not be\npruned (note that we are maximizing, so a higher upper bound is desired since that means the current branch could yield a larger solution\nthat the best we have encountered). Statement III is false: when solving a maximization problem, we want to overestimate the upper bound\nsince underestimating would cause us to believe that a branch may not yield an optimal solution even when it could.", "answer_embedding": null, "answer_confidence": null, "page_ids": ["e07bc6fe-0bb9-5892-9565-a839b6bcff01"]}}
{"type": "unmatched_answer", "record": {"id": null, "qa_id": null, "book_id": "47bbcc23-9276-5662-9e40-96e8a4841ec7", "section_labels": ["solutions"], "section_titles": ["Exercise Solutions"], "pdf_page": 873, "problem_key": "9", "answer_number": 9, "answer_choice": "D", "answer_text": "There are 4! = 24 distinct Hamiltonian cycles in the graph with four vertices, and 5! = 120 distinct Hamiltonian\ncycles in the graph with five vertices. Thus, there are 120 - 24 = 96 more Hamiltonian cycles in the graph with five vertices than the one\nwith four vertices.", "answer_embedding": null, "answer_confidence": null, "page_ids": ["e07bc6fe-0bb9-5892-9565-a839b6bcff01"]}}
{"type": "unmatched_answer", "record": {"id": null, "qa_id": null, "book_id": "47bbcc23-9276-5662-9e40-96e8a4841ec7", "section_labels": ["solutions"], "section_titles": ["Exercise Solutions"], "pdf_page": 873, "problem_key": "10", "answer_number": 10, "answer_choice": "D", "answer_text": "Backtracking can be used to solve constraint satisfaction problems, but it is not guaranteed to find an optimal\nsolution. Thus, it cannot be used to solve I, which is an optimization problem, but it can be used to solve II and III, which care only about\nthe existence of a solution rather than a best solution.", "answer_embedding": null, "answer_confidence": null, "page_ids": ["e07bc6fe-0bb9-5892-9565-a839b6bcff01"]}}
{"type": "unmatched_answer", "record": {"id": null, "qa_id": null, "book_id": "47bbcc23-9276-5662-9e40-96e8a4841ec7", "section_labels": ["solutions"], "section_titles": ["Exercise Solutions"], "pdf_page": 873, "problem_key": "11", "answer_number": 11, "answer_choice": "B", "answer_text": "Branch and bound can be used to find an optimal solution, while backtracking is designed to find the existence\nof a solution (and not necessarily the best). All the other choices apply to both backtracking and branch and bound.", "answer_embedding": null, "answer_confidence": null, "page_ids": ["e07bc6fe-0bb9-5892-9565-a839b6bcff01"]}}
{"type": "unmatched_answer", "record": {"id": null, "qa_id": null, "book_id": "47bbcc23-9276-5662-9e40-96e8a4841ec7", "section_labels": ["solutions"], "section_titles": ["Exercise Solutions"], "pdf_page": 873, "problem_key": "12", "answer_number": 12, "answer_choice": "A", "answer_text": "The current partial branch has a weight of 30 + 28 + 13 = 71, which is the same as the best complete solution\nfound so far. Since this partial branch already has a weight equal to a complete solution, there is no reason to continue extending this branch\n(since at best the outcome you get cannot go below 71), and the branch can be pruned.\n862\nChapter 22. Backtracking and Branch and Bound\n13. This is a constraint satisfaction problem that can be solved using a backtracking approach. Similar to examples 22.1 and 22.2, we will add\nvalues to a running collection, storing each output in the solution once it reaches a size of ğ‘˜. An implementation of this is shown below:\n1\nstd::vector<std::vector<int32_t>> k_combinations(int32_t int32_tn, k) {\n2\nstd::vector<std::vector<int32_t>> solution;\n3\nstd::vector<int32_t>());backtrack(n, k, 1, solution,\n4\nreturn solution;\n5\n} // k_combinations()\n6\n7\nvoid backtrack(int32_t int32_t int32_tn, k, start,\n8\nstd::vector<std::vector<int32_t>>& std::vector<int32_t>solution, current) {\n9\nif (k == 0) {\n10\nsolution.push_back(current);\n11\nreturn;\n12\n} // if\n13\nfor (int32_t i = start; i <= n; ++i) {\n14\ncurrent.push_back(i);\n15\nbacktrack(n, k - 1, i + 1, solution, current);\n16\ncurrent.pop_back();\n17\n} // for i\n18\n} // backtrack()\nWe can use a similar backtracking concept to solve this problem. We will iterate over all the characters of the input string and decide if we14.\ncan append each potential number to generate a valid IP. If we successfully added four numbers to our IP from the provided characters\nwithout pruning the solution, then we know that we have a valid IP. An implementation of this is shown below:\n1\nget_valid_ips(conststd::vector<std::string> std::string& digits) {\n2\nstd::vector<std::string> solution;\n3\nbacktrack(digits, \"\", 0, 0, solution);\n4\nreturn solution;\n5\n} // get_valid_ips()\n6\n7\nvoid backtrack(const size_t int32_tstd::string& digits, std::string curr_path, idx, num_parts,\n8\nstd::vector<std::string>& solution) {\n9\n// Can't have more than 4 numbers in an IP\n10\nif (num_parts > 4) {\n11\nreturn;\n12\n} // if\n13\n// This gets hit if we added exactly four numbers after processing all digits without pruning\n14\nif (num_parts == 4 && idx == digits.length()) {\n15\n// Remove trailing period\n16\ncurr_path.pop_back();\n17\nsolution.push_back(curr_path);\n18\nreturn;\n19\n} // if\n20\nfor (int32_t i = 1; i <= 3 && idx + i <= digits.length(); ++i) {\n21\nstd::string num = digits.substr(idx, i);\n22\n// Prune invalid solutions\n23\nif (num[0] == '0' && i != 1) {\n24\nbreak;\n25\n} // if\n26\nelse if (std::stoi(num) <= 255) {\n27\nbacktrack(digits, curr_path + digits.substr(idx, i) + \".\", idx + i, num_parts + 1, solution);\n28\n} // else if\n29\n} // for i\n30\n} // backtrack()\n15. To determine whether the placement of a bishop is promising, we just need to check if there are any other bishops in the diagonal directions\nrowfrom the provided position. If there are, then the solution is not promising. Since we know that only bishops up to row have been\nrowplaced, we only need to check the upper left and upper right diagonals (as there are no bishops below in the given board). One\nimplementation of this is shown below (note that this is similar to the N-Queens problem, but only checking the diagonals).\n1\nbool promising(const std::vector<std::vector<bool>>& size_t size_tboard, row, col) {\n2\nfor (size_t r = row, c = col; r-- > 0 && c-- > 0; ) {\n3\nif true)(board[r][c] == {\n4\nreturn false;\n5\n} // if\n6\n} // for r, c\n7\nfor (size_t r = row, c = col; r-- > 0 && c++ < board.size(); ) {\n8\nif true)(board[r][c] == {\n9\nreturn false;\n10\n} // if\n11\n} // for r, c\n12\nreturn true;\n13\n} // promising()\n864\nChapter 23. Dynamic Programming\nThere are many different problems that exhibit this type of behavior, where a recursive call may be called multiple times on the exact same input\nthroughout the lifetime of solving the problem. This is inefficient, since you are essentially computing the same thing multiple times (and each\nrecursive call is often quite expensive). This is where dynamic programming comes into play! The idea behind dynamic programming is to store\nline. In the context ofreusedthe solutions of each recursive call so that they can be whenever the same recursive call is needed later down the\nthe previous example, this is equivalent to \"remembering\" your position in line so that you donâ€™t have to re-ask for it if you ever need it again.\nÂ¸ 23.1.2\nFibonacci Numbers\nTo begin our exploration of dynamic programming, letâ€™s first take a look at one of the most common problems involving recursion: computing\nFibonacci numbers.\nğ‘›thExample 23.1 n, fib(n)Given a positive integer write a function that returns the number in the Fibonacci sequence: 0, 1, 1, 2, 3, 5,\nfib(0) = 0, fib(1) = 1,8, 13, 21, ..., where and every subsequent number is the sum of the previous two numbers in the sequence.\nğ‘›thn,A recurrence relation for this problem can be derived in a straightforward manner: given any integer we can obtain the Fibonacci number\nfib(n-1) fib(n-2).by simply summing up and\nğ‘“ğ‘–ğ‘(ğ‘›)=\nâ§\nâª\nâ¨\nâªâ©\n0,\nif ğ‘›=0\n1,\nif ğ‘›=1\nğ‘“ğ‘–ğ‘(ğ‘›âˆ’1)+ğ‘“ğ‘–ğ‘(ğ‘›âˆ’2),\nif ğ‘›>1\nConverting this recurrence relation to code, we get:\n1\nuint64_t fib(int32_t n) {\n2\nif return(n == 0) 0;\n3\nif return(n == 1) 1;\n4\nreturn fib(n - 1) + fib(n - 2);\n5\n} // fib()\nn,If we run this function using small values of we are able to get the correct solution in a reasonable amount of time. However, if we were to try\nn = 50),it with a larger number (such as the function would take forever to run. To understand why this happens, letâ€™s take a look at exactly\nfib() fib() n = 6:what is happening when is called. The following tree depicts every recursive call that is made when is invoked with\nfib(6)\nfib(4)\nfib(2)\nfib(0)\nfib(1)\nfib(3)\nfib(1)\nfib(2)\nfib(0)\nfib(1)\nfib(5)\nfib(3)\nfib(1)\nfib(2)\nfib(0)\nfib(1)\nfib(4)\nfib(2)\nfib(0)\nfib(1)\nfib(3)\nfib(1)\nfib(2)\nfib(0)\nfib(1)\nAt each node of the tree, we make two recursive calls and add up their return values, where each addition requires a constant amount of work.\nğ‘‚(2ğ‘›) ğ‘‚(2ğ‘›).fib(n)Since there are a total of nodes in the tree, the total work required to solve for can thus be represented as This is why the\ninputs!2 fib()function takes forever to run on larger Additionally, since is not tail recursive and has a recursion depth of ğ‘›, the auxiliary\nspace required by this recursive implementation is Î˜(ğ‘›).\nToreturntheFibonaccinumberforalargevalueofğ‘›inareasonableamountoftime, wewillneedtoreduceouralgorithmâ€™stimecomplexity.\nTo do so, we can either reduce the number of recursive calls we make, or we can reduce the amount of work that is done at each recursive\ncall. Since each recursive call only performs a single addition operation, we cannot further reduce the work that is done at each recursive call.\nTherefore, our only option is to reduce the number of recursive calls that we make.\n2This fib(n)actuallyisnâ€™tthetightestpossibleboundforthethisrecursive function,astheFibonaccisequencehasaclosedformsolutionof\nğ‘“ğ‘–ğ‘(ğ‘›)=\n1\nâˆš\n5\n(\n1+\nâˆš\n5\n2\n)ğ‘›\nâˆ’1\nâˆš\n5\n(\n1âˆ’\nâˆš\n5\n2\n)ğ‘›\nwhichisÎ˜((1+\nâˆš\n5)âˆ•2)ğ‘›)â‰ˆÎ˜(1.618ğ‘›). ğ‘‚(2ğ‘›)Visually,youcanseetheactualtimecomplexityisslightlybetterthan sinceonesideofthetreeisalwayslarger\nthantheotherbecausethetworecursivecallsarenotthesamesize. Alsoyes,youcouldtechnicallywritea solutionusingthisclosed-formsolution,butÎ˜(1)\nthatisbesidethepointsincethisisnâ€™tsomethingwewouldreasonablyexpectyoutodointhisclass.\n23.1 Foundations of Dynamic Programming\n865\nUpon closer inspection of the recursion tree, there is a major issue with our naÃ¯ve recursive approach: several identical recursive calls are\nfib(6) fib(4)completed once. For example, a single call to ends up calling twice before it returns.more than\nfib(6)\nfib(4)\nfib(2)\nfib(0)\nfib(1)\nfib(3)\nfib(1)\nfib(2)\nfib(0)\nfib(1)\nfib(5)\nfib(3)\nfib(1)\nfib(2)\nfib(0)\nfib(1)\nfib(4)\nfib(2)\nfib(0)\nfib(1)\nfib(3)\nfib(1)\nfib(2)\nfib(0)\nfib(1)\nfib(3) fib(2)Similarly, is called three times, and five times. However, these additional calls are pointless, since you already know the\nsolutions of these recursive calls. For larger values of ğ‘›, this replicated work can end up being quite wasteful! It would be nice if our program\ncould remember which recursive calls it has already made so that it never duplicates any work.\nThis is where the strategy of dynamic programming comes into play. When solving a problem using dynamic programming, you want to\nstore the solutions to all the subproblems you encounter in a fast-access data structure such as a vector or a hash table. This container is known\nas a memo, which maps the of each subproblem to the solution of that subproblem. That way, if you ever encounter the sameinput arguments\nsubproblem more than once, you can quickly retrieve its solution by using its input arguments to reference your memo. Forin constant time\nfib(4) memo[4] = 3).example, the solution of is 3, so your dynamic programming memo should map the input to the output 3 (i.e.,ğ‘›=4\nTypically, the dimensions of a memo should correspond to the number of arguments that are required to uniquely identify each subproblem\nor recursive call. In the Fibonacci example, each recursive call only accepts a single argument ğ‘›, so our memo will be one-dimensional based on\nthe value of ğ‘›. However, there will be problems where a recurrence relation may involve multiple inputs within a single recursive call â€” for\nexample, given the recurrence ğ¹(ğ‘šâˆ’1,ğ‘›)+ğ¹(ğ‘š,ğ‘›âˆ’1), your memo would need to be two-dimensional, one dimension for ğ‘šand theğ¹(ğ‘š,ğ‘›)=\nother for ğ‘›. That way, your memo will be large enough to support all possible input combinations up to ğ‘šand ğ‘›. We will look at some examples\nthat require multidimensional memos later in this chapter.\nFirst, letâ€™s analyze the dynamic programming solution for the Fibonacci problem, with initial input size 6. To start, we want to initializeğ‘›=\nfib(0) fib(n).a memo that can be used to store the solutions to all subproblems we encounter, from to This can be done using a vector of\ni fib(i). fib(0) fib(1)size 7, where each index stores the value of We know that and are equal to 0 and 1, so we can fill out these\nvalues in the memo immediately (or directly return them in our recursive function).\nmemo\n0\n1\n0\n1\n2\n3\n4\n5\n6\nfib(6). memo[6] fib(6)We start by making a recursive call to is currently uninitialized, which indicates that we have never called before,\nfib(6). fib(5).so we make a recursive call to This recursive call then makes a call to\nfib(6)\nfib(5)\nmemo\n0\n1\n0\n1\n2\n3\n4\n5\n6\nmemo[5] fib(5) fib(5), fib(4).is uninitialized, so we havenâ€™t called before. We make a recursive call to which calls\nfib(6)\nfib(5)\nfib(4)\nmemo\n0\n1\n0\n1\n2\n3\n4\n5\n6\n868\nChapter 23. Dynamic Programming\nThe shaded nodes of the previous tree represent recursive calls we were able to trivially solve, either from returning a base case or from pulling\na solution directly from the memo. By getting rid of duplicate recursive calls, we were able to bring the time complexity down from exponential\nfib(0) fib(1)to linear. The code for this dynamic programming implementation is shown below. Since we already know that and return 0\nand 1, we can initialize them in the memo immediately. We then call a helper function that performs the work of solving each subproblem and\nstoring its solution in the memo.\n1\nuint64_t fib(int32_t n) {\n2\nstd::vector<uint64_t> memo(n + 1);\n3\nreturn fib_helper(n, memo);\n4\n} // fib()\n5\n6\nuint64_t fib_helper(int32_t std::vector<uint64_t>&n, memo) {\n7\nif (n == 0 || n == 1) {\n8\nreturn n;\n9\n} // if\n10\nif (memo[n] != 0) { // already solved before, fetch from memo\n11\nreturn memo[n];\n12\n} // else if\n13\n// solve and store in memo\n14\nreturn memo[n] = fib_helper(n - 1, memo) + fib_helper(n - 2, memo);\n15\n} // fib_helper()\nÂ¸ 23.1.3\nTop-Down and Bottom-Up Dynamic Programming\nThis process of storing the results of recursive calls so that they can be used later is formally known as memoization. Memoization can often be\nimplemented without significant changes to an existing recursive solution. To memoize a recursive function:\nâ€¢ On function entry:\n1. Query the memo using the function input(s) to determine if a recursive call has been made on that input before.\n2. If the input has been called before, retrieve the result from the memo instead of recomputing with a recursive call.\nâ€¢ On function exit:\n1. Save the result of the recursive call in the memo, in the position corresponding to the function input(s).\nThus, memoization solutions often exhibit a structure similar to a naÃ¯ve recursive approach, as shown below in pseudocode:\n1\nfunction dp_helper(dp_state, memo):\n2\nif dp_state is a base case:\n3\nreturn base case solution\n4\nif dp_state in memo:\n5\nreturn memo[dp_state]\n6\ncalculate solution for dp_state using recursive calls\n7\nsave the solution for dp_state in memo\n8\nreturn solution for dp_state\n9\n10\nfunction solve_original_problem(input):\n11\ninitialize memo\n12\nreturn dp(starting_state, memo)\nSofar,wehavediscussedtherecursivememoizationstrategyforsolvingdynamicprogrammingproblems. However,thisisnotthesoleapproach:\nfib(6),you can avoid recursion by precomputing the entire memo at the beginning of the algorithm! For example, if you are asked to compute\nyou could simply precompute all Fibonacci numbers up to the sixth Fibonacci number and then return its value. This method achieves the same\nlinear time complexity as the previous approach, and it is implemented rather than recursively. The code is shown below:iteratively\n1\nuint64_t fib(int32_t n) {\n2\nstd::vector<uint64_t> memo(n + 1);\n3\nmemo[0] = 0;\n4\nmemo[1] = 1;\n5\nfor (size_t i = 2; i <= n; ++i) {\n6\nmemo[i] = memo[i - 1] + memo[i - 2];\n7\n} // for i\n8\nreturn memo[n];\n9\n} // fib()\nThis process of starting at the smallest possible subproblem and building upward toward a solution is known as tabulation. Both memoization\nand tabulation are valid approaches for solving a dynamic programming problem! The main difference between the two approaches is in how\nthe subproblems are computed along the way. With memoization, you start with the inputs of the original problem and make your way down to\nthe smallest subproblems using recursive calls. With tabulation, you start from the smallest subproblems and use their solutions to build upward\nsolve.3toward the original problem you are trying to In both cases, the solutions of intermediate subproblems are stored in a memo so that they\ncan be referenced later.\n3Note: ifyouusetabulation,youmustmakesureyouaresolvingthesubproblemsinthecorrectorder,sothateachsubproblemâ€™sdependenciesareallsolved\nbeforethesubproblemitself. Thismayrequireyoutoiterateoverthememoinaspecificway,whichmaynotalwaysbeobvious!\n23.1 Foundations of Dynamic Programming\n869\nFormally, dynamic programming that involves recursion and memoization falls into the category of top-down dynamic programming, while\ndynamic programming that involves iteration and tabulation falls into the category of bottom-up dynamic programming. The top-down\napproach starts with the original problem and divides the input into smaller subproblems that are solved recursively, while the bottom-up\napproach starts by solving the smallest subproblems and uses these solutions to solve for larger subproblems, eventually reaching the solution\nof the original problem. If a problem can be solved using top-down dynamic programming, it can also be solved using bottom-up dynamic\nprogramming (and vice versa), and choosing one over the other is often a matter of preference.\nThere are a few minor differences between the two approaches. Top-down dynamic programming only computes subproblems that are\nneeded, since a result is only stored in the memo if a recursive call has already been made on its input. On the other hand, bottom-up dynamic\nprogramming precomputes possible subproblems, so it may solve for subproblems that are never used. That being said, this does not meanall\nthat top-down is always better. For instance, a top-down approach is more likely to stack overflow for large inputs compared to a bottom-up\napproach, since it relies on recursion rather than iteration. A top-down approach may also prevent you from reusing positions of the memo for\nmultiple subproblems to reduce memory usage (which we will discuss in section 23.8). Furthermore, one implementation may be easier or\ncleaner to write than the other depending on the type of problem you are trying to solve.\nThe performance of these two approaches also depends on the problem at hand. Bottom-up implementations are more cache-friendly\nand perform slightly better than top-down in many cases, since querying a precomputed table is often faster than making a recursive call and\nencountered.4conditionally checking a memo for every subproblem However, if the number of relevant subproblems only comprise a small\nportion of the overall output space, top-down may be faster than bottom-up if the cost of precomputing all possible subproblems exceeds the\ncost of making recursive calls only on the subproblems that matter.\nÂ¸ 23.1.4\nBinomial Coeï¬ƒcients\nAs another example, letâ€™s look at the problem, which depends on two inputs in its recurrence relation rather than one. Inbinomial coefficient\n(ğ‘›mathematics, we define the binomial coefficient\nğ‘˜\n) as the number of ways to choose ğ‘˜unordered outcomes out of ğ‘›possibilities, defined as\nfollows for non-negative integers ğ‘›and ğ‘˜:\n(ğ‘›\nğ‘˜\n)=\nğ‘›!\nğ‘˜!(ğ‘›âˆ’ğ‘˜)!\nğ‘›â‰¥ğ‘˜,Example 23.2 bi_coeff(n, k)Given two non-negative integers ğ‘›and ğ‘˜, where implement a function that returns the binomial\n(ğ‘›coefficient\nğ‘˜\n).\n(ğ‘›One way to approach this problem is to calculate ğ‘›!, ğ‘˜!, and (ğ‘›âˆ’ğ‘˜)!, and then use these values to solve for\nğ‘˜\n). However, this doesnâ€™t always\nwork, since factorials can get quite large: integer overflow becomes an issue when for 32-bit integers, and for 64-bit integers.ğ‘›> ğ‘›>12 20\nInstead, a better way would be to use the definition of the binomial coefficient formula, shown below (this should have been covered inrecursive\nEECS 203, but we wonâ€™t expect you to derive anything like this on your own):\n(ğ‘›\nğ‘˜\n) (ğ‘›âˆ’1=\nğ‘˜âˆ’1\n)+(ğ‘›âˆ’1\nğ‘˜\n)\n(ğ‘›\n0\n)=1\n(ğ‘›\nğ‘›\n)=1\nConverting this to a recursive function, we would get the following:\n1\nuint64_t bi_coeff(int32_t int32_tn, k) {\n2\nif (k == 0 || k == n) {\n3\nreturn 1;\n4\n} // if\n5\nreturn bi_coeff(n - 1, k - 1) + bi_coeff(n - 1, k);\n6\n} // bi_coeff()\n(7However, this implementation is not fully efficient since there are duplicate subproblems. This is shown below for\n4\n):\n(7\n4\n)\n(6\n4\n)\n(5\n4\n)\n(4\n4\n)\n(4\n3\n)\n(3\n3\n)\n(3\n2\n)\n(2\n2\n)\n(2\n1\n)\n(5\n3\n)\n(4\n3\n)\n(3\n3\n)\n(3\n2\n)\n(2\n2\n)\n(2\n1\n)\n(4\n2\n)\n(3\n2\n)\n(2\n2\n)\n(2\n1\n)\n(3\n1\n)\n(6\n3\n)\n(5\n3\n)\n(4\n3\n)\n(3\n3\n)\n(3\n2\n)\n(2\n2\n)\n(2\n1\n)\n(4\n2\n)\n(3\n2\n)\n(2\n2\n)\n(2\n1\n)\n(3\n1\n)\n(5\n2\n)\n(4\n2\n)\n(3\n2\n)\n(2\n2\n)\n(2\n1\n)\n(3\n1\n)\n(4\n1\n)\n4Note: wearetalkingaboutactualruntimehere,and timecomplexity.not\n870\nChapter 23. Dynamic Programming\nTo avoid repeating recursive calls that have already been made, we can use dynamic programming and store the solutions of these subproblems\nin a memo. In this case, each subproblem is identified using two input values, ğ‘›and ğ‘˜, so our memo will need to be two-dimensional with size\n(ğ‘›to support all possible subproblems. An example of a suitable memo is shown below: here, the solution toÎ˜(ğ‘›ğ‘˜)\nğ‘˜\n) for any valid ğ‘›and ğ‘˜is\nstored in row ğ‘›, column ğ‘˜.\n0\n1\n2\n3\n4\n0\n1\n2\n3\n4\n5\n6\n7\nğ‘˜\nğ‘›\n(ğ‘›We know that\n0\n) (ğ‘›and\nğ‘›\n) are both equal to 1 from the base case, so we can fill out their corresponding cells immediately (or return 1 in our\nrecursive helper function if any of these base cases are reached):\n0\n1\n2\n3\n4\n0\n1\n1\n1\n1\n2\n1\n1\n3\n1\n1\n4\n1\n1\n5\n1\n6\n1\n7\n1\nğ‘˜\nğ‘›\nIf we use a top-down dynamic programming approach, we would take our original recursive function and add a memo to keep track of\nsubproblems we have encountered before. A top-down solution is shown below:\n1\nuint64_t bi_coeff(int32_t int32_tn, k) {\n2\nstd::vector<std::vector<uint64_t>> std::vector<uint64_t>(kmemo(n + 1, + 1));\n3\nreturn bi_coeff_helper(n, k, memo);\n4\n} // bi_coeff()\n5\n6\nuint64_t bi_coeff_helper(int32_t int32_t std::vector<std::vector<uint64_t>>&n, k, memo) {\n7\nif (k == 0 || n == k) {\n8\nreturn 1;\n9\n} // if\n10\nif (memo[n][k] != 0) { // recursive call made on (n, k) already\n11\nreturn memo[n][k];\n12\n} // if\n13\n// solve and store in memo\n14\nreturn memo[n][k] = bi_coeff_helper(n - 1, k - 1, memo) + bi_coeff_helper(n - 1, k, memo);\n15\n} // bi_coeff_helper()\nIf we use a bottom-up dynamic programming approach, we would loop over our memo and precompute all subproblems up to our original input.\nTo implement this, we begin by looking at the smaller subproblems (e.g., the base cases), and then solving for the larger subproblems using\n(1the solutions we compute from the smaller subproblems. For example, we know that\n0\n) (1and\n1\n) are both equal to 1. Thus, we can solve for\n(2\n1\n) (1=\n0\n)+(1\n1\n) (22. Then, we can use the solution of=1+1=\n1\n)\n(3to solve for\n1\n)\n(3and\n2\n)\n(4, which we can use to solve for\n1\n)\n(4,\n2\n)\n(4,\n3\n)\n, and so on,\n(ğ‘›until we eventually obtain the solution for\nğ‘˜\n). The code for a bottom-up solution is shown below.\n1\nuint64_t bi_coeff(int32_t int32_tn, k) {\n2\nstd::vector<std::vector<uint64_t>>\n3\nstd::vector<uint64_t>(kmemo(n + 1, + 1));\n4\nfor (int32_t curr_n = 0; curr_n <= n; ++curr_n) {\n5\nfor (int32_t curr_k = 0; curr_k <= std::min(curr_n, k); ++curr_k) {\n6\nif (curr_n == curr_k || curr_k == 0) {\n7\nmemo[curr_n][curr_k] = 1;\n8\n} // if\n9\nelse {\n10\nmemo[curr_n][curr_k] = memo[curr_n - 1][curr_k - 1] + memo[curr_n - 1][curr_k];\n11\n} // else\n12\n} // for curr_k\n13\n} // for curr_n\n14\nreturn memo[n][k];\n15\n} // bi_coeff()\n23.2 Dynamic Programming Implementation Strategies\n871\nBy storing the solutions of repeated subproblems in a memo, we only need to solve each subproblem once, regardless of how many times it is\nneeded. Since there are only subproblems we may encounter given values ğ‘›and ğ‘˜, and each subproblem takes a constant amount of timeÎ˜(ğ‘›ğ‘˜)\nto solve, the worst-case time complexity of a dynamic programming approach is Î˜(ğ‘›ğ‘˜). Furthermore, since we used a memo with dimensions\n(ğ‘›+1)Ã—(ğ‘˜+1), the auxiliary space used by our solution is also Î˜(ğ‘›ğ‘˜).\n23.2\nDynamic Programming Implementation Strategies\nIn general, dynamic programming is useful for problems that exhibit the following characteristics:\n1. Optimal substructure. A problem with an optimal substructure is one whose solution can be constructed using the optimal solutions of\nits smaller subproblems. If a problem has optimal substructure, the correct solution for some input size ğ‘›can be computed by simply\nreferencing the solutions of subproblems with input size less than ğ‘›.\n2. Overlapping subproblems. A problem exhibits the property of overlapping subproblems if multiple instances of the same subproblem\nare encountered while recursively decomposing the original problem down to its base cases.\nFor example, the Fibonacci problem exhibits both optimal substructure and overlapping subproblems. If we know the values of andğ‘“ğ‘–ğ‘(ğ‘›âˆ’2)\nfor any ğ‘›, we can immediately use their solutions to compute the value of ğ‘“ğ‘–ğ‘(ğ‘›). In addition, if we recursively break any input downğ‘“ğ‘–ğ‘(ğ‘›âˆ’1)\nto its base case, we can see that multiple identical subproblems appear more than once.\nfib(n)\nfib(n-2)\nfib(n-4)\nfib(n-6)\n...\n...\nfib(n-5)\n...\n...\nfib(n-3)\nfib(n-5)\n...\n...\nfib(n-4)\n...\n...\nfib(n-1)\nfib(n-3)\nfib(n-5)\n...\n...\nfib(n-4)\n...\n...\nfib(n-2)\nfib(n-4)\n...\n...\nfib(n-3)\n...\n...\nThe existence of overlapping subproblems is important to have! A common misconception is that dynamic programming can be used to\nimprove the performance of any recusive algorithm. This is not true: for dynamic programming to be beneficial, there must exist overlapping\nsubproblems that recur multiple times over the course of solving a problem. If the subproblems can be solved independently without any overlap,\nthere is no need to store their solutions in a memo since you will never need them more than once (for these problems, an approach such as\ndivide-and-conquer may be more applicable). Only when there exist does a memo become useful in significantlydependent subproblems\nalgorithm.5improving the performance of an\nIdentifying and solving a dynamic programming problem can be challenging at times, but this is a topic that can be mastered with practice.\nAt the end of the day, the goal of dynamic programming is the same regardless of what type of problem you are working with: you want to (1)\nbreak a larger problem into a collection of smaller subproblems, (2) solve each of these smaller subproblems and store their solutions in aonce\nmemo, and (3) use these solutions to compute the solution of the original problem, either in a top-down (recursive) or bottom-up (iterative)\nmanner. The procedure for solving a dynamic programming problem can be roughly summarized using the following steps:\n1. Verify that the problem you are solving can be broken up into smaller subproblems.\nTo determine if dynamic programming can be efficiently used to solve a problem, first ask yourself if the problem you are trying to solve can\nbe problem. That is, if you had the solutions of the problem on smaller input,expressed using the solutions of smaller instances of the same\ncan you use those solutions to help you calculate the solution on a larger input? If you can, then the problem has an optimal substructure, and\ndynamic programming may be viable approach.\n2. Identify the problem variables that each subproblem depends on.\nNext, determine the input variables that uniquely identify each subproblem; this will allow you to identify the number of subproblems you may\nneed to solve, and therefore the size of your memo. For example, the subproblems of the Fibonacci problem depend on the value of ğ‘›, while the\nsubproblems of the binomial coefficient problem depend on the values of ğ‘›and ğ‘˜. Therefore, there are potentially subproblems that youÎ˜(ğ‘›)\nneed to solve for the Fibonacci problem, and subproblems that you need to solve for the binomial coefficient problem. You only want toÎ˜(ğ‘›ğ‘˜)\nfocus on the variables that among the subproblems you may encounter â€” if a variable never changes across all subproblems, then itdiffer\ndoesnâ€™t affect the number of subproblems you may need to solve.\n5Theterm\"dependent\"hereindicatesthattheprocessofsolvingonesubproblemmaydependonasolutionthatwasalreadysolvedbyanothersubproblem,and\nthatthetwosubproblemsshareresourcesorneedtobesolvedtogether.not\n872\nChapter 23. Dynamic Programming\n3. Express the problem in the form of a recurrence relation.\nUse the information from the previous two steps to express the problem in the form of a recurrence relation, including all the base cases. This is\nOncean important step that you should complete before you begin writing any code, since it will make implementation significantly easier!\nyou have identified how the subproblems relate to each other, the recurrence relation should come naturally: simply write an expression that\ndescribes how several smaller subproblems can be combined to compute the solution of the larger problem you are trying to solve.\nFor example, we know that 0, 1, and that and can be summed to obtain the value of ğ‘“ğ‘–ğ‘(ğ‘›). Therefore,ğ‘“ğ‘–ğ‘(0) ğ‘“ğ‘–ğ‘(1) ğ‘“ğ‘–ğ‘(ğ‘›âˆ’2) ğ‘“ğ‘–ğ‘(ğ‘›âˆ’1)= =\nwe would express the Fibonacci problem using the following recurrence relation:\nğ‘“ğ‘–ğ‘(ğ‘›)=\nâ§\nâª\nâ¨\nâªâ©\n0,\nif ğ‘›=0\n1,\nif ğ‘›=1\nğ‘“ğ‘–ğ‘(ğ‘›âˆ’1)+ğ‘“ğ‘–ğ‘(ğ‘›âˆ’2),\nif ğ‘›>1\nForthebinomialcoefficientproblem,weknowthat and arebothequalto1,andthat isthesumofğ¶(ğ‘›âˆ’1,ğ‘˜âˆ’1)+ğ¶(ğ‘›âˆ’1,ğ‘˜).ğ¶(ğ‘›,0) ğ¶(ğ‘›,ğ‘›) ğ¶(ğ‘›,ğ‘˜)\nThus, we would express the binomial coefficient problem using the following recurrence relation:\nğ¶(ğ‘›,ğ‘˜)=\nâ§\nâª\nâ¨\nâªâ©\n1,\nif ğ‘˜=0\n1,\nif ğ‘›=ğ‘˜\nğ¶(ğ‘›âˆ’1,ğ‘˜âˆ’1)+ğ¶(ğ‘›âˆ’1,ğ‘˜),\nif ğ‘›>ğ‘˜\n4. Identify the overlapping subproblems.\nFor dynamic programming to be useful, we want there to be overlapping subproblems. Therefore, it is always good to check your recurrence\nrelation to see if duplicate subproblems actually exist (a good way to do this is to draw out a recurrence tree, like the one on the previous page,\nand look for subproblems that appear multiple times). If they donâ€™t exist, then dynamic programming may not be the best approach to use, and\nan alternative approach such as divide-and-conquer should be considered instead.\n5. Convert the recurrence relation into code, using either a top-down (recursive) or bottom-up (iterative) approach.\nOnce you have identified the recurrence relation, convert it into code using either a top-down or bottom-up approach. If you decide to use\na top-down approach, start by writing a straightforward recursive solution that solves for relevant subproblems using recursive calls. Then,\nadd memoization to prevent the same subproblem from being computed twice â€” this is done by storing the solutions of recursive calls in a\nmemo so that they can be easily retrieved later when they are needed again. If you decide to use a bottom-up approach, start with the base cases\nof the problem and use the recursive relationship of the problem to build upward toward the original input size you are trying to solve. Each\nintermediary subproblem you encounter is stored in a memo so that it can be quickly referenced later while solving for larger subproblems.\nRegardless of how you approach a dynamic programming problem, the core component of any solution revolves around the memo, which stores\nthe solutions of overlapping subproblems so that they donâ€™t have to be solved more than once. By using a bit of additional memory to store these\nsubproblems, dynamic programming can greatly reduce the runtime of a recursive function! Over the next few sections, we will look at a few\nexamples of problems that can be solved using dynamic programming.\n23.3\nCommon Dynamic Programming Patterns\nÂ¸ 23.3.1\nCounting Distinct Ways\nThere are several common categories of problems that can be efficiently solved using dynamic programming. One common problem you might\nsee involves to get to some target value or state, given a set of rules that you must follow to reach thatcounting the number of distinct ways\ntarget. These problem types often exhibit both the optimal substructure and overlapping subproblems that make dynamic programming useful.\nTo see why, consider the following example. Suppose you want to get to some state ğ¶, which is accessible from states ğ´and ğµ. There are 5\ndistinct ways to get to state ğ´, and 10 distinct ways to get to state ğµ. Knowing this, how many distinct ways are there to get to state ğ¶?\nA\nB\nC\n5\n10\nThe answer is pretty straightforward: since there are 5 ways to get to state ğ´and 10 ways to get to state ğµ, the total number of ways to get to\nstate ğ¶must be 5 + 10 = 15, since ğ¶can only be reached from ğ´or ğµ. This simple example can actually be generalized to any state, allowing\nus to conceptualize a recurrence relation for any problem that fits this pattern. To solve problems that ask you to count the distinct number of\nit. That is, if you wanted to countways to reach some target state, you should sum up all the possible ways to reach states that directly precede\nthe number of ways to reach some target state ğ¶, and you can get to ğ¶from either ğ´or ğµ, then the number of ways to get to ğ¶is equal to the\nsum of the number of ways to get to ğ´and ğµ. We will look at a few examples of this pattern in this section.\n23.3 Common Dynamic Programming Patterns\n873\nExample 23.3 You are located at the top-left corner of a ğ‘šÃ—ğ‘›grid, and you want to reach the bottom-right corner. However, you are only\nallowed to move or at any point in time. Write a function that takes in ğ‘šand ğ‘›and returns the total number of paths youdown right unique\ncan take to reach the bottom-right corner of the grid.\nExample: Given the following grid, there are three unique paths that you can take to reach the bottom-right corner:2Ã—3\n1. down, right, right\n2. right, down, right\n3. right, right, down\nâ˜…\nThe key detail to notice here is that there are only two ways for you to reach the target square: either by moving down from the square directly\nabove, or by moving right from the square directly to the left. Thus, if we know there are ğ‘¥ways to reach the square directly above, and ğ‘¦ways\nto reach the square directly to the left, then there must be ğ‘¥+ğ‘¦ways to reach the target square.\nğ‘¥\nğ‘¦\nğ‘¥+ğ‘¦\nThus, given any square at (row ğ‘Ÿ, column ğ‘) of the grid, we can calculate the number of ways to reach this square by recursively computing the\nnumber of ways to get to (row ğ‘Ÿâˆ’1, column ğ‘) and (row ğ‘Ÿ, column ğ‘âˆ’1), and then summing up these two values. The base case is our starting\nposition at (row 1, column 1), which we can trivially reach in exactly one way. There are also zero ways to reach any out-of-bounds square. This\ngives us the following recurrence relation ğ¹(ğ‘Ÿ,ğ‘), which represents the total number of ways to reach the square in (row ğ‘Ÿ, column ğ‘):\nğ¹(ğ‘Ÿ,ğ‘)=\nâ§\nâª\nâ¨\nâªâ©\n1,\nif andğ‘Ÿ= ğ‘=1 1\n0,\nif or (out-of-bounds)ğ‘Ÿ< ğ‘<1 1\nğ¹(ğ‘Ÿâˆ’1,ğ‘)+ğ¹(ğ‘Ÿ,ğ‘âˆ’1),\notherwise\nIf we draw out the recursion tree, we would see that there are overlapping subproblems:\nğ¹(ğ‘Ÿ,ğ‘)\nğ¹(ğ‘Ÿ,ğ‘âˆ’1)\nğ¹(ğ‘Ÿ,ğ‘âˆ’2)\nğ¹(ğ‘Ÿ,ğ‘âˆ’3)\n...\n...\nğ¹(ğ‘Ÿâˆ’1,ğ‘âˆ’2)\n...\n...\nğ¹(ğ‘Ÿâˆ’1,ğ‘âˆ’1)\nğ¹(ğ‘Ÿâˆ’1,ğ‘âˆ’2)\n...\n...\nğ¹(ğ‘Ÿâˆ’2,ğ‘âˆ’1)\n...\n...\nğ¹(ğ‘Ÿâˆ’1,ğ‘)\nğ¹(ğ‘Ÿâˆ’1,ğ‘âˆ’1)\nğ¹(ğ‘Ÿâˆ’1,ğ‘âˆ’2)\n...\n...\nğ¹(ğ‘Ÿâˆ’2,ğ‘âˆ’1)\n...\n...\nğ¹(ğ‘Ÿâˆ’2,ğ‘)\nğ¹(ğ‘Ÿâˆ’2,ğ‘âˆ’1)\n...\n...\nğ¹(ğ‘Ÿâˆ’3,ğ‘)\n...\n...\nThus, dynamic programming can be used to solve this problem. Each subproblem is identified using two variables, the row and column, so we\nwill initialize a ğ‘šÃ—ğ‘›memo of integers to store the solutions of subproblems we encounter (where the solution to for any (ğ‘Ÿ, ğ‘) is storedğ¹(ğ‘Ÿ,ğ‘)\nmemo[r][c]).at position If we use a top-down approach to solve this problem, we would make recursive calls on and per(ğ‘Ÿâˆ’1,ğ‘) (ğ‘Ÿ,ğ‘âˆ’1)\nthe recurrence relation above, but we will check the memo before every recursive call to determine if the call has been made before. If the call\nhas been made before, we just fetch its solution from the memo; otherwise, we make the recursive call and write the solution to the memo.\n874\nChapter 23. Dynamic Programming\nbelow:6The code for a top-down solution is shown\n1\nint32_t count_paths(int32_t int32_tm, n) {\n2\nstd::vector<std::vector<int32_t>> std::vector<int32_t>(nmemo(m + 1, + 1));\n3\nreturn count_paths_helper(m, n, memo);\n4\n} // count_paths()\n5\n6\nint32_t count_paths_helper(int32_t int32_t std::vector<std::vector<int32_t>>&r, c, memo) {\n7\nif (r == 1 && c == 1) { // base case\n8\nreturn 1;\n9\n} // if\n10\nif (r < 1 || c < 1) { // out-of-bounds\n11\nreturn 0;\n12\n} // if\n13\nif (memo[r][c] != 0) { // recursive call made before, fetch from memo\n14\nreturn memo[r][c];\n15\n} // if\n16\n// solve and store in memo\n17\nreturn memo[r][c] = count_paths_helper(r - 1, c, memo) + count_paths_helper(r, c - 1, memo);\n18\n} // count_paths_helper()\nIf we use a bottom-up approach, we would start with the base cases and build upward toward the solution using the relationships between\nsubproblems. Here, we know that 1, so we can use that to compute that and ğ¹(2,1), which can be used to compute ğ¹(2,2),ğ¹(1,1) ğ¹(1,2)=\nand so on, until we reach ğ¹(ğ‘š,ğ‘›). The code for a bottom-up solution is shown below.\n1\nint32_t count_paths(int32_t int32_tm, n) {\n2\nstd::vector<std::vector<int32_t>> std::vector<int32_t>(nmemo(m + 1, + 1, 1));\n3\nfor (int32_t r = 2; r <= m; ++r) {\n4\nfor (int32_t c = 2; c <= n; ++c) {\n5\nmemo[r][c] = memo[r - 1][c] + memo[r][c - 1];\n6\n} // for c\n7\n} // for r\n8\nreturn memo[m][n];\n9\n} // count_paths()\nSince there are a total of subproblems that we may encounter, and each subproblem is solved only once in constant time with the help ofÎ˜(ğ‘šğ‘›)\nthe memo (i.e., add up two values), the time complexity of the above dynamic programming solution is Î˜(ğ‘šğ‘›). Similarly, since a memo of size\nis used, the auxiliary space used by the implementation is also Î˜(ğ‘šğ‘›).Î˜(ğ‘šğ‘›)\nExample 23.4 You are climbing a staircase requiring ğ‘›steps to reach the top. Write a function that takes in the number of steps ğ‘›and\nreturns the number of distinct ways you climb the stairs, if you can only climb either 1 or 2 steps at any point in time.\nSimilar to the previous problem, the number of ways to reach the top of the staircase is dependent on the number of ways to reach the steps\nğ‘›thdirectly below it. In this case, we can reach the step from either the step directly below it (by climbing one step) or two steps below it (by\nclimbing two steps). Thus, if there are ğ‘¥ways to reach the step at position and ğ‘¦ways to reach the step at position ğ‘›âˆ’1, then there must beğ‘›âˆ’2\nğ‘¥+ğ‘¦ways to reach the step at position ğ‘›. The base cases occur when and 1, which both have a solution of 1 (there is only one way toğ‘›= ğ‘›=0\nreach the top of the stairs if the staircase only consists of one step, or if there are no stairs at all).\nğ‘¥+ğ‘¦\nğ‘¦\nğ‘¥\nSince this problem can be defined in terms of solutions to smaller subproblems, we can express the problem using the following recurrence\nğ‘–threlation, where represents the number of ways to reach the step:ğ¹(ğ‘–)\nğ¹(ğ‘–)=\n{\n1,\nif orğ‘–= ğ‘–=0 1\nğ¹(ğ‘–âˆ’1)+ğ¹(ğ‘–âˆ’2),\nif ğ‘–>1\n6Inthisimplementation,weareinitializingamemowithdimensions sothatwecanuse1-indexing,wherethesolutionfor isstoredin(ğ‘š+1)Ã—(ğ‘›+1) ğ¹(ğ‘š,ğ‘›)\nmemo[ğ‘š][ğ‘›]insteadofmemo[ğ‘šâˆ’1][ğ‘›âˆ’1]. However,thisisnotnecessary,anditis perfectlyfinetouse0-indexinganddeclareamemowithdimensionsğ‘šÃ—ğ‘›;\nyouwilljustneedtoreturnmemo[ğ‘šâˆ’1][ğ‘›âˆ’1]attheendofthealgorithminsteadofmemo[ğ‘š][ğ‘›]andtreatthebasecaseas insteadof 1).(ğ‘Ÿ=0,ğ‘= (ğ‘Ÿ=1,ğ‘=0)\n882\nChapter 23. Dynamic Programming\nThis problem is very similar to the one in which we had to count the number of ways to get to the bottom-right corner of a grid. Notice here that\nthere are two ways to reach the bottom-right square: either from the cell above or the cell to the left.\nâ†“\nâ†’\nTherefore, if we knew the best path to either of these two squares, we would be able to compute the overall best path by simply adding it to the\nvalue of the final square! This gives us our recursive relationship between subproblems, where represents the minimum cost path toğ¹(ğ‘Ÿ,ğ‘)\nreach the cell at (row ğ‘Ÿ, column ğ‘):\nmin\n2\n1\n2\n1\n6\n4\n3\n9\n3\n7\n1\n5\nğ¹(2,2)=9\n2\n1\n2\n1\n6\n4\n3\n9\n3\n7\n1\n5\nğ¹(1,3)=15\n+\n2\n1\n2\n1\n6\n4\n3\n9\n3\n7\n1\n5\nğº[2][3] = 5\n=\n2\n1\n2\n1\n6\n4\n3\n9\n3\n7\n1\n5\nğ¹(2,3)=14\nThe recurrence relation for this problem is as follows. Given a grid of values ğº, we can compute the minimum path to reach (row ğ‘Ÿ, column ğ‘)\nby solving the subproblems and ğ¹(ğ‘Ÿ,ğ‘âˆ’1), and then combining the smaller of these two values with the value of ğº[ğ‘Ÿ][ğ‘]. The baseğ¹(ğ‘Ÿâˆ’1,ğ‘)\ncase occurs when there is only a single square in the grid (ğ‘Ÿ= 0), which trivially implies that the minimum path cost is simply the value ofğ‘=\nthat square, ğº[0][0]. Since this recurrence relation exhibits overlapping subproblems, a dynamic programming approach can be used.\nğ¹(ğ‘Ÿ,ğ‘)=\nâ§\nâª\nâ¨\nâªâ©\nğº[0][0],\nif ğ‘Ÿ=0,ğ‘=0\nâˆ(i.e., should be ignored),\nif or (out-of-bounds)ğ‘Ÿ< ğ‘<0 0\nmin(ğ¹(ğ‘Ÿâˆ’1,ğ‘),ğ¹(ğ‘Ÿ,ğ‘âˆ’1))+ğº[ğ‘Ÿ][ğ‘],\nif ğ‘Ÿ>0,ğ‘>0\nRemark: Since this is an optimization problem with an optimal substructure, it is good practice to check if a greedy solution exists before\nwe start planning a dynamic programming solution. If we can find an algorithm that guarantees an optimal solution by simply making a\nlocally optimal choice at each step, we would not need to potentially solve and store every possible subproblem as required by a dynamic\nprogramming approach.\nAscoveredinchapter21,agreedyapproachworksiftheproblemexhibitstwoproperties: anoptimal\n(where the optimal solution of a problem can be computed using the optimal solutionssubstructure\nof its subproblems) and the (at least one optimal solution contains the firstgreedy-choice property\ngreedy choice). Although the problem exhibits an optimal substructure, it does exhibit thenot\ngreedy-choice property. In the following grid, the first greedy choice would be to move to the right,\nsince the cost of going right (1) is better than the cost of going down (2). However, the optimal\nsolution goes down first, with a total path cost of 1 + 2 + 1 + 1 + 1 = 6. Since the greedy-choice\nproperty does not hold, we can conclude that the problem cannot be solved using a greedy approach.\n1\n1\n1\n2\n9\n9\n1\n1\n1\ngreedy\noptimal\n1\n1\n1\n2\n9\n9\n1\n1\n1\n1\n1\n1\n2\n9\n9\n1\n1\n1\nA top-down solution for this problem is shown below:\n1\nint32_t min_path(const std::vector<std::vector<int32_t>>& grid) {\n2\nsize_t m = grid.size(), n = grid[0].size();\n3\nstd::vector<std::vector<int32_t>> std::vector<int32_t>(n,memo(m, -1));\n4\nreturn min_path_helper(m - 1, n - 1, grid, memo);\n5\n} // min_path()\n6\n7\nint32_t min_path_helper(int32_t int32_t const std::vector<std::vector<int32_t>>&row, col, grid,\n8\nstd::vector<std::vector<int32_t>>& memo) {\n9\nif (row == 0 && c == 0) {\n10\nreturn grid[0][0];\n11\n} // if\n12\nif (row < 0 || col < 0) {\n13\n// prevents algorithm from choosing a path out-of-bounds\n14\nreturn std::numeric_limits<int>::max();\n15\n} // if\n16\nif (memo[row][col] != -1) {\n// recursive call made before\n17\nreturn memo[row][col];\n18\n} // if\n19\nelse {\n// solve and store in memo\n20\nreturn memo[row][col] = std::min(min_path_helper(row - 1, col, grid, memo),\n21\nmin_path_helper(row, col - 1, grid, memo)) + grid[row][col];\n22\n} // else\n23\n} // min_path_helper()\n23.3 Common Dynamic Programming Patterns\n883\nA bottom-up solution for this problem is shown below:\n1\nint32_t min_path(const std::vector<std::vector<int32_t>>& grid) {\n2\nsize_t m = grid.size(), n = grid[0].size();\n3\nstd::vector<std::vector<int32_t>> std::vector<int32_t>(n));memo(m,\n4\nmemo[0][0] = grid[0][0];\n5\nfor (size_t i = 1; i < m; ++i) {\n6\nmemo[i][0] = memo[i - 1][0] + grid[i][0];\n7\n} // for i\n8\nfor (size_t j = 1; j < n; ++j) {\n9\nmemo[0][j] = memo[0][j - 1] + grid[0][j];\n10\n} // for j\n11\nfor (size_t i = 1; i < m; ++i) {\n12\nfor (size_t j = 1; j < n; ++j) {\n13\nmemo[i][j] = std::min(memo[i - 1][j], memo[i][j - 1]) + grid[i][j];\n14\n} // for j\n15\n} // for i\n16\nreturn memo[m - 1][n - 1];\n17\n} // min_path()\nThetimeandspacecomplexityofthisproblemisÎ˜(ğ‘šğ‘›), sinceupto subproblemsneedtobesolvedifamemoisusedtostoreoverlappingÎ˜(ğ‘šğ‘›)\nsolutions, and each subproblem takes time to compute.Î˜(1)\nExample 23.9 You are given an integer array of coin denominations and a target value. Write a function that returns the fewest number of\n0coins that you need to make change for the given target, or if no such way to make change exists.\nThis is a problem we have seen before when discussing greedy algorithms. Although the greedy approach works for some coin denominations, it\ndoes not find an optimal solution in all cases (see example 21.3). On the contrary, a dynamic programming approach guarantee an optimaldoes\nsolution, regardless of which coin denominations are used! This is because dynamic programming considers all relevant subproblems when\nbuilding up a solution, and not just the locally optimal ones.\nSincethisisadecisionoptimizationproblem,wherewehavetooptimizethecoinweselectateachstep,wecanbeginadynamicprogramming\nsolution by considering the optimal solutions of all preceding states that allow us to reach ğ‘¥cents with the addition of an available coin. Given\nany set of ğ‘›coin denomiations ğ‘‘1,ğ‘‘2,â€¦,ğ‘‘ğ‘›and a target amount ğ‘¥, there are up to ğ‘›preceding states that allow us to directly reach our goal:\nâ€¢ If we have already made optimal change for cents, we can simply add a cent coin.ğ‘¥âˆ’ğ‘‘1 ğ‘‘1\nâ€¢ If we have already made optimal change for cents, we can simply add a cent coin.ğ‘¥âˆ’ğ‘‘2 ğ‘‘2\nâ€¢ If we have already made optimal change for ğ‘¥âˆ’ğ‘‘ğ‘›cents, we can simply add a ğ‘‘ğ‘›cent coin.\nTherefore, to determine the minimum number of coins needed to make change for ğ‘¥cents, we can first compute the minimum number of coins\nto make change for cents, cents, â€¦, and ğ‘¥âˆ’ğ‘‘ğ‘›cents, find the solution out of these subproblems that requires the fewest number ofğ‘¥âˆ’ğ‘‘1 ğ‘¥âˆ’ğ‘‘2\ncoins, and then add one to that solution (for the additional coin we need to reach ğ‘¥cents). The recurrence relation is shown below, where ğ¹(ğ‘¥)\nrepresents the minimum number of coins needed to make change for ğ‘¥cents.\nğ¹(ğ‘¥)=\n{\n0,\nif ğ‘¥=0\n1+min(ğ¹(ğ‘¥âˆ’ğ‘‘1),ğ¹(ğ‘¥âˆ’ğ‘‘2),â€¦,ğ¹(min(ğ‘¥âˆ’ğ‘‘ğ‘›,0)),\nif ğ‘¥>0\nThis recurrence exhibits overlapping subproblems, so dynamic programming can be used. A top-down solution is shown below:\n1\nint32_t coin_change(const std::vector<int32_t>& int32_tcoins, target) {\n2\nstd::vector<int32_t> memo(target + 1, -1);\n3\nreturn coin_change_helper(coins, target, memo);\n4\n} // coin_change()\n5\n6\nint32_t coin_change_helper(std::vector<int32_t>& int32_tcoins, rem_change,\n7\nstd::vector<int32_t>& memo) {\n8\nif (rem_change == 0) {\n9\nreturn 0;\n10\n} // if\n11\nif (rem_change < 0) {\n12\nreturn -1;\n// invalid\n13\n} // if\n14\n// if recursive call made before, fetch solution from memo\n15\nif (memo[rem_change] != -1) { // recursive call made before\n16\nreturn memo[rem_change];\n17\n} // if\n18\nelse { // solve and store in memo\n19\nint32_t std::numeric_limits<int32_t>::max();curr_min =\n20\nfor (int32_t coin_value : coins) {\n21\nint32_t result = coin_change_helper(coins, rem_change - coin_value, memo);\n22\nif (result >= 0 && result < curr_min) {\n23\ncurr_min = result + 1;\n24\n} // if\n25\n} // for coin_value\n26\nreturn memo[rem_change] =\n27\nstd::numeric_limits<int32_t>::max())(curr_min == ? -1 : curr_min;\n28\n} // else\n29\n} // coin_change_helper()\n23.3 Common Dynamic Programming Patterns\n889\nÂ¸ 23.3.3\nDecision Making: Take It or Leave It\nSome dynamic programming problems require you to choose a subset of items to include in a solution given a set of constraints, where you\nhave to decide if each input value should be included or excluded to attain a desired result. To solve these problems, iterate over each item and\ncompare previous states where the item is and isnâ€™t used, and use the solutions to these subproblems to determine if you should include the item\nor exclude it. A few examples are covered below.\nExample 23.12 You are a robber planning to rob houses along a street. Each house has a certain amount of money stashed, stored in\nhouses.an integer array However, you are not allowed to rob houses, since adjacent houses have security systems that willadjacent\nhousesautomatically alert the police if both houses are broken into on the same night. Write a function that takes in the array and returns\nthe maximum amount of money you can rob in one night without alerting the police.\nAt each house, you have two choices you can make: you can either rob the house, or you can choose not to rob it. As a result, this is a decision\nproblem, and the decision you make is dependent on the previous houses you decide to rob. If the house you are considering to rob is located at\nindex ğ‘–, then the choice to rob that house means that you cannot rob the house located at index (but you can rob the house at index andğ‘–âˆ’1 ğ‘–âˆ’2\nthe optimal houses up to that house). On the other hand, if you choose not to rob the house at index ğ‘–, you will be able to rob the house at index\nand all optimal houses up to that point. Therefore, the decision to rob the house at index ğ‘–boils depends on which is more profitable:ğ‘–âˆ’1\nâ€¢ Rob the house at index ğ‘–and combine the money with the optimal amount from robbing up to house ğ‘–âˆ’2\nâ€¢ Do not rob the house at index ğ‘–and keep the optimal amount from robbing up to house ğ‘–âˆ’1\nThis gives us the following recurrence relation, where represents the optimal profit attainable from robbing houses up to index ğ‘–. The baseğ¹(ğ‘–)\ncase occurs when 0, since you earn 0 profit if you cannot rob any house at all.ğ‘–<\nğ¹(ğ‘–)=\n{\n0,\nif ğ‘–<0\nmax(ğ¹(ğ‘–âˆ’2)+houses[ğ‘–],ğ¹(ğ‘–âˆ’1)),\nğ‘–â‰¥0if\nA top-down solution is shown below:\n1\nint32_t rob_houses(const std::vector<int32_t>& houses) {\n2\nstd::vector<int32_t> memo(houses.size(), -1);\n3\nreturn rob_helper(houses, houses.size() - 1, memo);\n4\n} // rob_houses()\n5\n6\nint32_t rob_helper(const std::vector<int32_t>& int32_t std::vector<int32_t>&houses, idx, memo) {\n7\nif (idx < 0) {\n8\nreturn 0;\n9\n} // if\n10\nif (memo[idx] != -1) {\n11\nreturn memo[idx];\n12\n} // if\n13\nelse {\n14\nreturn memo[idx] = std::max(rob_helper(houses, idx - 2, memo) + houses[idx],\n15\nrob_helper(houses, idx - 1, memo));\n16\n} // else\n17\n} // rob_helper()\nA bottom-up solution is shown below:\n1\nint32_t rob_houses(const std::vector<int32_t>& houses) {\n2\nif (houses.size() == 0) {\n3\nreturn 0;\n4\n} // if\n5\nif (houses.size() == 1) {\n6\nreturn houses[0];\n7\n} // if\n8\nstd::vector<int32_t> memo(houses.size());\n9\nmemo[0] = houses[0];\n10\nmemo[1] = std::max(houses[0], houses[1]);\n11\nfor (int32_t i = 2; i < houses.size(); ++i) {\n12\nmemo[i] = std::max(memo[i - 2] + houses[i], memo[i - 1]);\n13\n} // for i\n14\nreturn memo.back();\n15\n} // rob_houses()\nGiven ğ‘›houses, there are ğ‘›potential subproblems that you will need to solve, each of which takes time. Since each subproblem is solvedÎ˜(1)\nat most once using dynamic programming, the time complexity of the above solution is Î˜(ğ‘›). Similarly, since a memo of size is declared,Î˜(ğ‘›)\nthe auxiliary space usage is Î˜(ğ‘›).\n890\nChapter 23. Dynamic Programming\nExample 23.13 Given an array of non-negative integers and a target sum ğ‘¥, write a function that determines if there exists a subset of the\ngiven set with a sum equal to ğ‘¥.\n[6, 9, 10, 15, 36, 44, 68] true,Example: Given the array and a target of 104, you would return since 9 + 15 + 36 + 44 = 104.\nSince we choosing which numbers to include in our subset, this is a decision making problem. Therefore, we can consider each value in the array\none-by-one and use the solutions of smaller subproblems to determine whether each value should be included or excluded from our solution.\nHow do we know whether a value should be included or excluded? To answer this, consider the value 68 in the example above. Notice that the\ninclusion of 68 in the subset sum depends on the following two subproblems:\n[6, 9, 10, 15, 36, 44]â€¢ Can the previous values sum up to 104? (If so, exclude 68 in solution.)\n[6, 9, 10, 15, 36, 44]â€¢ Can the previous values sum up to 36? (If so, include 68 in solution.)104âˆ’68=\nIf the previous numbers we can choose from can already sum up to our target value of 104, then we know that the solution to the entire problem\ntrue.must be However, if the previous numbers cannot sum to 104, then including 68 can help sum to 104 only if the previous numbers can\n36. If the previous numbers cannot sum to 36, then there is no way to include 68 to attain oursum up to the difference between 104 and 68, or\ntarget sum of 104.\nThis idea can be applied to every value in our input array. If we define as the value at index of the array (using 0-indexing)ğ‘£ğ‘›âˆ’1 ğ‘›âˆ’1\nand as whether the first ğ‘›values in our input array can sum up to a target value of ğ‘¥, we can express the problem using the followingğ¹(ğ‘›,ğ‘¥)\nrecurrence relation.\nğ¹(ğ‘›,ğ‘¥)=\nâ§\nâª\nâ¨\nâªâ©\ntrue,\nif ğ‘›=0,ğ‘¥=0\nfalse,\n0,ğ‘¥â‰ 0if ğ‘›=\norğ¹(ğ‘›âˆ’1,ğ‘¥) ğ¹(ğ‘›âˆ’1,ğ‘¥âˆ’ğ‘£ğ‘›âˆ’1),\notherwise\nHere, represents whether the previous values can already sum to ğ‘¥, and represents whether the previousğ¹(ğ‘›âˆ’1,ğ‘¥) ğ‘›âˆ’1 ğ¹(ğ‘›âˆ’1,ğ‘¥âˆ’ğ‘£ğ‘›âˆ’1)\nvalues can sum to ğ‘¥âˆ’ğ‘£ğ‘›âˆ’1. If any of these two are true, then is also true; otherwise it is false.ğ‘›âˆ’1 ğ¹(ğ‘›,ğ‘¥)\nstd::unordered_map<>A top-down solution is shown below. This solution uses a to keep track of subproblems because Booleans\ntrue false, falseonly take on a value of or and we want to differentiate between subproblems that return and subproblems that have not\nbeen encountered before.\n1\nbool subset_sum(const std::vector<int32_t>& int32_tnums, target) {\n2\nstd::vector<std::unordered_map<int32_t, bool>> memo(nums.size() + 1);\n3\nreturn subset_sum_helper(nums, nums.size(), target, memo);\n4\n} // subset_sum()\n5\n6\nbool subset_sum_helper(const std::vector<int32_t>& int32_t int32_tnums, idx, target,\n7\nstd::vector<std::unordered_map<int32_t, bool>>& memo) {\n8\nif (idx == 0) {\n9\nreturn target == 0;\n10\n} // if\n11\nif (target < 0) {\n12\nreturn false;\n13\n} // if\n14\nif (memo[idx].count(target)) {\n15\nreturn memo[idx][target];\n16\n} // if\n17\nelse {\n18\nreturn memo[idx][target] = subset_sum_helper(nums, idx - 1, target, memo) ||\n19\nsubset_sum_helper(nums, idx - 1, target - nums[idx - 1], memo);\n20\n} // else\n21\n} // subset_sum_helper()\nA bottom-up solution is shown below:\n1\nbool subset_sum(std::vector<int32_t>& int32_tnums, target) {\n2\nstd::vector<std::vector<bool>> std::vector<bool>(targetmemo(nums.size() + 1, + 1));\n3\nfor (int32_t i = 0; i <= nums.size(); ++i){\n4\ntrue;memo[i][0] =\n5\n} // for i\n6\nfor (int32_t i = 1; i <= target; ++i) {\n7\nfalse;memo[0][i] =\n8\n} // for i\n9\nfor (int32_t i = 1; i <= nums.size(); ++i) {\n10\nfor (int32_t j = 1; j <= target; ++j) {\n11\nmemo[i][j] = memo[i - 1][j];\n12\nif (j >= nums[i - 1]) {\n13\nmemo[i][j] = memo[i - 1][j] || memo[i - 1][j - nums[i - 1]];\n14\n} // if\n15\n} // for j\n16\n} // for i\n17\nreturn memo[nums.size()][target];\n18\n} // subset_sum()\nThere are a total of subproblems we may need to solve, each taking time. Since the memo allows us to solve each subproblem atÎ˜(ğ‘›ğ‘¥) Î˜(1)\nmost once, the overall time complexity of our dynamic programming solution is therefore Î˜(ğ‘›ğ‘¥). Similarly, since we are using a (ğ‘›+1)Ã—(ğ‘¥+1)\nmemo, the auxiliary space used by this implementation is also Î˜(ğ‘›ğ‘¥).\n23.3 Common Dynamic Programming Patterns\n891\nRemark: One of the best examples of a decision making problem that can be solved using dynamic programming is the 0-1 knapsack\nproblem, which involves finding the best subset of items to fit in a limited capacity knapsack to maximize overall value. However, this\nproblem will not be discussed here since it will get its own chapterâ€¦ so if you are interested in seeing another example of this dynamic\nprogramming pattern, you can read about it in the next chapter!\nÂ¸ 23.3.4\nInterval Merging\nInterval merging is another pattern you may see when working through dynamic programming problems. In these problems, you are given a\ncollection of items that you have to merge together with optimal cost. To solve interval merging questions, you should identify the optimal\nmerging strategy for all possible subintervals and combine these solutions to determine the best way to merge the entire input. As an example,\none common approach for solving these problems is to iterate over each position in the given interval, recursively solve the subproblems\ncorresponding to the intervals to the left and right of this position, and then combine these solutions in a manner that will allow you to obtain\nthe optimal cost. We will look at a few examples below.\nExample 23.14 You are trying to weld together a series of ğ‘›pipes with lengths ğ‘¤0, ğ‘¤1, â€¦, ğ‘¤ğ‘›âˆ’1. The cost to weld together two pipes of\nlengths ğ‘¤ğ‘–and ğ‘¤ğ‘—is max(ğ‘¤ğ‘–, ğ‘¤ğ‘—), and welding these pipes creates a new pipe of length ğ‘¤ğ‘–+ğ‘¤ğ‘—. Implement a function that returns the\nminimum cost required to weld together all the pipes, given the constraint that only adjacent pipes can be welded together. That is, pipes 1\nand 2 can be welded together, but pipes 1 and 3 cannot.\n[3, 5, 2, 6]:Example: Given pipes of lengths\n3\n5\n2\n6\nYou would first merge together the pipes with lengths 3 and 5, for a running cost of max(3, 5) = 5.\n8\n2\n6\nThen, you would merge the pipes with lengths 2 and 6 together, for a running cost of 5 + max(2, 6) = 11.\n8\n8\nLastly, you would merge the remaining two pipes together, for a running cost of 11 + max(8, 8) = 19. This is the minimum cost required to\nmerge all the pipes together, so your function would return 19.\n16\nA dynamic programming solution to this problem, if there even is one, is not inherently obvious. Since this is an optimization problem, you\ncould check if a greedy approach works first. However, you would quickly see that there is no viable greedy algorithm that always produces an\noptimal solution, as only adjacent pipes can be welded together (had this restriction been removed, then the greedy approach of welding the\nsmallest pipes together would work).\n892\nChapter 23. Dynamic Programming\nSince greedy does not work, letâ€™s try to come up with a dynamic programming solution instead. A good starting point is to think about ways we\ncan break the problem up into smaller instances of the same problem, and use these solutions to build up the solution for a larger problem. To\ncome up with our subproblems, we can make the following observation: regardless of how the pipes are welded together, there must always\nlast. By choosing where we want to complete our final weld, we can split the remaining pipe into two independentexist a position that is welded\nsubproblems. For instance, there are three positions we can choose for the last weld using the example above:\n3\n13\n8\n8\n10\n6\nIf we define as the optimal cost of welding all pipes from pipe ğ‘¥up to pipe ğ‘¦(inclusive, using 0-indexing), we can recursively assign ağ¹(ğ‘¥,ğ‘¦)\ncost for each of these final welds. The optimal cost to merge all the pipes if our final weld occurs directly after pipe 0 is\nmax(3, 13) + +ğ¹(0,0) ğ¹(1,3)\n3\n13\nThe optimal cost to merge all the pipes if our final weld occurs directly after pipe 1 is\nmax(8, 8) + +ğ¹(0,1) ğ¹(2,3)\n8\n8\nThe optimal cost to merge all the pipes if our final weld occurs directly after pipe 2 is\nmax(10, 6) + +ğ¹(0,2) ğ¹(3,3)\n10\n6\nIn general, if you are given ğ‘›pipes, the optimal merge cost if the final weld occurs directly after pipe ğ‘˜can be expressed as\nmax(\nğ‘˜\nâˆ‘\nğ‘–=0\nğ‘¤ğ‘–,\nğ‘›âˆ’1\nâˆ‘\nğ‘—=ğ‘˜+1\nğ‘¤ğ‘—)\nâŸââââââââââââââŸââââââââââââââŸ\ncosttoweld\npipes andk+1k\n+\nğ¹(0,ğ‘˜)\nâŸâŸâŸ\ncosttoweldall\npipesfrom0tok\n+ ğ¹(ğ‘˜+1,ğ‘›âˆ’1)\nâŸâââââââŸâââââââŸ\ncosttoweldall\npipesfromk+1ton-1\nTherefore, to determine the optimal cost to merge all pipes from pipe ğ‘¥up to pipe ğ‘¦, we would solve the above equation for all possible values of\nğ‘˜and take the minimum cost. This results in the recurrence relation shown below. The base case for occurs when ğ‘¦, since it takes 0ğ¹(ğ‘¥,ğ‘¦) ğ‘¥=\ncost to merge a pipe with itself.\nğ¹(ğ‘¥,ğ‘¦)=\n{\n0,\nif ğ‘¥=ğ‘¦\nminğ‘¥â‰¤ğ‘˜<ğ‘¦(max(âˆ‘ğ‘˜\nğ‘–=ğ‘¥ğ‘¤ğ‘–,âˆ‘ğ‘¦\nğ‘¤ğ‘—)+ğ¹(ğ‘¥,ğ‘˜)+ğ¹(ğ‘˜+1,ğ‘¦)),ğ‘—=ğ‘˜+1\notherwise\n23.3 Common Dynamic Programming Patterns\n893\nSince the problem requires us to find the optimal cost of merging all pipes from pipe 0 to pipe ğ‘›âˆ’1, we want to solve for ğ¹(0,ğ‘›âˆ’1). If we were\nto write a naÃ¯ve recursive solution for this problem, we would get something like this:\n1\nint32_t weld_pipes(const std::vector<int32_t>& pipes) {\n2\nreturn weld_helper(pipes, 0, pipes.size() - 1);\n3\n} // weld_pipes()\n4\n5\nint32_t weld_helper(const std::vector<int>& int32_t int32_tpipes, first, last) {\n6\nif (first == last) {\n7\nreturn 0; // no work to merge pipe with itself\n8\n} // if\n9\nint32_t std::numeric_limits<int32_t>::max();best =\n10\nfor (int32_t k = first; k < last; ++k) {\n11\nint32_t cost_left = std::accumulate(pipes.begin() + first, pipes.begin() + k + 1, 0);\n12\nint32_t cost_right = std::accumulate(pipes.begin() + k + 1, pipes.begin() + last + 1, 0);\n13\nbest = std::min(best, std::max(cost_left, cost_right) +\n14\nweld_helper(pipes, first, k) + weld_helper(pipes, k + 1, last));\n15\n} // for k\n16\nreturn best;\n17\n} // weld_helper()\nHowever, this implementation is inefficient, since there are overlapping subproblems, and we are solving several subproblems more than once\n(shown by the partial recurrence tree below):\nğ¹(1,ğ‘›âˆ’1)\nâ€¦\nğ¹(3,ğ‘›âˆ’1)\nğ¹(1,2)\nğ¹(2,2)\nğ¹(1,1)\nğ¹(2,ğ‘›âˆ’1)\nâ€¦\nğ¹(4,ğ‘›âˆ’1)\nğ¹(2,3)\nğ¹(3,ğ‘›âˆ’1)\nğ¹(2,2)\nğ¹(1,1)\nTo address this problem, we can use dynamic programming to store the solutions of these repeating subproblems. Since computing each\nsubproblem requires knowledge of both the weight and optimal cost of the pipes to the left and right of the final weld, we want to store both\nand in our memo (or use two separate memos, one for weight and one for cost). This allows us to fetch the weight of any pipe inweight cost\nconstant time, without having to complete a separate linear-time summation every time. An example of this memo structure is shown below:\n3\n5\n2\n6\nweights\n0\n1\n2\n3\n0\n1\n2\n3\ncosts\n0\n1\n2\n3\n0\n1\n2\n3\nweights[i][j] i j costs[i][j]Here, stores the weight of the fully welded pipe from pipe to pipe (i.e., +â€¦+ğ‘¤ğ‘—), andğ‘¤ğ‘–+ğ‘¤ğ‘–+1\ni jstores the optimal cost of welding together all pipes from pipe up to pipe (i.e., ğ¹(ğ‘–,ğ‘—)). The shaded cells do not need to be filled out since\nweights[i][j] == weights[j][i].their values are mirrored across the diagonal:\nUsing the example provided, the memos would be filled out as follows. The solution of the problem would eventually be stored in the top-right\ncosts costs[0][n-1].cell of the table, since our goal is to solve for the optimal cost of welding all pipes from pipe 0 to pipe ğ‘›âˆ’1, or\nweights\n0\n1\n2\n3\n0\n1\n2\n3\n3\n8\n10\n16\n5\n7\n13\n2\n8\n6\ncosts\n0\n1\n2\n3\n0\n1\n2\n3\n0\n5\n12\n19\n0\n5\n12\n0\n6\n0\n898\nChapter 23. Dynamic Programming\nExample 23.16 value.You are given ğ‘›balloons, indexed from 0 to ğ‘›âˆ’1. Each balloon is painted with a number stored in an array If\nithyou burst the balloon, you will earn points based on the product of the popped ballon and its adjacent balloons. Write a function that\nreturns the maximum number of points you can earn from bursting all the balloons.\nFor instance, suppose there are four balloons, with values 4, 2, 7, and 9.\nIt is optimal to first pop the balloon with a value of 2, to earn 4 2 7 = 56 points.Ã— Ã—\nThen, it would be optimal to pop the balloon with a value of 7, to earn 4 7 9 = 252 points.Ã— Ã—\nThen, it would be optimal to pop the balloon with a value of 4, to earn 4 9 = 36 points.Ã—\nThen, the final balloon is popped to earn 9 points.\nAll of the balloons have been popped, so your final score is 56 + 252 + 36 + 9 = 353. This is the highest score you can attain from popping\nthe balloons, so you should return 353.\nIf you wanted to solve this problem using brute force, you would need to iterate over all the popping orders and calculate the number of points\nyou can earn for each order, taking the best at the very end. Given ğ‘›balloons, however, there are unique popping orders. In addition, it takesğ‘›!\ntime to sum up the number of points earned for each order, resulting in an overall time complexity of Î˜(ğ‘›Ã—ğ‘›!). Is there a way to do better?Î˜(ğ‘›)\nSince this is an optimization problem, we could try to see if a greedy solution exists first. However, if you were to try some approaches out,\nyou would see that there is no greedy strategy that satisfies all possible examples. (One common incorrect approach is to pop from smallest to\nlargest among the balloons not at the ends, and then pop the final two balloons in ascending order, but this does not work in the case of 2, 8, 2).\nInstead, we will have to see if there exists a way to recursively break the problem into smaller subproblems, so that an approach such as\ndivide-and-conquer or dynamic programming can be used. A reasonable starting point would be to consider what would happen if we pop any\nballoon in the sequence:\nNotice here that we end up with two remaining intervals after the balloon at index ğ‘˜is popped: one subsequence consisting of all balloons to the\nleft of ğ‘˜and one consisting of all balloons to the right. We can therefore think of the problem in terms of intervals, where the optimal score to\npop all the balloons in a smaller interval can be used to construct the optimal score of a larger interval. In this case, we want to find a recurrence\nrelation that expresses our optimal solution in terms of the two subsequences that remain after the balloon at index ğ‘˜is popped.\nHowever, there is a flaw with this approach. If we think about the recurrence in terms of the balloon we pop, we run into the issuefirst\nwhere the solution of one interval cannot be solved without knowledge of another. For instance, if we popped balloon ğ‘˜and then wanted to find\nthe optimal cost of popping balloon ğ‘˜âˆ’1, our solution would depend on whether balloon has been popped already, as would beğ‘˜+1 ğ‘˜+1\nadjacent to ğ‘˜âˆ’1. This prevents us from being able to solve the subproblems independently!\nTo fix this issue, we need to reverse our thinking. The reason why the subproblems cannot be solved independently is that balloon ğ‘˜has\nalready been popped, which creates a dependency between balloons and ğ‘˜+1. Thus, to be able to solve the subproblems properly, weğ‘˜âˆ’1\nmust keep balloon ğ‘˜unpopped to separate balloons and so that their solutions do not depend on each other. This is the key insight forğ‘˜âˆ’1 ğ‘˜+1\nsolving this problem: ğ‘˜beforebecause we cannot pop balloon solving the left and right subproblems without introducing a dependency between\npop. Notice that this is the same idea we used to solvelastsubproblems, we will instead think about our recurrence in terms of the balloon we\nthe pipe welding problem covered earlier, where we defined our subproblems using the position of the last weld rather than the first weld.\n904\nChapter 23. Dynamic Programming\nSince overlapping subproblems are involved, a dynamic programming approach is useful for solving this problem. There are a total of ğ‘€+1\npossibilities for the length of the first string (0, 1, â€¦, ğ‘€) and possibilities for the length of the second string (0, 1, â€¦, ğ‘), so we willğ‘+1\ncreate a memo with dimensions (ğ‘€+1)Ã—(ğ‘+1). If we use a top-down approach to solve this problem, we will make recursive calls using\nthe conditions of the recurrence relation above, retrieving any solutions from the memo if they have been encountered before. The code for a\ntop-down solution is shown below:\n1\nint32_t lcs(const conststd::string& s1, std::string& s2) {\n2\nsize_t m = s1.length(), n = s2.length();\n3\nstd::vector<std::vector<int32_t>> std::vector<int32_t>(nmemo(m + 1, + 1, -1));\n4\nreturn lcs_helper(s1, s2, s1.length(), s2.length(), memo);\n5\n} // lcs_helper()\n6\n7\nint32_t lcs_helper(const const int32_t int32_tstd::string& s1, std::string& s2, m, n,\n8\nstd::vector<std::vector<int32_t>>& memo) {\n9\nif (m == 0 || n == 0) {\n10\nreturn 0;\n11\n} // if\n12\nif (memo[m][n] != -1) {\n13\nreturn memo[m][n];\n14\n} // if\n15\n// final characters match (minus 1 since strings use 0-indexing)\n16\nif (s1[m - 1] == s2[n - 1]) {\n17\nreturn memo[m][n] = lcs_helper(s1, s2, m - 1, n - 1, memo) + 1;\n18\n} // if\n19\nelse {\n20\nreturn memo[m][n] = std::max(\n21\nlcs_helper(s1, s2, m - 1, n, memo),\n22\nlcs_helper(s1, s2, m, n - 1, memo)\n23\n);\n24\n} // else\n25\n} // lcs_helper()\nIf we use a bottom-up approach to solve the problem, we would build up the subproblems starting from the base case. Using the rules of\nthe recurrence relation, if the two characters at and match, then we would set the value of memo[ğ‘–][ğ‘—] to memo[ğ‘–âˆ’1][ğ‘—âˆ’1] + 1ğ‘†1[ğ‘–] ğ‘†2[ğ‘—]\n(examples of this case are shown below).\na\nl\nm\no\ns\nt\n0\n1\n2\n3\n4\n5\n6\np\na\nr\nr\no\nt\n0\n1\n2\n3\n4\n5\n6\n0\n0\n0\n0\n0\n0\n0\n0\n0\n0\n0\n0\n0\n0\n0\n1\n1\n1\n1\n1\n1\n0\n1\n1\n1\n1\n1\n1\n0\n1\n1\n1\n1\n1\n1\n0\n1\n1\n1\n2\n2\n2\n0\n1\n1\n1\n2\n2\n3\nIf == ğ‘†1[ğ‘—], then we would set the value of memo[ğ‘–][ğ‘—] to max(memo[ğ‘–âˆ’1][ğ‘—], memo[ğ‘–][ğ‘—âˆ’1]).ğ‘†1[ğ‘–]\na\nl\nm\no\ns\nt\n0\n1\n2\n3\n4\n5\n6\np\na\nr\nr\no\nt\n0\n1\n2\n3\n4\n5\n6\n0\n0\n0\n0\n0\n0\n0\n0\n0\n0\n0\n0\n0\n0\n0\n1\n1\n1\n1\n1\n1\n0\n1\n1\n1\n1\n1\n1\n0\n1\n1\n1\n1\n1\n1\n0\n1\n1\n1\n2\n2\n2\n0\n1\n1\n1\n2\n2\n3\n23.3 Common Dynamic Programming Patterns\n907\nThere are overlapping subproblems involved in this recurrence relation, so dynamic programming can be applied. Given strings of lengths ğ‘š\nand ğ‘›, there are a total of subproblems that may be encountered (one subproblem for every possible substring pair), so we will declare aÎ˜(ğ‘šğ‘›)\nmemo of size Î˜(ğ‘šğ‘›). If we use a top-down approach, we would make the corresponding recursive calls and store the solutions we encounter in\nour memo along the way. A top-down solution is shown below:\n1\nint32_t edit_distance(const conststd::string& s1, std::string& s2) {\n2\nstd::vector<std::vector<int32_t>> std::vector<int32_t>(s2.length()memo(s1.length() + 1, + 1, -1));\n3\nreturn edit_distance_helper(s1, s2, s1.length(), s2.length(), memo);\n4\n} // edit_distance()\n5\n6\nint32_t edit_distance_helper(const const int32_t int32_tstd::string& s1, std::string& s2, i, j,\n7\nstd::vector<std::vector<int32_t>>& memo) {\n8\nif (i == 0) {\n9\nreturn j;\n10\n} // if\n11\nif (j == 0) {\n12\nreturn i;\n13\n} // if\n14\nif (memo[i][j] != -1) {\n15\nreturn memo[i][j];\n16\n} // if\n17\nif (s1[i - 1] == s2[j - 1]) {\n18\nreturn memo[i][j] = edit_distance_helper(s1, s2, i - 1, j - 1, memo);\n19\n} // if\n20\nelse {\n21\nint32_t insertion = edit_distance_helper(s1, s2, i, j - 1, memo);\n22\nint32_t deletion = edit_distance_helper(s1, s2, i - 1, j, memo);\n23\nint32_t replacement = edit_distance_helper(s1, s2, i - 1, j - 1, memo);\n24\nreturn memo[i][j] = std::min({insertion, deletion, replacement}) + 1;\n25\n} // else\n26\n} // edit_distance_helper()\nIf we use a bottom-up approach, we would build up the edit distances of all pairs of substrings, starting from the base cases. This is done by\ncomparing the characters corresponding to each cell of the memo and identifying the relevant subproblems we need the solutions to. If the\ncharacters match, we simply copy over the value in the cell on the top left.\ns\na\nt\nu\nr\nd\na\ny\n0\n1\n2\n3\n4\n5\n6\n7\n8\ns\nu\nn\nd\na\ny\n0\n1\n2\n3\n4\n5\n6\nğ‘¥\nğ‘¥+1\nIf the characters do not match, we add one to the minimum of the cell directly above, the cell directly on the left, and the cell directly on the top\nleft (this picks the best outcome out of insertion, deletion, and replacement).\ns\na\nt\nu\nr\nd\na\ny\n0\n1\n2\n3\n4\n5\n6\n7\n8\ns\nu\nn\nd\na\ny\n0\n1\n2\n3\n4\n5\n6\nğ‘¦\nğ‘§\nğ‘¥\nmin(ğ‘¥, ğ‘¦, ğ‘§) + 1\nAfter filling out the entire memo, the solution would be stored at the cell in the bottom right corner.\n23.4 Memo Space Optimization for Bottom-Up Dynamic Programming\n909\nIf we use a top-down approach, we would make the recursive calls indicated by the recurrence relation, storing any solutions we encounter in\nour memo. A top-down solution to this problem is shown below:\n1\nint32_t lis(const std::vector<int32_t>& nums) {\n2\nstd::vector<int32_t> memo(nums.size(), -1);\n3\nfor (int32_t i = nums.size() - 1; i >= 0; --i) {\n4\nlis_helper(nums, i, memo);\n5\n} // for i\n6\nreturn *std::max_element(memo.begin(), memo.end());\n7\n} // lis()\n8\n9\nint32_t lis_helper(const std::vector<int32_t>& int32_t std::vector<int32_t>&nums, idx, memo) {\n10\nif (idx == 0) {\n11\nreturn 1;\n12\n} // if\n13\nif (memo[idx] != -1) {\n14\nreturn memo[idx];\n15\n} // if\n16\nint32_t best = 1;\n17\nfor (int32_t i = idx - 1; i >= 0; --i) {\n18\nif (nums[i] < nums[idx]) {\n19\nbest = std::max(best, 1 + lis_helper(nums, i, memo));\n20\n} // if\n21\n} // for i\n22\nreturn memo[idx] = best;\n23\n} // lis_helper()\nIf we use a bottom-up approach, we would build up the subproblems starting from the base case. To determine what goes at memo[ğ‘–], we would\niterate over the sequence up to index ğ‘–and find the largest value of memo[ğ‘—] such that ğ‘†[ğ‘–], and then add one to this value. A bottom-upğ‘†[ğ‘—]<\nsolution is shown below:\n1\nint32_t lis(const std::vector<int32_t>& nums) {\n2\nstd::vector<int32_t> memo(nums.size(), 1);\n3\nfor (int32_t i = 1; i < nums.size(); ++i) {\n4\nfor (int32_t j = 0; j < i; ++j) {\n5\nif (nums[j] < nums[i]) {\n6\nif (memo[j] + 1 > memo[i]) {\n7\nmemo[i] = memo[j] + 1;\n8\n} // if\n9\n}\n// if\n10\n}\n// for j\n11\n}\n// for i\n12\nreturn *std::max_element(memo.begin(), memo.end());\n13\n}\n// lis()\nnumsFor any index ğ‘–, we have to iterate over all ğ‘–previous values in the array to determine if it contributes to the subsequence (and potentially\nÎ˜(ğ‘›2) numsneeding to solve a subproblem at each index). With the help of the memo, this can completed in time, where ğ‘›is the size of the\narray. The auxiliary space used by this algorithm is Î˜(ğ‘›), for the size of the memo.\n23.4\nMemo Space Optimization for Bottom-Up Dynamic Programming\nWhen using bottom-up dynamic programming, there are certain situations where you can optimize memory usage by reusing previous memo\ncells for multiple subproblems. This optimization technique can be used if you know that a subproblem will never be needed again when\nbuilding up your solution.\nğ‘–thFor instance, consider the Fibonacci problem introduced at the beginning of this chapter. To find the Fibonacci number, you only need to\n(ğ‘–âˆ’1)th (ğ‘–âˆ’2)thquery the and Fibonacci numbers.\nmemo\n0\n1\n1\n2\n3\n5\n8\n0\n1\n2\n3\n4\n5\n6\nmemo[4] memo[5] memo[6].In the example above, you only need to know and to compute The remaining elements in the memo are not\nmemo[0]needed at all â€” in fact, you will never need them again when you solve for larger subproblems! Thus, there is no point in storing up\nmemo[3],to since they will never be referenced later.\n910\nChapter 23. Dynamic Programming\nFor problems like these, you can save on memory by recycling the memo space used for subproblems that will never be needed later. This often\ninvolves collapsing a dimension of the memo (for example, or based on how far back you need to query to solve aÎ˜(ğ‘›) Î˜(ğ‘šğ‘›)â†’Î˜(ğ‘›))â†’Î˜(1)\nsubproblem. In the example above, we only need to keep track of two values at any point in time, so we can reduce the size of our memo from\nto Î˜(1). A solution using this strategy is shown below:Î˜(ğ‘›)\n1\nuint64_t fib(int32_t n) {\n2\nif (n < 2) {\n3\nreturn n;\n4\n} // if n\n5\nuint64_t prev2 = 0, prev1 = 1, curr = 0;\n6\nfor (int32_t i = 2; i <= n; ++i) {\n7\ncurr = prev2 + prev1;\n8\nprev2 = prev1;\n9\nprev1 = curr;\n10\n} // for i\n11\nreturn curr;\n12\n} // fib()\nThis strategy can be used to optimize multidimensional dynamic programming problems as well. Consider the knight moves problem covered\nÎ˜(ğ‘šğ‘›2) ğ‘›2earlier. Initially, we used a memo of size to store all the ways to reach each of the cells on the chessboard using up to ğ‘šmoves.\n1\nmemo[0]\n1\n1\nmemo[1]\n2\n1\n1\n1\n1\n2\n1\n1\n1\n1\nmemo[2]\n2\n1\n2\n2\n8\n3\n2\n8\n4\n4\n1\n4\n2\n1\n3\n2\n3\n2\n4\n3\n2\n1\nmemo[3]\nâ‹®\nHowever, some of this information will never be used again once the subproblems become large enough! For any ğ‘–, the solutions for ğ‘–moves\nonly depend on the solutions for moves, so there is no reason to store the subproblems for and fewer moves if youâ€™ve already built upğ‘–âˆ’1 ğ‘–âˆ’2\nğ‘–ththe solution to the move. This insight allows us to collapse a dimension of our memo, as we only need to store two boards in our memo at\nany single point in time. We can implement this by using one board for odd-numbered moves and another board for even-numbered moves,\nalternating between the two as we build up the solution.\n1\nmemo[0]\n1\n1\nmemo[1]\n2\n1\n1\n1\n1\n2\n1\n1\n1\n1\nmemo[0]\n1\n1\nmemo[1]\n2\n1\n1\n1\n1\n2\n1\n1\n1\n1\nmemo[0]\n2\n1\n2\n2\n8\n3\n2\n8\n4\n4\n1\n4\n2\n1\n3\n2\n3\n2\n4\n3\n2\n1\nmemo[1]\n914\nChapter 23. Dynamic Programming\n7. Consider two solutions to the Fibonacci problem, one that uses a naÃ¯ve approach that does not use memoization, and one that memoizes the\nencountered subproblems using top-down dynamic programming. Which of the following statements is TRUE regarding the auxiliary\nspace complexity of the two approaches?\nA) The naÃ¯ve approach uses auxiliary space, while the top-down dynamic programming approach uses auxiliary spaceÎ˜(1) Î˜(1)\nB) The naÃ¯ve approach uses auxiliary space, while the top-down dynamic programming approach uses auxiliary spaceÎ˜(ğ‘›) Î˜(1)\nC) The naÃ¯ve approach uses auxiliary space, while the top-down dynamic programming approach uses auxiliary spaceÎ˜(ğ‘›)Î˜(1)\nD) The naÃ¯ve approach uses auxiliary space, while the top-down dynamic programming approach uses auxiliary spaceÎ˜(ğ‘›) Î˜(ğ‘›)\nÎ˜(2ğ‘›)E) The naÃ¯ve approach uses auxiliary space, while the top-down dynamic programming approach uses auxiliary spaceÎ˜(ğ‘›)\n8. Which of the following is/are advantages in using a bottom-up dynamic programming approach to solve a problem instead of a top-down\ndynamic programming approach?\nI. The bottom-up approach may end up doing less work since it only computes the answers to subproblems that are needed.\nII. The bottom-up approach makes it easier to reuse positions in the underlying memo if you know which subproblems will never\nbe referenced again.\nIII. The bottom-up approach is less likely to stack overflow if the top-down solution cannot be made tail recursive.\nA) III only\nB) I and II only\nC) I and III only\nD) II and III only\nE) I, II, and III\n9. Consider the coin change making problem, where you want to compute the fewest number of coins needed to make change for a given target\namount ğ‘‡. In this problem, the provided coin denominations are 1Â¢, 4Â¢, and 5Â¢. Which of the following could potentially be a valid partial\nsnapshot of the underlying memo if a bottom-up dynamic programming approach is used? Note that $X.X1 represents some unknown\namount of money that has a 1 in its hundredths position, and that the provided change amounts are consecutive.\nA)\nChange Amount\nâ€¦\n$X.X1\n$X.X2\n$X.X3\n$X.X4\n$X.X5\n$X.X6\nâ€¦\nT\nMinimum Number of Coins Needed\nâ€¦\n45\n46\n47\n48\n49\n50\nâ€¦\n???\nB)\nChange Amount\nâ€¦\n$X.X1\n$X.X2\n$X.X3\n$X.X4\n$X.X5\n$X.X6\nâ€¦\nT\nMinimum Number of Coins Needed\nâ€¦\n45\n45\n45\n45\n45\n45\nâ€¦\n???\nC)\nChange Amount\nâ€¦\n$X.X1\n$X.X2\n$X.X3\n$X.X4\n$X.X5\n$X.X6\nâ€¦\nT\nMinimum Number of Coins Needed\nâ€¦\n45\n46\n40\n41\n42\n47\nâ€¦\n???\nD)\nChange Amount\nâ€¦\n$X.X1\n$X.X2\n$X.X3\n$X.X4\n$X.X5\n$X.X6\nâ€¦\nT\nMinimum Number of Coins Needed\nâ€¦\n45\n43\n44\n45\n43\n44\nâ€¦\n???\nE)\nChange Amount\nâ€¦\n$X.X1\n$X.X2\n$X.X3\n$X.X4\n$X.X5\n$X.X6\nâ€¦\nT\nMinimum Number of Coins Needed\nâ€¦\n45\n45\n45\n45\n45\n46\nâ€¦\n???\n10. Consider a problem whose solution can be expressed using the following recurrence relation:\nğ¹(ğ‘›)=\n{\n0,\nğ‘›â‰¤8if\n2ğ¹(ğ‘›âˆ’8)+ğ¹(ğ‘›âˆ’1),\nğ‘›>8\nIf you solve this problem using an optimal implementation of dynamic programming, what is the worst-case time complexity for computing\nwith additional space?ğ¹(ğ‘›) ğ‘‚(ğ‘›)\nA) Î˜(1)\nB) Î˜(log(ğ‘›))\nC) Î˜(ğ‘›)\nÎ˜(ğ‘›2)D)\nÎ˜(2ğ‘›)E)\n11. You are given a set of ğ‘integers and a target integer ğ¾. Suppose you want to find the subset of these ğ‘integers with the largest size, such\nthat the total sum of all elements in the subset is less than or equal to ğ¾. Which algorithm family should you use to solve this problem, if\nyou want the the best time complexity?\nA) If ğ¾, choose greedy, otherwise choose dynamic programminglog(ğ‘)<\nB) If ğ¾, choose greedy, otherwise choose dynamic programminglog(ğ‘)>\nC) If ğ¾, choose greedy, otherwise choose brute forceğ‘<\nD) If ğ¾, choose greedy, otherwise choose brute forceğ‘>\nE) The greedy algorithm should be chosen for all values of ğ‘and ğ¾\n23.5 Summary of Dynamic Programming Patterns\n919\nChapter 23 Exercise Solutions\n1. Thecorrectansweris(B).Dynamicprogrammingoftenreducesthetimerequiredtosolveaproblemwithmultipleoverlappingsubproblems,\nbut this typically comes at the tradeoff of increased memory (to store the solutions of encountered subproblems in a memo).", "answer_embedding": null, "answer_confidence": null, "page_ids": ["e07bc6fe-0bb9-5892-9565-a839b6bcff01"]}}
{"type": "unmatched_answer", "record": {"id": null, "qa_id": null, "book_id": "47bbcc23-9276-5662-9e40-96e8a4841ec7", "section_labels": ["solutions"], "section_titles": ["Exercise Solutions"], "pdf_page": 931, "problem_key": "8", "answer_number": 8, "answer_choice": "D", "answer_text": "Only statements II and III are true. Statement I is a property of top-down but not bottom-up dynamic\nprogramming. Statement II is true because you can reuse memory for positions of the memo if you know that future subproblems will not\nneed to rely on previous values to be computed (see section 23.4). Statement III is true because bottom-up does not rely on recursive calls\nto build the memo, but rather computes the subproblems iteratively starting from the base case, which is less prone to stack overflows.\n24.2 0-1 Knapsack\n929\nIn general, the approach of selecting higher value items first may not work if large items have high value (such as item 5), which forces us to\nincur a large weight cost after greedily selecting a high-value item. On the other hand, the approach of selecting lower weight items first could\nfail if small items have low value (such as item 1), which causes us to gain little value for the weight we take on. Therefore, to find a valid\ngreedy approach (if it exists), we would need to consider both the weight and value of each item in tandem.\nThis leads us to a third approach: greedily selecting items with the highest (or ratio) first. The value density ofvalue density value-weight\nan item is its value divided by its weight (e.g., value/weight). This allows us to maximize the value we get from each unit of weight we take on,\ninstead of blindly taking on valuable or light items without considering the other variable. However, if we try this strategy on the example, it\nalso does not produce an optimal solution: we would end up taking item 5 first, then 2, then 1 for a total value of 35.\nItem\n1\n2\n3\n4\n5\nWeight\n1\n2\n5\n6\n7\nValue\n1\n6\n18\n22\n28\nRatio\n1\n3\n3.6\n3.67\n4\nUnfortunately, this greedy strategy could still fail for the 0-1 knapsack problem if large items have a high value density (such as item 5). By\ntaking item 5, we were prevented from taking the next best item (item 4) because our knapsack could not support it.\nIf considering the value-weight ratio failed to find a valid greedy solution, is there even a way to do better? It actually turns out that the\nanswer is no: problem! If we wanted to solve 0-1there exists no greedy strategy that guarantees an optimal solution for the 0-1 knapsack\nknapsack, we would have to rely on a slightly more complicated algorithm family.\nÂ¸ 24.2.3\nSolving 0-1 Knapsack Using Dynamic Programming\nOne approach that we can use to solve the 0-1 knapsack problem is dynamic programming, as it is perfectly follows the decision making problem\nstructure discussed in the previous chapter. To solve 0-1 knapsack using dynamic programming, we will iterate over each item and use the\nsolutions of previously computed subproblems to determine we should take the item or leave it behind. To illustrate this, letâ€™s define asğ¹(ğ‘–,ğ‘)\nğ‘–ththe optimal value attainable from considering the first ğ‘–items with a knapsack of capacity ğ‘, with ğ‘¤ğ‘–and ğ‘£ğ‘–as the weight and value of the\nitem. We can express recursively by noticing that there are only two possibilities for each item ğ‘–: it can either be taken or left behind.ğ¹(ğ‘–,ğ‘)\nâ€¢ If item ğ‘–is behind, the maximum value attainable must be equal to ğ¹(ğ‘–âˆ’1,ğ‘), or the optimal solution of the first items with ağ‘–âˆ’1left\nğ‘–thknapsack capacity ğ‘. This is because, if the item is not included, the best you can do is equal to the solution of the subproblem that\ndoes not consider this item.\nâ€¢ If item ğ‘–is taken, the maximum value attainable must be equal to ğ¹(ğ‘–âˆ’1,ğ‘âˆ’ğ‘¤ğ‘–)+ğ‘£ğ‘–, or the optimal solution of the first items withğ‘–âˆ’1\nğ‘–th ğ‘–tha knapsack capacity ğ‘âˆ’ğ‘¤ğ‘–, plus the value of the item. This is because, if you want to include the item in your knapsack, the earlier\nitems can only take up at most ğ‘âˆ’ğ‘¤ğ‘–weight so you donâ€™t go over capacity.\nTherefore, to compute ğ¹(ğ‘–,ğ‘), we simply have to take the better of these two values. The base case of this problem occurs when (no itemsğ‘–=0\nto choose from), which implies that the best value attainable is also 0 (since you cannot take any items). Putting this all together, we end up with\nthe following recurrence relation:\nğ¹(ğ‘–,ğ‘)=\n{\n0,\nif ğ‘–=0\nmax(ğ¹(ğ‘–âˆ’1,ğ‘), ğ¹(ğ‘–âˆ’1,ğ‘âˆ’ğ‘¤ğ‘–)+ğ‘£ğ‘–),\nif ğ‘–>0, ğ‘>0\nA top-down solution is shown below â€” in this solution, we simply make the recursive calls reflected in the above recurrence relation and write\nour solutions to a memo, where memo[ğ‘–][ğ‘] stores the solution to ğ¹(ğ‘–,ğ‘).\n1\nstruct Item {\n2\nint32_t weight;\n3\nint32_t value;\n4\n};\n5\n6\nint32_t knapsack_01(int32_t constc, std::vector<Item>& items) {\n7\nconst size_t n = items.size();\n8\nstd::vector<std::vector<int32_t>> std::vector<int32_t>(cmemo(n + 1, + 1, -1));\n9\nreturn knapsack_helper(c, items, n - 1, memo);\n10\n} // knapsack_01()\n11\n12\nint32_t knapsack_helper(int32_t const int32_tc, std::vector<Item>& items, i,\n13\nstd::vector<std::vector<int32_t>>& memo) {\n14\nif (i < 0) {\n15\nreturn 0;\n16\n} // if\n17\nif (memo[i][c] != -1) {\n18\nreturn memo[i][c];\n19\n} // if\n20\nint32_t val_excluded = knapsack_helper(c, items, i - 1, memo);\n21\n// optimization: if weight of item already over capacity, it must be excluded\n22\nif (items[i].weight > c) {\n23\nreturn memo[i][c] = val_excluded;\n24\n} // if\n25\nint32_t val_included = knapsack_helper(c - items[i].weight, items, i - 1, memo) + items[i].value;\n26\nreturn memo[i][c] = std::max(val_excluded, val_included);\n27\n} // knapsack_helper()\n930\nChapter 24. The Knapsack Problem\nA bottom-up approach follows the same idea, but starts with the base cases and builds upwards toward the final solution. To implemement a\nbottom-up solution, we will need a double nested loop: an outer loop that iterates over all the items, and an inner loop that iterates over all\nknapsacks from capacity 0 to ğ‘. A bottom-up implementation is shown below:\n1\nstruct Item {\n2\nint32_t weight;\n3\nint32_t value;\n4\n};\n5\n6\nint32_t knapsack_01(int32_t constc, std::vector<Item>& items) {\n7\nconst size_t n = items.size();\n8\nstd::vector<std::vector<int32_t>> std::vector<int32_t>(cmemo(n + 1, + 1, 0));\n9\nfor (size_t i = 0; i < n; ++i) {\n10\nfor (size_t j = 0; j < c + 1; ++j) {\n11\nif (j < items[i].weight) {\n12\n// weight of item already over capacity, exclude\n13\nmemo[i + 1][j] = memo[i][j];\n14\n} // if\n15\nelse {\n16\nmemo[i + 1][j] = std::max(memo[i][j], memo[i][j - items[i].weight] + items[i].value);\n17\n} // else\n18\n} // for j\n19\n} // for i\n20\nreturn memo[n][c];\n21\n} // knapsack_01()\nTo illustrate how this works, we will use the example provided. We start off by initiating a memo of size to store the solutions of(ğ‘›+1)Ã—(ğ‘+1)\nour subproblems. Since any subproblem where has a solution of 0, row 0 of our memo must be entirely filled out with 0s.ğ‘›=0\n0\n1\n2\n3\n4\n5\n6\n7\n8\n9\n10\n11\n0\n0\n0\n0\n0\n0\n0\n0\n0\n0\n0\n0\n0\n1\n2\n3\n4\n5\nCapacity\nItem\nWe will then consider row 1, which considers all items up to item 1. Item 1 has a weight of 1, which does not fit in a knapsack with capacity 0,\nso memo[1][0] gets set to 0.\n0\n1\n2\n3\n4\n5\n6\n7\n8\n9\n10\n11\n0\n0\n0\n0\n0\n0\n0\n0\n0\n0\n0\n0\n0\n1\n0\n2\n3\n4\n5\nCapacity\nItem\nHowever, if our knapsack capacity increases to 1, we would be able to add item 1 to our knapsack. This increases our value to 1, which is\nassigned to memo[1][1].\n0\n1\n2\n3\n4\n5\n6\n7\n8\n9\n10\n11\n0\n0\n0\n0\n0\n0\n0\n0\n0\n0\n0\n0\n0\n1\n0\n1\n2\n3\n4\n5\nCapacity\nItem\n24.5 Unbounded Knapsack\n941\n6. Assume you are implementing a dynamic programming approach to the 0-1 knapsack problem, and you are trying to find the maximum\npossible value you can take in your knapsack of weight capacity 5. You have the following items; the prices of items 3 and 4 are unknown:\nItem ID\nWeight\nValue\n1\n2\n$27\n2\n1\n$20\n3\n4\n4\n3\nT\nThe memo for this problem is shown below. Some of the values in the memo have already been filled in (ID represented by memo row,\nweight represented by memo column). You are given two conditions that need to be met:\nğ‘‹â‰¥ğ‘Œinâ€¢ the memo below\nâ€¢ all optimal solutions for this 0-1 knapsack problem (with weight capacity 5) must include item 4 in the final knapsack\nID/Weight\n0\n1\n2\n3\n4\n5\n0\n$0\n$0\n$0\n$0\n$0\n$0\n1\n$0\n$0\n$27\n$27\n2\n$0\n3\n$0\nğ‘‹\nğ‘Œ\n4\n$0\nWhat is the lowest possible value of item 4 (denoted as ğ‘‡) that ensures these two conditions will always be true?\nA) $40\nB) $41\nC) $47\nD) $67\nE) $68\nFor questions 7-8, suppose you had the following five items, and you want to place them in a knapsack of capacity 16.\nItem\n1\n2\n3\n4\n5\nWeight\n4\n10\n6\n8\n2\nValue\n5\n7\n9\n6\n4\nKnapsack Capacity: 16\n7. If you are allowed to take a portion of these items for partial value (i.e., fractional knapsack), what is the maximum value that can be stored\ninto the knapsack without going over capacity?\nA) 18\nB) 19\nC) 20\nD) 21\nE) 22\n8. Which of the following statements is/are TRUE?\nI. If this were a 0-1 knapsack problem, the maximum value attainable in the knapsack is 18\nII. Item 1 is taken in the optimal fractional knapsack solution, but is left behind in the optimal 0-1 knapsack solution\nIII. If there were an unlimited supply of all five items, the maximum value attainable in the unbounded knapsack is 32\nA) I only\nB) II only\nC) III only\nD) I and III only\nE) II and III only\n9. Which of the following statements is/are TRUE regarding the greedy approach toward a knapsack problem?\nI. The greedy approach will not always give an optimal solution to the 0-1 knapsack problem\nII. The greedy approach will not always give an optimal solution to the fractional knapsack problem\nIII. Given ğ‘›items to put into a fractional knapsack of capacity ğ‘, the worst-case time complexity of a greedy solution is Î˜(ğ‘›log(ğ‘›))\nA) I only\nB) II only\nC) I and II only\nD) I and III only\nE) I, II, and III\n946\nChapter 24. The Knapsack Problem\nChapter 24 Exercise Solutions", "answer_embedding": null, "answer_confidence": null, "page_ids": ["2afd0c50-ab9c-5b1e-acab-c7e93b22bf80"]}}
{"type": "unmatched_answer", "record": {"id": null, "qa_id": null, "book_id": "47bbcc23-9276-5662-9e40-96e8a4841ec7", "section_labels": ["solutions"], "section_titles": ["Exercise Solutions"], "pdf_page": 958, "problem_key": "8", "answer_number": 8, "answer_choice": "E", "answer_text": "The optimal solution to the 0-1 knapsack problem is 19, which is obtained by taking items 3, 4, and 5. This\nmakes statement I false and statement II true (since we do not take item 1 here, but did in the fractional knapsack solution in question 7). If\nthere is an unlimited supply of all five items, the unbounded knapsack solution would be to only take item 5 until the knapsack is full (8\ncopies), which yields a total value of 8 4 = 32.Ã—\n24.5 Unbounded Knapsack\n949", "answer_embedding": null, "answer_confidence": null, "page_ids": ["f5d6b0c4-2db1-5173-8428-b1cf083e7cc4"]}}
{"type": "unmatched_answer", "record": {"id": null, "qa_id": null, "book_id": "47bbcc23-9276-5662-9e40-96e8a4841ec7", "section_labels": ["solutions"], "section_titles": ["Exercise Solutions"], "pdf_page": 961, "problem_key": "20", "answer_number": 20, "answer_choice": "A", "answer_text": "This is a constraint satisfaction problem, where you are checking if you can build a schedule that meets all your\nconstraints. This is a problem that can be best solved using backtracking.\nThe correct answer is (D). This is similar to the 0-1 knapsack problem, where you have to place items (rides) of different costs (wait times)21.\ninto a knapsack of limited size (the time you have remaining until the park closes). Since you are dealing with integer values here, this type\nof problem can be most efficiently solved using a dynamic programming approach.", "answer_embedding": null, "answer_confidence": null, "page_ids": ["fa3d76e7-f248-5f89-aa79-8ac7b5a3afa5"]}}
{"type": "unmatched_answer", "record": {"id": null, "qa_id": null, "book_id": "47bbcc23-9276-5662-9e40-96e8a4841ec7", "section_labels": ["solutions"], "section_titles": ["Exercise Solutions"], "pdf_page": 961, "problem_key": "22", "answer_number": 22, "answer_choice": "E", "answer_text": "This is similar to the fractional knapsack problem; if you begin eating a plate of food, you arenâ€™t obligated to\nfinish it. It is okay to only eat a portion of a dish to fill your stomach, so the best approach would be to eat the food you like the most until\nyou cannot eat anymore. This is an example of a greedy algorithm.", "answer_embedding": null, "answer_confidence": null, "page_ids": ["fa3d76e7-f248-5f89-aa79-8ac7b5a3afa5"]}}
{"type": "unmatched_answer", "record": {"id": null, "qa_id": null, "book_id": "47bbcc23-9276-5662-9e40-96e8a4841ec7", "section_labels": ["solutions"], "section_titles": ["Exercise Solutions"], "pdf_page": 961, "problem_key": "23", "answer_number": 23, "answer_choice": "A", "answer_text": "Since you want to color the United States under a constraint that two adjacent states cannot share the same\ncolor, you will want to select an algorithm that can be used to solve constraint satisfaction problems. Of the given options, this is best\nhandled using a backtracking approach.", "answer_embedding": null, "answer_confidence": null, "page_ids": ["fa3d76e7-f248-5f89-aa79-8ac7b5a3afa5"]}}
{"type": "unmatched_answer", "record": {"id": null, "qa_id": null, "book_id": "47bbcc23-9276-5662-9e40-96e8a4841ec7", "section_labels": ["solutions"], "section_titles": ["Exercise Solutions"], "pdf_page": 961, "problem_key": "24", "answer_number": 24, "answer_choice": "D", "answer_text": "The strategy that will allow you to minimize the total number of drops would be to use a binary search approach\nto eliminate half of the remaining test heights with each drop. (i.e., start the first drop at height ğ‘›âˆ•2; if the phone breaks, do the next drop at\nheight ğ‘›âˆ•4, otherwise do the next drop at height 3ğ‘›âˆ•4, and so on). This is an example of divide-and-conquer.", "answer_embedding": null, "answer_confidence": null, "page_ids": ["fa3d76e7-f248-5f89-aa79-8ac7b5a3afa5"]}}
{"type": "unmatched_answer", "record": {"id": null, "qa_id": null, "book_id": "47bbcc23-9276-5662-9e40-96e8a4841ec7", "section_labels": ["solutions"], "section_titles": ["Exercise Solutions"], "pdf_page": 961, "problem_key": "25", "answer_number": 25, "answer_choice": "C", "answer_text": "Since you want to sort a ton of logs that do not fit in main memory, an external sorting algorithm (like external\nmergesort) would be most appropriate for this task. Such a sorting algorithm would be able to divide the data into smaller chunks that do fit\nin memory, sort each individual chunk and write the results to temporary files on disk, and then merge the sorted chunks in passes to get the\nfinal result. These efficient sorting methods fall under the divide-and-conquer paradigm.", "answer_embedding": null, "answer_confidence": null, "page_ids": ["fa3d76e7-f248-5f89-aa79-8ac7b5a3afa5"]}}
{"type": "unmatched_answer", "record": {"id": null, "qa_id": null, "book_id": "47bbcc23-9276-5662-9e40-96e8a4841ec7", "section_labels": ["solutions"], "section_titles": ["Exercise Solutions"], "pdf_page": 961, "problem_key": "26", "answer_number": 26, "answer_choice": "E", "answer_text": "This is a variation of the activity selection problem discussed in section 21.3.3, which can be solved by greedily\nselecting the next lecture with the earliest end time.", "answer_embedding": null, "answer_confidence": null, "page_ids": ["fa3d76e7-f248-5f89-aa79-8ac7b5a3afa5"]}}
{"type": "unmatched_answer", "record": {"id": null, "qa_id": null, "book_id": "47bbcc23-9276-5662-9e40-96e8a4841ec7", "section_labels": ["solutions"], "section_titles": ["Exercise Solutions"], "pdf_page": 961, "problem_key": "27", "answer_number": 27, "answer_choice": "A", "answer_text": "This is a constraint satisfaction problem, where you have to find a solution that meets several complex\nrequirements (in this case, every prime number must end up in a gray cell, and all adjacent numbers must be in neighboring cells). This\nis best handled by backtracking, which explores the solution space and rejects any partial solution that fails to meet any of the required\nconstraints (i.e., paths where a prime number falls on a non-shaded cell).", "answer_embedding": null, "answer_confidence": null, "page_ids": ["fa3d76e7-f248-5f89-aa79-8ac7b5a3afa5"]}}
{"type": "unmatched_answer", "record": {"id": null, "qa_id": null, "book_id": "47bbcc23-9276-5662-9e40-96e8a4841ec7", "section_labels": ["solutions"], "section_titles": ["Exercise Solutions"], "pdf_page": 961, "problem_key": "28", "answer_number": 28, "answer_choice": "B", "answer_text": "Knowing that a coin is candy does not give you any additional information on which coin is real, since the only\nway to determine if a coin is real or not is to bite into it, and you can only test each coin individually. Thus, there is no option but to try\nevery coin until you find the one that is not candy, which is a brute force approach.\n29. Thecorrectansweris(C).Withtheaddedknowledgethattherealcoinisheavierthantheothers, younowhaveawaytodividethesolution\nspace so that you do not have to try out each coin individually. The optimal strategy would be to split the coins into two even groups and\nplace each group on one side of the scale. The heavier side must contain the real coin, and all the coins in the lighter side must be fake. This\nis continued until the real coin is the only one that remains (in the case of an odd number of coins, one coin can be placed aside, and if the\ntwo sides of the scale are equal in weight, then the coin placed aside must be real). This is an example of a divide-and-conquer algorithm.", "answer_embedding": null, "answer_confidence": null, "page_ids": ["fa3d76e7-f248-5f89-aa79-8ac7b5a3afa5"]}}
{"type": "unmatched_answer", "record": {"id": null, "qa_id": null, "book_id": "47bbcc23-9276-5662-9e40-96e8a4841ec7", "section_labels": ["solutions"], "section_titles": ["Exercise Solutions"], "pdf_page": 961, "problem_key": "30", "answer_number": 30, "answer_choice": "B", "answer_text": "This is very similar to the traveling salesperson (TSP) problem, where you want to minimize the total travel\nneeded to visit a set of predetermined locations. TSP problems can be solved using branch-and-bound (where you try to explore the search\nspace and prune out any solutions that are not as good as the best solution encountered so far), which is the most applicable algorithm\nfamily for solving this problem. Backtracking does not apply here since this is an optimization problem, divide-and-conquer does not apply\nsince you cannot break up the TSP problem into independent subproblems, and there is no greedy method that can optimally solve TSP.\n958\nChapter 25. Shortest Path Algorithms\nFor example, consider the following graph, where we want to find the shortest path from ğ´to ğ¶:\nA\nB\nC\n4\n2\n-3\nDijkstraâ€™s algorithm would greedily select edge ğ´ğ¶for a distance of 2, since it is better than the distance of 4 from edge ğ´ğµ. As a result, the\nalgorithm would mark vertex ğ¶as visited with a best known distance of 2â€¦ however, this is not the optimal solution! If we had gone through\nvertex ğµinstead, we would have ended up with a better distance of 4 + (-3) = 1. However, Dijkstraâ€™s algorithm failed to find this optimal path\nbecause it did not know about edge ğµğ¶and that its weight was negative enough to overcome the seemingly suboptimal choice of edge ğ´ğµ.\nA\nB\nC\n4\n2\n-3\nDijkstra Solution\nA\nB\nC\n4\n2\n-3\nOptimal Solution\nIn general, if there are multiple ways to reach a vertex in a graph, and at least one of those ways involves a negative edge, then Dijkstraâ€™s\nalgorithm could potentially mark that vertex as visited before encountering the negative edge. Since Dijkstraâ€™s uses a greedy approach, it never\nreconsiders this decision and assumes that the solution it found is optimal, using it to construct the solutions of subsequent vertices that are\nencountered later on. By the time the algorithm discovers a negative edge that improves the solution of a previously visited vertex, it is too\nlate! This is why Dijkstraâ€™s algorithm is avoided if a graph has negative edges. If you do have a graph with negative edges, it is better to use a\ndifferent algorithmic approach that can handle this scenario (specifically dynamic programming, which will be discussed in the next section).\nÂ¸ 25.2.4\nChanging Edge Weights in the Shortest Path\nExample 25.1 Let ğ‘ƒbe the shortest path from vertex ğ‘ to vertex ğ‘¡of a given graph. If the weight of every edge in the graph is multiplied\nby the same positive constant ğ‘˜(i.e., the weight of each edge is changed from ğ‘¥to ğ‘˜ğ‘¥), is ğ‘ƒstill guaranteed to be the shortest path in the\ngraph? Or could the shortest path change?\nThe shortest path does not change if you multiply every edge by a constant factor. We can show this using a proof by contradiction: suppose\nğ‘ƒâ€² ğ‘ƒâ€²there exists a different path from ğ‘ to ğ‘¡that is shorter than ğ‘ƒafter all the edges are multiplied by ğ‘˜. However, if we divide all the edges in\nğ‘ƒâ€²by ğ‘˜, we would see that must have been shorter before all the edges were multiplied. Therefore, ğ‘ƒwould not have been the shortest path,\nwhich results in a contradiction. In general, multiplying all edges by a constant factor does not change the shortest path because multiplication is\ndistributive (unlike addition, which we will see in the next example).\nExample 25.2 Let ğ‘ƒbe the shortest path from vertex ğ‘ to vertex ğ‘¡of a given graph. If the weight of every edge in the graph is incremented\nby the same positive constant ğ‘˜(i.e., the weight of each edge is changed from ğ‘¥to ğ‘˜+ğ‘¥), is ğ‘ƒstill guaranteed to be the shortest path in the\ngraph? Or could the shortest path change?\nUnlike multiplication, addition does not guarantee that the shortest path will remain the same. This can be shown using a quick example: in the\nfollowing graph, the shortest path from ğ´to ğ¶is to go through ğµfor a total weight of 1 + 2 = 3.\nA\nB\nC\n1\n4\n2\nHowever, if we add 2 to every edge, the shortest path now travels from ğ´to ğ¶directly for a total weight of 6.\nA\nB\nC\n3\n6\n4\nThe reason for this is that addition, unlike multiplication, does not distribute weight proportionally across all edges in the graph. This ends up\npunishing paths with more edges significantly more than paths with fewer edges, as longer paths have more edges on which additional weight\ncan be applied. As a result, a path that is initially optimal may be overtaken by a path with fewer edges if the same weight is applied equally to\nevery edge of the graph.\n982\nChapter 25. Shortest Path Algorithms\nChapter 25 Exercise Solutions", "answer_embedding": null, "answer_confidence": null, "page_ids": ["fa3d76e7-f248-5f89-aa79-8ac7b5a3afa5"]}}
{"type": "unmatched_answer", "record": {"id": null, "qa_id": null, "book_id": "47bbcc23-9276-5662-9e40-96e8a4841ec7", "section_labels": ["solutions"], "section_titles": ["Exercise Solutions"], "pdf_page": 994, "problem_key": "8", "answer_number": 8, "answer_choice": "B", "answer_text": "Since Dijkstraâ€™s algorithm greedily explores vertices in order of increasing distance from the source vertex ğ´,\nfor vertex ğ·to be discovered last, it must be farther from vertex ğ´than all the other vertices. There are only two ways to reach vertex ğ·\nfrom the source vertex ğ´given the provided order that Dijkstraâ€™s visited the vertices: either through the direct connection of weight ğ‘¦, or\nthrough vertex ğ¶, which is reachable from ğ´with total weight 2+ğ‘¥. We know that ğ¸is marked as visited before ğ·, so the distance from ğ´\nto ğ·via vertex ğ¶must be strictly greater than the distance to get from ğ´to ğ¸via vertex ğ¶(equal does not work since ties are broken\nalphabetically). Thus, must be true, or ğ·would be visited before ğ¸. The smallest possible value of ğ‘¥is 1 since the graph hasğ‘¦>2+ğ‘¥+2\npositive, non-zero integer weights, so ğ‘¦must be strictly greater than 5.", "answer_embedding": null, "answer_confidence": null, "page_ids": ["7b25559a-771c-5789-849e-761231306ccf"]}}
{"type": "unmatched_answer", "record": {"id": null, "qa_id": null, "book_id": "47bbcc23-9276-5662-9e40-96e8a4841ec7", "section_labels": ["solutions"], "section_titles": ["Exercise Solutions"], "pdf_page": 994, "problem_key": "9", "answer_number": 9, "answer_choice": "D", "answer_text": "To solve the all-pairs shortest path problem using Dijkstraâ€™s algorithm, you would need to run the algorithm\n|ğ‘‰| Î˜(|ğ¸|log(|ğ‘‰|))time with each vertex as the source vertex. Each run would take time on a sparse graph with the priority queue\n|ğ‘‰| Î˜(|ğ‘‰||ğ¸|log(|ğ‘‰|)).implementation, so running the algorithm times would yield an overall time complexity of", "answer_embedding": null, "answer_confidence": null, "page_ids": ["7b25559a-771c-5789-849e-761231306ccf"]}}
{"type": "unmatched_answer", "record": {"id": null, "qa_id": null, "book_id": "47bbcc23-9276-5662-9e40-96e8a4841ec7", "section_labels": ["solutions"], "section_titles": ["Exercise Solutions"], "pdf_page": 994, "problem_key": "10", "answer_number": 10, "answer_choice": "E", "answer_text": "All of the algorithms can be considered as greedy algorithms. Primâ€™s greedily chooses the vertex with the\nsmallest tentative distance to another vertex, Kruskalâ€™s greedily chooses the smallest edge that does not produce a cycle, and Dijkstraâ€™s\ngreedily chooses the vertex with the shortest distance available from the source vertex.", "answer_embedding": null, "answer_confidence": null, "page_ids": ["7b25559a-771c-5789-849e-761231306ccf"]}}
{"type": "unmatched_answer", "record": {"id": null, "qa_id": null, "book_id": "47bbcc23-9276-5662-9e40-96e8a4841ec7", "section_labels": ["solutions"], "section_titles": ["Exercise Solutions"], "pdf_page": 994, "problem_key": "11", "answer_number": 11, "answer_choice": "A", "answer_text": "The process of running Dijkstraâ€™s is shown below. The order in which vertices are marked as visited is:\nğ´,ğ¶,ğµ,ğ¹,ğ·,ğº,ğ¸.\nğ‘£ğ‘˜ğ‘£ğ‘‘ğ‘£ğ‘ğ‘£\nğ´\nğµ\nğ¶\nğ·\nğ¸\nğ¹\nğº\nT\n0\n-\nâˆ-F\nâˆ-F\nâˆ-F\nâˆ-F\nâˆ-F\nâˆ-F\nğ‘£ğ‘˜ğ‘£ğ‘‘ğ‘£ğ‘ğ‘£\nğ´\nğµ\nğ¶\nğ·\nğ¸\nğ¹\nğº\nT\n0\n-\nF\n3\nA\nF\n2\nA\nâˆ-F\nâˆ-F\nâˆ-F\nâˆ-F\nğ‘£ğ‘˜ğ‘£ğ‘‘ğ‘£ğ‘ğ‘£\nğ´\nğµ\nğ¶\nğ·\nğ¸\nğ¹\nğº\nT\n0\n-\nF\n3\nA\nT\n2\nA\nâˆ-F\nâˆ-F\nâˆ-F\nâˆ-F\nğ‘£ğ‘˜ğ‘£ğ‘‘ğ‘£ğ‘ğ‘£\nğ´\nğµ\nğ¶\nğ·\nğ¸\nğ¹\nğº\nT\n0\n-\nF\n3\nA\nT\n2\nA\nF\n6\nC\nâˆ-F\nF\n5\nC\nâˆ-F\nğ‘£ğ‘˜ğ‘£ğ‘‘ğ‘£ğ‘ğ‘£\nğ´\nğµ\nğ¶\nğ·\nğ¸\nğ¹\nğº\nT\n0\n-\nT\n3\nA\nT\n2\nA\nF\n6\nC\nâˆ-F\nF\n5\nC\nâˆ-F\nğ‘£ğ‘˜ğ‘£ğ‘‘ğ‘£ğ‘ğ‘£\nğ´\nğµ\nğ¶\nğ·\nğ¸\nğ¹\nğº\nT\n0\n-\nT\n3\nA\nT\n2\nA\nF\n6\nC\nF\n9\nB\nF\n5\nC\nâˆ-F\nğ‘£ğ‘˜ğ‘£ğ‘‘ğ‘£ğ‘ğ‘£\nğ´\nğµ\nğ¶\nğ·\nğ¸\nğ¹\nğº\nT\n0\n-\nT\n3\nA\nT\n2\nA\nF\n6\nC\nF\n9\nB\nT\n5\nC\nâˆ-F\nğ‘£ğ‘˜ğ‘£ğ‘‘ğ‘£ğ‘ğ‘£\nğ´\nğµ\nğ¶\nğ·\nğ¸\nğ¹\nğº\nT\n0\n-\nT\n3\nA\nT\n2\nA\nF\n6\nC\nF\n9\nB\nT\n5\nC\nF\n7\nF\nğ‘£ğ‘˜ğ‘£ğ‘‘ğ‘£ğ‘ğ‘£\nğ´\nğµ\nğ¶\nğ·\nğ¸\nğ¹\nğº\nT\n0\n-\nT\n3\nA\nT\n2\nA\nT\n6\nC\nF\n9\nB\nT\n5\nC\nF\n7\nF\nğ‘£ğ‘˜ğ‘£ğ‘‘ğ‘£ğ‘ğ‘£\nğ´\nğµ\nğ¶\nğ·\nğ¸\nğ¹\nğº\nT\n0\n-\nT\n3\nA\nT\n2\nA\nT\n6\nC\nF\n9\nB\nT\n5\nC\nT\n7\nF\nğ‘£ğ‘˜ğ‘£ğ‘‘ğ‘£ğ‘ğ‘£\nğ´\nğµ\nğ¶\nğ·\nğ¸\nğ¹\nğº\nT\n0\n-\nT\n3\nA\nT\n2\nA\nT\n6\nC\nT\n9\nB\nT\n5\nC\nT\n7\nF\n26.10 Segment Trees\n1025\nWith this information, we are now able to query the minimum value of any range in worst-case time. If we are given any index range,Î˜(log(ğ‘›))\nthere are three outcomes that can happen:\n1. The range matches the segment of a node in the segment tree. In this case, you can just return the value associated with this node.\n2. The range falls entirely within the domain of either the left or right child (i.e., in the left or right half of values). In this case, recurse into\nthe child that covers the range.\n3. The range is split across both the left and right children. In this case, you will have to make two recursive calls: one into the left child\nwith its portion of the range, and one into the right child with its portion of the range. Then, combine the two solutions together to get the\nsolution for the original range.\nFor example, consider what happens when we make a query to find the minimum value within the index range [2, 4]. We start at the root of the\ntree and see which side the range [2, 4] belongs to. Because the range [2, 4] is split between both the left and right children, we will perform two\nrecursive calls, one on the left child, and one on the right child.\n[0,7]\n-14\n[4,7]\n-14\n[6,7]\n1\n[7,7]\n10\n[6,6]\n1\n[4,5]\n-14\n[5,5]\n-14\n[4,4]\n-12\n[0,3]\n-13\n[2,3]\n-13\n[3,3]\n19\n[2,2]\n-13\n[0,1]\n4\n[1,1]\n7\n[0,0]\n4\nLetâ€™s first consider the recursive call on the left child, which stores the range of [0, 3]. The portion of our original range that falls in the left half\nis [2, 3], which falls entirely in the right half of the range [0, 3]. Thus, we will perform a recursive call on the right child with this range of [2, 3].\n[0,7]\n-14\n[4,7]\n-14\n[6,7]\n1\n[7,7]\n10\n[6,6]\n1\n[4,5]\n-14\n[5,5]\n-14\n[4,4]\n-12\n[0,3]\n-13\n[2,3]\n-13\n[3,3]\n19\n[2,2]\n-13\n[0,1]\n4\n[1,1]\n7\n[0,0]\n4\nWe have encountered a node associated with the interval range of [2, 3], which matches the range that we were looking for. Therefore, the value\nof this node, -13, is the solution of the original recursive call on the rootâ€™s left child.\n[0,7]\n-14\n[4,7]\n-14\n[6,7]\n1\n[7,7]\n10\n[6,6]\n1\n[4,5]\n-14\n[5,5]\n-14\n[4,4]\n-12\n[0,3]\n-13\n[2,3]\n-13\n[3,3]\n19\n[2,2]\n-13\n[0,1]\n4\n[1,1]\n7\n[0,0]\n4\nWe can repeat this process for the right subtree, as shown. The solution of this recursive call is -12.\n[0,7]\n-14\n[4,7]\n-14\n[6,7]\n1\n[7,7]\n10\n[6,6]\n1\n[4,5]\n-14\n[5,5]\n-14\n[4,4]\n-12\n[0,3]\n-13\n[2,3]\n-13\n[3,3]\n19\n[2,2]\n-13\n[0,1]\n4\n[1,1]\n7\n[0,0]\n4\nThe minimum sum in the range [2, 3] is -13, and the minimum sum in the range [4, 4] is -12. We can combine these two solutions to get the\nminimum sum in the desired range of [2, 4], which is min(-13, -12) = -13.\n1026\nChapter 26. Computational Geometry\nUpdating a value in the array also takes time in a segment tree. This is because any element in the original data is only associatedÎ˜(log(ğ‘›))\nwith a single node at each level of the tree. Since there are only levels in the tree, each update would only need to changeÎ˜(log(ğ‘›)) Î˜(log(ğ‘›))\nnodes in the tree, which takes time if each update takes constant time. An example is shown for the given example: if we change theÎ˜(log(ğ‘›))\n19 -19,value at index 3 from to only the following nodes of the segment tree need to be updated:\n[0,7]\n-19\n[4,7]\n-14\n[6,7]\n1\n[7,7]\n10\n[6,6]\n1\n[4,5]\n-14\n[5,5]\n-14\n[4,4]\n-12\n[0,3]\n-19\n[2,3]\n-19\n[3,3]\n-19\n[2,2]\n-13\n[0,1]\n4\n[1,1]\n7\n[0,0]\n4\nNow that we have the basic structure of how our segment tree can be used to solve the problem, we can begin implementing it in code. To\ninitially build our tree, we can use recursion to construct the values of the segment tree in a postorder fashion. This is done by recursively\nbuilding the values of a nodeâ€™s two children and then merging the results together to get the value of the current node. An example is shown\nbelow (note that we store our segment tree as a binary tree that is represented as an 1-indexed array, which allows us to access the left and right\nchildren of the node at index ğ‘–using index 2ğ‘–and 2ğ‘–+1, respectively â€” see section 18.2.1 for more detail on this procedure).\n1\nclass SegmentTree {\n2\nprivate:\n3\nstd::vector<int32_t> segment_tree;\n// segment tree represented using an array (1-indexed)\n4\nstd::vector<int32_t> values;\n// the values we want to query range data from\n5\n6\n// helper function that can be used to construct a segment tree node at curr_idx of the array\n7\nvoid build_segment_tree(size_t size_t size_tcurr_idx, left, right) {\n8\nif (left == right) {\n// base case of single index in range (leaf node)\n9\nsegment_tree[curr_idx] = values[left];\n10\n} // if\n11\nelse {\n12\nsize_t middle = left + (right - left) / 2;\n13\n// recursively build left subtree (left child of idx is located at 2 idx)*\n14\nbuild_segment_tree(2 curr_idx, left, middle);*\n15\n// recursively build right subtree (right child of idx is located at 2 idx + 1)*\n16\nbuild_segment_tree(2 curr_idx + 1, middle + 1, right);*\n17\n// combine the solutions to get the value of the node at idx\n18\nsegment_tree[curr_idx] = std::min(segment_tree[2 curr_idx], segment_tree[2 curr_idx + 1]);* *\n19\n} // else\n20\n} // build_segment_tree()\n21\n22\npublic:\n23\n// Segment tree ctor, the segment tree array is initialized to a size of 4n since this is the\n24\n// maximum potential size needed (the vector is also initialized to the largest possible\n25\n// integer since we do not want unused positions to interfere in finding the smallest value)\n26\nSegmentTree(const std::vector<int32_t>& nums)\n27\nstd::numeric_limits<int32_t>::max()),: segment_tree(4 nums.size(), values(nums) {*\n28\n// 1 is passed in as the initial vertex since that is index of the root, which we start from\n29\nbuild_segment_tree(1, 0, nums.size() - 1);\n30\n} // SegmentTree()\n31\n};\n26.10 Segment Trees\n1027\nget_min_value_in_range(),To implement we will use the input range to decide which side of the tree to recurse into. If the input\nrange matches exactly with a range in our segment tree, we will return its value directly. Otherwise, we will search in the left and/or right\nsubtrees to get the solution(s), combining them if necessary. One possible implementation of this method is shown below:\n1\nclass SegmentTree {\n2\nprivate:\n3\n/* ... other members same as before ... */\n4\n5\n// helper function, seg_left and seg_right represent the boundaries of the current segment\n6\n// tree node, and query_left and query_right represent the boundaries of the current query\n7\nint32_t get_min_value_helper(size_t size_t size_tcurr_idx, seg_left, seg_right,\n8\nsize_t size_tquery_left, query_right) {\n9\n// query range matches range of segment tree node, so return the node's value\n10\nif (query_left == seg_left && query_right == seg_right) {\n11\nreturn segment_tree[curr_idx];\n12\n} // if\n13\nsize_t seg_middle = seg_left + (seg_right - seg_left) / 2;\n14\n// query entirely in left side, so recurse into left child\n15\nif (query_right <= seg_middle) {\n16\nreturn get_min_value_helper(2 curr_idx, seg_left, seg_middle, query_left, query_right);*\n17\n} // if\n18\n// query entirely in right side, so recurse into right child\n19\nif (query_left > seg_middle) {\n20\nreturn get_min_value_helper(2 curr_idx + 1, seg_middle + 1, seg_right,*\n21\nquery_left, query_right);\n22\n} // if\n23\n// else recurse into both and take the minimum (i.e., merge the two results together)\n24\nreturn std::min(\n25\nget_min_value_helper(2 curr_idx, seg_left, seg_middle, query_left, seg_middle),*\n26\nget_min_value_helper(2 curr_idx + 1, seg_middle + 1, seg_right, seg_middle + 1, query_right)*\n27\n);\n28\n} // get_min_value_helper()\n29\n30\npublic:\n31\n/* ... other members same as before ... */\n32\nint32_t get_min_value_in_range(size_t size_tleft, right) {\n33\nreturn get_min_value_helper(1, 0, values.size() - 1, left, right);\n34\n} // get_min_value_in_range()\n35\n};\nTo update a value at a specific index, we will recurse down the branch of the segment tree that contains the index we want to update. This can\nalso be done in a postorder fashion, as shown in the implementation below:\n1\nclass SegmentTree {\n2\nprivate:\n3\n/* ... other members same as before ... */\n4\nvoid update_index_helper(size_t size_t size_tcurr_idx, seg_left, seg_right,\n5\nsize_t int32_tidx_to_update, new_value) {\n6\nif (seg_left == seg_right) {\n// base case of single index in range (leaf node)\n7\nsegment_tree[curr_idx] = new_value;\n8\n} // if\n9\nelse {\n10\nsize_t seg_middle = seg_left + (seg_right - seg_left) / 2;\n11\nif (idx_to_update <= seg_middle) {\n12\n// update left child\n13\nupdate_index_helper(2 curr_idx, seg_left, seg_middle, idx_to_update, new_value);*\n14\n} // if\n15\nelse {\n16\n// update right child\n17\nupdate_index_helper(2 curr_idx + 1, seg_middle + 1, seg_right, idx_to_update, new_value);*\n18\n} // else\n19\n// combine solutions\n20\nsegment_tree[curr_idx] = std::min(segment_tree[2 curr_idx], segment_tree[2 curr_idx + 1]);* *\n21\n} // else\n22\n} // update_index_helper()\n23\n24\npublic:\n25\n/* ... other members same as before ... */\n26\nvoid update_index(size_t int32_tidx, new_value) {\n27\nupdate_index_helper(1, 0, values.size() - 1, idx, new_value);\n28\n} // update_index()\n29\n};\nThis concludes our implementation of the problem. By using a segment tree, we can ensure that values can be updated and that the minimum\nvalue can be queried from any range in worst-case time! This is better than the alternative options of recomputing the minimum valueÎ˜(log(ğ‘›))\nduring every query or during every update, both of which involve an operation that takes time.Î˜(ğ‘›)\n26.10 Segment Trees\n1029\nThis behavior is implemented below (note that this is very similar to our implementation in the previous example with the minimum value):\n1\nclass OptionsExpirationManager {\n2\nprivate:\n3\nint32_t farthest_expiration;\n4\n// each asset name needs its own segment tree, so we will use an unordered map\n5\nstd::vector<int32_t>>std::unordered_map<std::string, segment_trees_by_asset;\n6\n7\nvoid trade_helper(const size_t size_tstd::string& asset_name, curr_idx, seg_left,\n8\nsize_t size_t int32_tseg_right, idx_to_update, quantity) {\n9\n// initialize segment tree if no trades have been made for the asset yet\n10\nauto segment_tree_it = segment_trees_by_asset.find(asset_name);\n11\nif (segment_tree_it == segment_trees_by_asset.end()) {\n12\nsegment_trees_by_asset[asset_name].resize(4 farthest_expiration);*\n13\n} // if\n14\nauto& segment_tree = segment_trees_by_asset[asset_name];\n15\nif (seg_left == seg_right) {\n16\nsegment_tree[curr_idx] += quantity;\n17\n} // if\n18\nelse {\n19\nsize_t seg_middle = seg_left + (seg_right - seg_left) / 2;\n20\nif (idx_to_update <= seg_middle) {\n21\ntrade_helper(asset_name, 2 curr_idx, seg_left, seg_middle, idx_to_update, quantity);*\n22\n} // if\n23\nelse {\n24\ntrade_helper(asset_name, 2 curr_idx + 1, seg_middle + 1,*\n25\nseg_right, idx_to_update, quantity);\n26\n} // else\n27\n// combine solutions\n28\nsegment_tree[curr_idx] = segment_tree[2 curr_idx] + segment_tree[2 curr_idx + 1];* *\n29\n} // else\n30\n} // trade_helper()\n31\n32\npublic:\n33\n// Constructor takes in the number of days until the farthest expiration\n34\nOptionsExpirationManager(int32_t farthest_expiration_in)\n35\n: farthest_expiration(farthest_expiration_in) {}\n36\n37\nvoid make_trade(const int32_t int32_tstd::string& asset_name, days_to_exp, quantity) {\n38\ntrade_helper(asset_name, 1, 0, farthest_expiration - 1, days_to_exp, quantity);\n39\n} // make_trade()\n40\n};\nget_position() get_min_value_in_range()The function can be implemented similarly to the function in the previous example.\nWe will use the input range to determine which side of the tree to recurse into, and if the input range spans multiple intervals, we will recurse\ninto each of those intervals and combine their solutions. This is implemented below:\n1\nclass OptionsExpirationManager {\n2\nprivate:\n3\nint32_t farthest_expiration;\n4\n// each asset name needs its own segment tree, so we will use an unordered map\n5\nstd::vector<int32_t>>std::unordered_map<std::string, segment_trees_by_asset;\n6\n7\nint32_t position_helper(const size_t size_tstd::string& asset_name, curr_idx, seg_left,\n8\nsize_t size_t size_tseg_right, query_left, query_right) {\n9\n// return 0 if no trades have been made for the asset yet\n10\nauto segment_tree_it = segment_trees_by_asset.find(asset_name);\n11\nif (segment_tree_it == segment_trees_by_asset.end()) {\n12\nreturn 0;\n13\n} // if\n14\nif (query_left == seg_left && query_right == seg_right) {\n15\nreturn segment_tree_it->second[curr_idx];\n16\n} // if\n17\nsize_t seg_middle = seg_left + (seg_right - seg_left) / 2;\n18\nif (query_right <= seg_middle) {\n19\nreturn position_helper(asset_name, 2 curr_idx, seg_left,*\n20\nseg_middle, query_left, query_right);\n21\n} // if\n22\nif (query_left > seg_middle) {\n23\nreturn position_helper(asset_name, 2 curr_idx + 1, seg_middle + 1,*\n24\nseg_right, query_left, query_right);\n25\n} // if\n26\nreturn position_helper(asset_name, 2 curr_idx, seg_left, seg_middle, query_left, seg_middle) +*\n27\nposition_helper(asset_name, 2 curr_idx + 1, seg_middle + 1,*\n28\nseg_right, seg_middle + 1, query_right);\n29\n} // position_helper()\n30\n31\n/* ... continued on next page ... */\n26.11 Images and Graphics\n1041\nChapter 26 Exercise Solutions", "answer_embedding": null, "answer_confidence": null, "page_ids": ["7b25559a-771c-5789-849e-761231306ccf"]}}
{"type": "unmatched_answer", "record": {"id": null, "qa_id": null, "book_id": "47bbcc23-9276-5662-9e40-96e8a4841ec7", "section_labels": ["solutions"], "section_titles": ["Exercise Solutions"], "pdf_page": 1053, "problem_key": "8", "answer_number": 8, "answer_choice": "E", "answer_text": "The Shoelace formula can be used to find the area of any simple polygon, regardless of position and concavity\n(see section 26.5.3 for a demonstration). The only shape that the Shoelace formula cannot compute the area for is option (E), which is not a\nsimple polygon.\n9. Rectangles can be identified using either two vertical or horizontal lines. Thus, for each vertical line formed by two ğ‘¦-coordinates, a\nrectangle can be formed if another line that can be created using the same two ğ‘¦-coordinates is found. To obtain our solution, we can loop\nthrough the points and keep track of the ğ‘¦-coordinate pairs we encounter and a running total of the number of rectangles that can be created\nusing that pair as the vertical edges of a rectangle. One implementation of this solution is shown below:\n1\nint32_t count_rectangles(const std::vector<Point>& points) {\n2\nstd::map<std::pair<int32_t, int32_t>, int32_t> lines;\n3\nint32_t count = 0;\n4\nfor (const auto& p1 : points) {\n5\nfor (const auto& p2 : points) {\n6\nif (p1.x == p2.x && p1.y < p2.y) {\n7\nstd::pair<int32_t, int32_t> vertical_line{ p1.y, p2.y };\n8\ncount += lines[vertical_line]++;\n9\n} // if\n10\n} // for p2\n11\n} // for p1\n12\nreturn count;\n13\n} // count_rectangles()", "answer_embedding": null, "answer_confidence": null, "page_ids": ["6275fd1a-cffc-5d55-9e15-840a57b06dcd"]}}
